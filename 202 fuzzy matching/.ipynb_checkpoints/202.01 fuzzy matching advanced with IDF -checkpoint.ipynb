{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with Fuzzy Matching on large data\n",
    "\n",
    "There are many algorithms which can provide fuzzy matching but they quickly fall down when used on even modest data sets of greater than a few thousand records.\n",
    "The reason for this is that they compare each record to all the other records in the data set. In computer science, this is known as quadratic time and can quickly form a barrier when dealing with larger data sets.\n",
    "A relative small data set of 10k records would require 100m operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How a well known NLP algorithm can help solve the issue.  \n",
    "The solution to this problem comes from a well known NLP algorithm.  \n",
    "Term Frequency, Inverse Document Frequency (or tf-idf) has been used in language problems since 1972.  \n",
    "It is a simple algorithm which splits text into ‘chunks’ (or ngrams), counts the occurrence of each chunk for a given sample and then applies a weighting to this based on how rare the chunk is across all the samples of a data set. This means that useful words are filtered from the ‘noise’ of more common words which occur within text.\n",
    "Whilst these chunks are normally applied to whole words, there is no reason why the same technique cannot be applied to sets of characters within words. For example, we could split each word into 3 character ngrams, for the word ‘Department’, this would output: ' De', 'Dep', 'epa', 'par', 'art', 'rtm', 'tme', 'men', 'ent', 'nt '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1qhBwDRitrgapNhyaHGxCW8uKK5SWJblW\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for this case obtained from:\n",
    "\n",
    "https://www.gov.uk/contracts-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (0.2.9)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (46.0.0.post20200309)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (1.4.1)\n",
      "Requirement already satisfied: cython>=0.29.15 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (0.29.15)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparse_dot_topn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/csv/notices (3).csv\n",
      "./test_data/csv/notices (2).csv\n",
      "./test_data/csv/notices (9).csv\n",
      "./test_data/csv/notices (5).csv\n",
      "./test_data/csv/notices (4).csv\n",
      "./test_data/csv/notices (8).csv\n",
      "./test_data/csv/notices.csv\n",
      "./test_data/csv/notices (7).csv\n",
      "./test_data/csv/notices (6).csv\n",
      "./test_data/csv/notices (1).csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7659, 43)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob # used to read file directories, there are alternatives: pathlib.Path.rglob or os.walk\n",
    "files= glob.glob(\"./test_data/csv/*.csv\", recursive=False)\n",
    "df= pd.DataFrame()\n",
    "for f in files:\n",
    "    print(f)\n",
    "    d=pd.read_csv(f)\n",
    "    df=df.append(d, sort=False)\n",
    "   \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you just want to load one file use this\n",
    "#df=pd.read_csv(\"./test_data/csv/notices.csv\")\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notice Identifier</th>\n",
       "      <th>Notice Type</th>\n",
       "      <th>Organisation Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Nationwide</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Region</th>\n",
       "      <th>...</th>\n",
       "      <th>Value High</th>\n",
       "      <th>Awarded Date</th>\n",
       "      <th>Awarded Value</th>\n",
       "      <th>Supplier [Name|Address|Ref type|Ref Number|Is SME|Is VCSE]</th>\n",
       "      <th>Supplier's contact name</th>\n",
       "      <th>Contract start date</th>\n",
       "      <th>Contract end date</th>\n",
       "      <th>OJEU Procedure Type</th>\n",
       "      <th>Accelerated Justification</th>\n",
       "      <th>Closing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tender_243792/886810</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Department for Work and Pensions</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T14:40:54Z</td>\n",
       "      <td>Security Architecture Service for DWP Digital ...</td>\n",
       "      <td>Provide cloud security design, proportionate s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE98 1YX</td>\n",
       "      <td>North East</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/06/2020</td>\n",
       "      <td>99962.00</td>\n",
       "      <td>[Cyber Security Partnership LLP|Weaver Road, L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/07/2020</td>\n",
       "      <td>31/03/2021</td>\n",
       "      <td>CallOffFromFrameworkAgreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW27816 SRNA</td>\n",
       "      <td>Contract</td>\n",
       "      <td>H M REVENUE &amp; CUSTOMS</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T10:53:32Z</td>\n",
       "      <td>Wide Area Network - Multi site</td>\n",
       "      <td>Managed Wide Area Network Services to 27 sites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15/06/2020</td>\n",
       "      <td>2247088.80</td>\n",
       "      <td>[HIGHSPEED OFFICE LIMITED|50 Leman Street\\nLON...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/07/2020</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>CallOffFromFrameworkAgreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCA001-DN497372-32575894</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Homes England (the name adopted by the Homes a...</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T09:29:17Z</td>\n",
       "      <td>Homes England Framework - GCloud-BETA for HTB ...</td>\n",
       "      <td>Homes England Framework - GCloud-BETA for HTB ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>...</td>\n",
       "      <td>924000.0</td>\n",
       "      <td>29/06/2020</td>\n",
       "      <td>924000.00</td>\n",
       "      <td>[Gulp Digital|W3 7SH|NONE||Yes|No]</td>\n",
       "      <td>Mr Sam Osinowo</td>\n",
       "      <td>01/07/2020</td>\n",
       "      <td>30/11/2020</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA1011</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Restoration and Renewal Delivery Authority Ltd</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-10T15:30:11Z</td>\n",
       "      <td>Digital Bespoke Retained Capability Function</td>\n",
       "      <td>Call-off contract under the CCS-G-Cloud 11-RM1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SW1P 3JA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/06/2020</td>\n",
       "      <td>191425.00</td>\n",
       "      <td>[METHODS BUSINESS AND DIGITAL TECHNOLOGY LIMIT...</td>\n",
       "      <td>Meera Morjaria</td>\n",
       "      <td>01/07/2020</td>\n",
       "      <td>30/09/2020</td>\n",
       "      <td>CallOffFromFrameworkAgreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DR240773331</td>\n",
       "      <td>Contract</td>\n",
       "      <td>.East Riding Of Yorkshire Council</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-10T08:52:49Z</td>\n",
       "      <td>Barriers and Sanitiser Dispensers</td>\n",
       "      <td>Barriers and Sanitiser Dispensers required for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yorkshire and the Humber</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21/06/2020</td>\n",
       "      <td>74071.04</td>\n",
       "      <td>[Viking Hardware Ltd|Viking Hourse\\nSpyvee Str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22/06/2020</td>\n",
       "      <td>22/12/2020</td>\n",
       "      <td>CompetitiveQuotationNonOJEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Notice Identifier Notice Type  \\\n",
       "0      tender_243792/886810    Contract   \n",
       "1              CW27816 SRNA    Contract   \n",
       "2  HCA001-DN497372-32575894    Contract   \n",
       "3                    DA1011    Contract   \n",
       "4               DR240773331    Contract   \n",
       "\n",
       "                                   Organisation Name   Status  \\\n",
       "0                   Department for Work and Pensions  Awarded   \n",
       "1                              H M REVENUE & CUSTOMS  Awarded   \n",
       "2  Homes England (the name adopted by the Homes a...  Awarded   \n",
       "3     Restoration and Renewal Delivery Authority Ltd  Awarded   \n",
       "4                  .East Riding Of Yorkshire Council  Awarded   \n",
       "\n",
       "         Published Date                                              Title  \\\n",
       "0  2020-09-11T14:40:54Z  Security Architecture Service for DWP Digital ...   \n",
       "1  2020-09-11T10:53:32Z                     Wide Area Network - Multi site   \n",
       "2  2020-09-11T09:29:17Z  Homes England Framework - GCloud-BETA for HTB ...   \n",
       "3  2020-09-10T15:30:11Z       Digital Bespoke Retained Capability Function   \n",
       "4  2020-09-10T08:52:49Z                  Barriers and Sanitiser Dispensers   \n",
       "\n",
       "                                         Description  Nationwide  Postcode  \\\n",
       "0  Provide cloud security design, proportionate s...         NaN  NE98 1YX   \n",
       "1     Managed Wide Area Network Services to 27 sites         NaN       NaN   \n",
       "2  Homes England Framework - GCloud-BETA for HTB ...         NaN       NaN   \n",
       "3  Call-off contract under the CCS-G-Cloud 11-RM1...         NaN  SW1P 3JA   \n",
       "4  Barriers and Sanitiser Dispensers required for...         NaN       NaN   \n",
       "\n",
       "                     Region  ... Value High Awarded Date Awarded Value  \\\n",
       "0                North East  ...        NaN   30/06/2020      99962.00   \n",
       "1            United Kingdom  ...        NaN   15/06/2020    2247088.80   \n",
       "2                   England  ...   924000.0   29/06/2020     924000.00   \n",
       "3                       NaN  ...        NaN   30/06/2020     191425.00   \n",
       "4  Yorkshire and the Humber  ...        NaN   21/06/2020      74071.04   \n",
       "\n",
       "  Supplier [Name|Address|Ref type|Ref Number|Is SME|Is VCSE]  \\\n",
       "0  [Cyber Security Partnership LLP|Weaver Road, L...           \n",
       "1  [HIGHSPEED OFFICE LIMITED|50 Leman Street\\nLON...           \n",
       "2                 [Gulp Digital|W3 7SH|NONE||Yes|No]           \n",
       "3  [METHODS BUSINESS AND DIGITAL TECHNOLOGY LIMIT...           \n",
       "4  [Viking Hardware Ltd|Viking Hourse\\nSpyvee Str...           \n",
       "\n",
       "  Supplier's contact name Contract start date Contract end date  \\\n",
       "0                     NaN          01/07/2020        31/03/2021   \n",
       "1                     NaN          01/07/2020        30/06/2022   \n",
       "2          Mr Sam Osinowo          01/07/2020        30/11/2020   \n",
       "3          Meera Morjaria          01/07/2020        30/09/2020   \n",
       "4                     NaN          22/06/2020        22/12/2020   \n",
       "\n",
       "              OJEU Procedure Type Accelerated Justification Closing Time  \n",
       "0  CallOffFromFrameworkAgreement                        NaN        00:00  \n",
       "1  CallOffFromFrameworkAgreement                        NaN        23:00  \n",
       "2                          Other                        NaN        23:59  \n",
       "3  CallOffFromFrameworkAgreement                        NaN        17:00  \n",
       "4    CompetitiveQuotationNonOJEU                        NaN        12:00  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ftfy # amazing text cleaning for decode issues.. TO INVESTIGATE\n",
    "#from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ngram function  \n",
    "The below function is used as both a cleaning function of the text data as well as a way of splitting text into ngrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    #string = fix_text(string) # fix text encoding issues\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower() #make lower case\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string) #remove the list of chars defined above\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single space\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great thing about the tf-idf implementation in Scikit is that it allows for a custom function to be added to it. We can therefore add-in the function we have created above and build the matrix in just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1146x3097 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33263 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_field = df['Organisation Name'].unique()\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(target_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we are going to find similarities using the cosine function  \n",
    "While you could use the cosine similarity function from Scikit here, it is not the most efficient way of finding close matches as it returns a closeness score for every item in the dataset for each sample. Instead, we are going to use a faster implementation of this which can be found here:\n",
    "https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similarity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similarity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similarity': similarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFTIMED: 0.003007173538208008\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.85)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df = get_matches_df(matches, target_field, top=100)\n",
    "matches_df = matches_df[matches_df['similarity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Department for Transport : Department for Tran...</td>\n",
       "      <td>Department For Transport</td>\n",
       "      <td>0.974240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Department for Transport : Department for Tran...</td>\n",
       "      <td>THE DEPARTMENT FOR TRANSPORT</td>\n",
       "      <td>0.898558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MINISTRY OF HOUSING, COMMUNITIES &amp; LOCAL GOVER...</td>\n",
       "      <td>Ministry of Housing, Communities &amp; Local Gover...</td>\n",
       "      <td>0.989177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Business Energy and Industrial Strategy</td>\n",
       "      <td>Department for Business Energy &amp; Industrial St...</td>\n",
       "      <td>0.890011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>THE DEPARTMENT FOR TRANSPORT</td>\n",
       "      <td>Department For Transport</td>\n",
       "      <td>0.922317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            left_side  \\\n",
       "3   Department for Transport : Department for Tran...   \n",
       "4   Department for Transport : Department for Tran...   \n",
       "9   MINISTRY OF HOUSING, COMMUNITIES & LOCAL GOVER...   \n",
       "30            Business Energy and Industrial Strategy   \n",
       "34                       THE DEPARTMENT FOR TRANSPORT   \n",
       "\n",
       "                                           right_side  similarity  \n",
       "3                            Department For Transport    0.974240  \n",
       "4                        THE DEPARTMENT FOR TRANSPORT    0.898558  \n",
       "9   Ministry of Housing, Communities & Local Gover...    0.989177  \n",
       "30  Department for Business Energy & Industrial St...    0.890011  \n",
       "34                           Department For Transport    0.922317  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If we want to use this technique to match against another data source then we can recycle the majority of our code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=pd.read_csv(\"./test_data/csv/notices (1).csv\")\n",
    "target_field_clean = df_clean['Organisation Name'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing the data - this could take a few minutes for large datasets...\n",
      "Vectorizing completed...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(target_field_clean)\n",
    "print('Vectorizing completed...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<315x1752 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8539 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
