{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with Fuzzy Matching on large data\n",
    "\n",
    "There are many algorithms which can provide fuzzy matching but they quickly fall down when used on even modest data sets of greater than a few thousand records.\n",
    "The reason for this is that they compare each record to all the other records in the data set. In computer science, this is known as quadratic time and can quickly form a barrier when dealing with larger data sets.\n",
    "A relative small data set of 10k records would require 100m operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How a well known NLP algorithm can help solve the issue.  \n",
    "The solution to this problem comes from a well known NLP algorithm.  \n",
    "Term Frequency, Inverse Document Frequency (or tf-idf) has been used in language problems since 1972.  \n",
    "It is a simple algorithm which splits text into ‘chunks’ (or ngrams), counts the occurrence of each chunk for a given sample and then applies a weighting to this based on how rare the chunk is across all the samples of a data set. This means that useful words are filtered from the ‘noise’ of more common words which occur within text.\n",
    "Whilst these chunks are normally applied to whole words, there is no reason why the same technique cannot be applied to sets of characters within words. For example, we could split each word into 3 character ngrams, for the word ‘Department’, this would output: ' De', 'Dep', 'epa', 'par', 'art', 'rtm', 'tme', 'men', 'ent', 'nt '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1qhBwDRitrgapNhyaHGxCW8uKK5SWJblW\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for this case obtained from:\n",
    "\n",
    "https://www.gov.uk/contracts-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (0.2.9)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (46.0.0.post20200309)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (1.4.1)\n",
      "Requirement already satisfied: cython>=0.29.15 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (0.29.15)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/juanespasandin/opt/anaconda3/lib/python3.7/site-packages (from sparse_dot_topn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sparse_dot_topn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./test_data/notices.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notice Identifier</th>\n",
       "      <th>Notice Type</th>\n",
       "      <th>Organisation Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Nationwide</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Region</th>\n",
       "      <th>...</th>\n",
       "      <th>Value High</th>\n",
       "      <th>Awarded Date</th>\n",
       "      <th>Awarded Value</th>\n",
       "      <th>Supplier [Name|Address|Ref type|Ref Number|Is SME|Is VCSE]</th>\n",
       "      <th>Supplier's contact name</th>\n",
       "      <th>Contract start date</th>\n",
       "      <th>Contract end date</th>\n",
       "      <th>OJEU Procedure Type</th>\n",
       "      <th>Accelerated Justification</th>\n",
       "      <th>Closing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FSCS SS 031</td>\n",
       "      <td>Contract</td>\n",
       "      <td>FINANCIAL SERVICES COMPENSATION SCHEME LIMITED</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T19:37:46Z</td>\n",
       "      <td>Real-time GBR address verification</td>\n",
       "      <td>Data capture solution that offers real-time GB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28/08/2020</td>\n",
       "      <td>81933.0</td>\n",
       "      <td>[Experian Limited|Sir John Peace Building Expe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/09/2020</td>\n",
       "      <td>31/08/2021</td>\n",
       "      <td>SingleTenderActionNonOJEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tender_248561/886898</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Public Health England</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T17:17:55Z</td>\n",
       "      <td>Purchase of three centrifuges for Pillar 3 Cov...</td>\n",
       "      <td>Contract has been awarded to ThermoFisher Scie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Any region</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/08/2020</td>\n",
       "      <td>28285.0</td>\n",
       "      <td>[ThermoFisher Scientific|Bishop Meadow Road |L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25/08/2020</td>\n",
       "      <td>24/08/2021</td>\n",
       "      <td>SingleTenderActionNonOJEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLL20A14.</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Department for Transport : Department for Tran...</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T15:26:30Z</td>\n",
       "      <td>Provision of Legal Advisers for South Eastern ...</td>\n",
       "      <td>The Department for Transport invites proposals...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom,Isle of Man,Channel Islands</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>[Eversheds Sutherland (International) LLP|One ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/08/2020</td>\n",
       "      <td>23/08/2022</td>\n",
       "      <td>CallOffFromFrameworkAgreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLOSCC001-DN489914-49558633</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Gloucestershire County Council</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T15:08:53Z</td>\n",
       "      <td>C336AB - Churchdown School to Sandhurst</td>\n",
       "      <td>Home to school transport.\\r\\nPassenger transpo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South West</td>\n",
       "      <td>...</td>\n",
       "      <td>63745.0</td>\n",
       "      <td>18/08/2020</td>\n",
       "      <td>63745.0</td>\n",
       "      <td>[FIRST ASSOCIATED TAXIS|GL1 2EZ|NONE||Yes|No]</td>\n",
       "      <td>Mr Rashid Khan</td>\n",
       "      <td>04/09/2020</td>\n",
       "      <td>31/07/2023</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-36</td>\n",
       "      <td>Contract</td>\n",
       "      <td>UNIVERSITY OF WOLVERHAMPTON ENTERPRISE LIMITED</td>\n",
       "      <td>Awarded</td>\n",
       "      <td>2020-09-11T14:27:41Z</td>\n",
       "      <td>20-36 E-Textbook access</td>\n",
       "      <td>The University of Wolverhampton has awarded a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>[KORTEXT LIMITED|26-32 Oxford Road,Suite B, 6t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>10/08/2021</td>\n",
       "      <td>CallOffFromFrameworkAgreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Notice Identifier Notice Type  \\\n",
       "0                  FSCS SS 031    Contract   \n",
       "1         tender_248561/886898    Contract   \n",
       "2                   CCLL20A14.    Contract   \n",
       "3  GLOSCC001-DN489914-49558633    Contract   \n",
       "4                        20-36    Contract   \n",
       "\n",
       "                                   Organisation Name   Status  \\\n",
       "0     FINANCIAL SERVICES COMPENSATION SCHEME LIMITED  Awarded   \n",
       "1                              Public Health England  Awarded   \n",
       "2  Department for Transport : Department for Tran...  Awarded   \n",
       "3                     Gloucestershire County Council  Awarded   \n",
       "4     UNIVERSITY OF WOLVERHAMPTON ENTERPRISE LIMITED  Awarded   \n",
       "\n",
       "         Published Date                                              Title  \\\n",
       "0  2020-09-11T19:37:46Z                 Real-time GBR address verification   \n",
       "1  2020-09-11T17:17:55Z  Purchase of three centrifuges for Pillar 3 Cov...   \n",
       "2  2020-09-11T15:26:30Z  Provision of Legal Advisers for South Eastern ...   \n",
       "3  2020-09-11T15:08:53Z            C336AB - Churchdown School to Sandhurst   \n",
       "4  2020-09-11T14:27:41Z                            20-36 E-Textbook access   \n",
       "\n",
       "                                         Description  Nationwide Postcode  \\\n",
       "0  Data capture solution that offers real-time GB...         NaN      NaN   \n",
       "1  Contract has been awarded to ThermoFisher Scie...         NaN      NaN   \n",
       "2  The Department for Transport invites proposals...         NaN      NaN   \n",
       "3  Home to school transport.\\r\\nPassenger transpo...         NaN      NaN   \n",
       "4  The University of Wolverhampton has awarded a ...         NaN      NaN   \n",
       "\n",
       "                                       Region  ... Value High Awarded Date  \\\n",
       "0                              United Kingdom  ...        NaN   28/08/2020   \n",
       "1                                  Any region  ...        NaN   24/08/2020   \n",
       "2  United Kingdom,Isle of Man,Channel Islands  ...        NaN   13/08/2020   \n",
       "3                                  South West  ...    63745.0   18/08/2020   \n",
       "4                               West Midlands  ...        NaN   11/08/2020   \n",
       "\n",
       "  Awarded Value Supplier [Name|Address|Ref type|Ref Number|Is SME|Is VCSE]  \\\n",
       "0       81933.0  [Experian Limited|Sir John Peace Building Expe...           \n",
       "1       28285.0  [ThermoFisher Scientific|Bishop Meadow Road |L...           \n",
       "2      350000.0  [Eversheds Sutherland (International) LLP|One ...           \n",
       "3       63745.0      [FIRST ASSOCIATED TAXIS|GL1 2EZ|NONE||Yes|No]           \n",
       "4      300000.0  [KORTEXT LIMITED|26-32 Oxford Road,Suite B, 6t...           \n",
       "\n",
       "  Supplier's contact name Contract start date Contract end date  \\\n",
       "0                     NaN          01/09/2020        31/08/2021   \n",
       "1                     NaN          25/08/2020        24/08/2021   \n",
       "2                     NaN          24/08/2020        23/08/2022   \n",
       "3          Mr Rashid Khan          04/09/2020        31/07/2023   \n",
       "4                     NaN          11/08/2020        10/08/2021   \n",
       "\n",
       "              OJEU Procedure Type Accelerated Justification Closing Time  \n",
       "0      SingleTenderActionNonOJEU                        NaN        00:00  \n",
       "1      SingleTenderActionNonOJEU                        NaN        12:00  \n",
       "2  CallOffFromFrameworkAgreement                        NaN        11:00  \n",
       "3                          Other                        NaN        23:59  \n",
       "4  CallOffFromFrameworkAgreement                        NaN        09:00  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ftfy # amazing text cleaning for decode issues.. TO INVESTIGATE\n",
    "#from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ngram function  \n",
    "The below function is used as both a cleaning function of the text data as well as a way of splitting text into ngrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    #string = fix_text(string) # fix text encoding issues\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower() #make lower case\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "    string = re.sub(rx, '', string) #remove the list of chars defined above\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single space\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The great thing about the tf-idf implementation in Scikit is that it allows for a custom function to be added to it. We can therefore add-in the function we have created above and build the matrix in just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_field = df['Organisation Name'].unique()\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(target_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we are going to find similarities using the cosine function  \n",
    "While you could use the cosine similarity function from Scikit here, it is not the most efficient way of finding close matches as it returns a closeness score for every item in the dataset for each sample. Instead, we are going to use a faster implementation of this which can be found here:\n",
    "https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similarity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similarity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similarity': similarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFTIMED: 0.0022437572479248047\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.85)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df = get_matches_df(matches, target_field, top=100)\n",
    "matches_df = matches_df[matches_df['similarity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Department for Transport : Department for Tran...</td>\n",
       "      <td>Department For Transport</td>\n",
       "      <td>0.974240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Department for Transport : Department for Tran...</td>\n",
       "      <td>THE DEPARTMENT FOR TRANSPORT</td>\n",
       "      <td>0.898558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MINISTRY OF HOUSING, COMMUNITIES &amp; LOCAL GOVER...</td>\n",
       "      <td>Ministry of Housing, Communities &amp; Local Gover...</td>\n",
       "      <td>0.989177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Business Energy and Industrial Strategy</td>\n",
       "      <td>Department for Business Energy &amp; Industrial St...</td>\n",
       "      <td>0.890011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>THE DEPARTMENT FOR TRANSPORT</td>\n",
       "      <td>Department For Transport</td>\n",
       "      <td>0.922317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            left_side  \\\n",
       "3   Department for Transport : Department for Tran...   \n",
       "4   Department for Transport : Department for Tran...   \n",
       "9   MINISTRY OF HOUSING, COMMUNITIES & LOCAL GOVER...   \n",
       "30            Business Energy and Industrial Strategy   \n",
       "34                       THE DEPARTMENT FOR TRANSPORT   \n",
       "\n",
       "                                           right_side  similarity  \n",
       "3                            Department For Transport    0.974240  \n",
       "4                        THE DEPARTMENT FOR TRANSPORT    0.898558  \n",
       "9   Ministry of Housing, Communities & Local Gover...    0.989177  \n",
       "30  Department for Business Energy & Industrial St...    0.890011  \n",
       "34                           Department For Transport    0.922317  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record linkage and a different approach\n",
    "\n",
    "If we want to use this technique to match against another data source then we can recycle the majority of our code. In the below section we will see how this is achieved and also use the K Nearest Neighbour algorithm as an alternative closeness measure.\n",
    "The dataset we would like to join on is a set of ‘clean’ organisation names created by the Office for National Statistics (ONS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "clean_org_names = pd.read_excel('Gov Orgs ONS.xlsx')\n",
    "clean_org_names = clean_org_names.iloc[:, 0:6]\n",
    "org_name_clean = clean_org_names['Institutions'].unique()\n",
    "print('Vectorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(org_name_clean)\n",
    "print('Vectorizing completed...')\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "org_column = 'buyer' #column to match against in the messy data\n",
    "unique_org = set(names[org_column].values) # set used for increased performance\n",
    "###matching query:\n",
    "def getNearestN(query):\n",
    "    queryTFIDF_ = vectorizer.transform(query)\n",
    "    distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "    return distances, indices\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(unique_org)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)\n",
    "unique_org = list(unique_org) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2), clean_org_names.values[j][0][0],unique_org[i]]\n",
    "  matches.append(temp)\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
