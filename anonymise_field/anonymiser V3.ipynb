{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anonymised.csv    available_ids.csv translation.csv\n",
      "anonymiser.ipynb  input.csv         translation2.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "def create_test_input_table(number_of_transactions, number_of_ids, types_of_transactions):\n",
    "    d = []\n",
    "    fake = Faker() \n",
    "    name_list=[]\n",
    "    for i in range(0,number_of_ids):\n",
    "        name_list.append(fake.name())\n",
    "    print (\"Created a list of names of len:\" + str(len(name_list)))\n",
    "    for i in range(0, number_of_transactions):\n",
    "        id= random.randint(1,number_of_ids)\n",
    "        name =name_list[id-1]\n",
    "        transact= random.randint(1,types_of_transactions)\n",
    "        d.append({'ID': id ,'Name': name, 'Transact': transact })\n",
    "    print(len(d))\n",
    "    df= pd.DataFrame(d)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a list of names of len:10\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "df= create_test_input_table(1000,10,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to delete any column by index from a dataframe\n",
    "#df= df.drop(df.columns[0],1)\n",
    "#df  (or use inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_translation_table(file_path):\n",
    "    L2S={}\n",
    "    S2L={} \n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        r = csv.reader(csvfile, delimiter=',', quotechar='\"',)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            if row[0] in L2S.keys(): \n",
    "                print(\"Duplicate id value detected:\" + str(row[0]))\n",
    "            else:\n",
    "                L2S[row[0]]=row[1]\n",
    "            if row[1] in S2L.keys():\n",
    "                print(\"Duplicate syn value detected:\" + str(row[1]))\n",
    "            else:\n",
    "                S2L[row[1]]=row[0]\n",
    "                \n",
    "    return L2S, S2L\n",
    "\n",
    "\n",
    "def save_translation_table(file_path,L2S):\n",
    "    with open(file_path,'w') as f:\n",
    "        w = csv.writer(f, delimiter=',', quotechar='\"',quoting=csv.QUOTE_MINIMAL) \n",
    "        w.writerow(['id','syn'])\n",
    "        w.writerows(L2S.items())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads the translation table, which is a plain CSV\n",
    "Check out the quoting and delimiter if you wish to work with text IDs\n",
    "It does check if there is any duplicate. \n",
    "Because it is a transation table, there should be NO duplicates either way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_syn_range(start,end):\n",
    "    l = list(range(start,end+1))\n",
    "    l = [str(i) for i in l]\n",
    "    return l\n",
    "\n",
    "def load_available_syns(file_path):\n",
    "    l=[]\n",
    "    with open(file_path , 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip() #or some other preprocessing\n",
    "            l.append(line) #storing everything in memory!\n",
    "    return l\n",
    "def save_available_syns(file_path, list_available):\n",
    "    with open(file_path , 'w') as f:\n",
    "        f.write(\"syn\\n\")\n",
    "        for item in list_available:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "def check_available_syns(list_available, S2L, L2S, cleanup_used= False):\n",
    "    error_count=0\n",
    "    for n in S2L.keys():\n",
    "        if n in list_available:          \n",
    "            error_count += 1\n",
    "            loc= list_available.index(n)\n",
    "            print(str(n)+\" was found in the list_available list\" + str(loc))\n",
    "            if cleanup_used==True:\n",
    "                list_available.pop(loc)\n",
    "                print (\"Removed from list in memory\")\n",
    "    print (\"Errors found checking S2L:\" + str(error_count))\n",
    "    error_count=0\n",
    "    for n in L2S.values():\n",
    "        if n in list_available:          \n",
    "            error_count += 1\n",
    "            loc= list_available.index(n)\n",
    "            print(str(n)+\" was found in the list_available list\" + str(loc))\n",
    "            if cleanup_used==True:\n",
    "                list_available.pop(loc)\n",
    "                print (\"Removed from list in memory\")\n",
    "    print (\"Errors found checking L2S:\" + str(error_count))\n",
    "\n",
    "\n",
    "def expand_available_syns(list_available,  S2L, start, end):\n",
    "    new_range= list(range(start,end+1))\n",
    "    for n in new_range:\n",
    "        if  str(n) not in S2L.keys():\n",
    "            list_available.append(str(n))\n",
    "    return list_available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_syn_to_live(live_value,list_available,L2S,S2L):\n",
    "    if live_value in L2S.keys():\n",
    "        return L2S[live_value]\n",
    "    else:\n",
    "        if len(list_available)>0:\n",
    "            new_syn=list_available.pop(0)\n",
    "            L2S[live_value]=new_syn\n",
    "            S2L[new_syn]=live_value\n",
    "        else:\n",
    "            print(\"Ran out of available ids\")\n",
    "            new_syn=\"\"\n",
    "        return new_syn\n",
    "\n",
    "def anonymise(df, column_name, list_available, L2S, S2L ):\n",
    "    for i, r in df.iterrows():\n",
    "        live_value= r[column_name]\n",
    "        syn_value = assign_syn_to_live(live_value,list_available,L2S,S2L)\n",
    "        df.at[i, column_name]= syn_value\n",
    "def de_anonymise(df,column_name,list_available,S2L):\n",
    "    for i, r in df.iterrows():\n",
    "        syn_value= r[column_name]\n",
    "        live_value= S2L[syn_value]\n",
    "        df.at[i,column_name]= live_value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a list of names of len:100\n",
      "1000\n",
      "     ID                   Name  Transact\n",
      "0    48         Barbara Hodges         2\n",
      "1    86            Warren Hunt         4\n",
      "2    34            Lori Turner         1\n",
      "3    76             Chase Soto         8\n",
      "4    72         Cameron Walker         8\n",
      "5    36        Kristine Larsen         7\n",
      "6    51          Thomas Flores         3\n",
      "7    90          Tanya Ramirez         2\n",
      "8    93        Jonathan Miller         6\n",
      "9    16            Karen Banks         6\n",
      "10   19     Valerie Richardson         2\n",
      "11   80      Dr. Gerald Murphy         5\n",
      "12   36        Kristine Larsen         4\n",
      "13   56            Michele Lee         4\n",
      "14   33         Gary Davis DDS         5\n",
      "15   21            Thomas Mays         4\n",
      "16   73       Stephen Saunders         1\n",
      "17   79     Christopher Hudson         2\n",
      "18   71           Kirk Buckley         2\n",
      "19   58        Nicholas French         6\n",
      "20   65          Melissa Smith         6\n",
      "21   10            Mark Jensen        10\n",
      "22   88            Dwayne Cook         5\n",
      "23   36        Kristine Larsen         1\n",
      "24   70           Stephen Webb         8\n",
      "25   25    Jennifer Washington         8\n",
      "26   23          Margaret Berg         8\n",
      "27   63      Johnathan Russell         5\n",
      "28   35      Cassandra Pearson         9\n",
      "29   26           Julia Watson         8\n",
      "..   ..                    ...       ...\n",
      "970  20      Kathleen Thompson         5\n",
      "971  50           Cheryl Brown         1\n",
      "972  93        Jonathan Miller         1\n",
      "973  44            Bryce Smith        10\n",
      "974  21            Thomas Mays         6\n",
      "975  34            Lori Turner         1\n",
      "976  68           Sarah Graham        10\n",
      "977  40          Joshua Fuller         3\n",
      "978   8          Melissa Perez         8\n",
      "979  25    Jennifer Washington         1\n",
      "980  86            Warren Hunt         1\n",
      "981   3              Lisa Cruz         4\n",
      "982  15        Jessica Whitney         6\n",
      "983  75         Destiny Jordan         1\n",
      "984  57        Jaime Wilkerson        10\n",
      "985  59            Justin Ford         5\n",
      "986   5  Mr. Tracy Fuentes PhD        10\n",
      "987   7          Kristen Solis         4\n",
      "988  21            Thomas Mays         4\n",
      "989   6           Sheila Smith         8\n",
      "990  84           Donna Arnold        10\n",
      "991   5  Mr. Tracy Fuentes PhD         8\n",
      "992  61          Tammy Johnson         6\n",
      "993  95            Erin Morgan         3\n",
      "994  70           Stephen Webb         4\n",
      "995  62           Steven Weeks         8\n",
      "996  45         Christine Koch         4\n",
      "997  86            Warren Hunt         7\n",
      "998  19     Valerie Richardson         8\n",
      "999  90          Tanya Ramirez         3\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "CPU times: user 60.4 ms, sys: 21.3 ms, total: 81.7 ms\n",
      "Wall time: 82.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "L2S={}\n",
    "S2L={}\n",
    "df= create_test_input_table(1000,100,10)\n",
    "list_available=create_syn_range(1,200)\n",
    "len(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anonymise(df,\"ID\",list_available,L2S,S2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Barbara Hodges</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Warren Hunt</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lori Turner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chase Soto</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cameron Walker</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Kristine Larsen</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Thomas Flores</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tanya Ramirez</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Jonathan Miller</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Karen Banks</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Valerie Richardson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Dr. Gerald Murphy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>Kristine Larsen</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Michele Lee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Gary Davis DDS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Thomas Mays</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Stephen Saunders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Christopher Hudson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Kirk Buckley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Nicholas French</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Melissa Smith</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Mark Jensen</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Dwayne Cook</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>Kristine Larsen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>Stephen Webb</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>Jennifer Washington</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>Margaret Berg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>Johnathan Russell</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>Cassandra Pearson</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>Julia Watson</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>100</td>\n",
       "      <td>Kathleen Thompson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>84</td>\n",
       "      <td>Cheryl Brown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>9</td>\n",
       "      <td>Jonathan Miller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>58</td>\n",
       "      <td>Bryce Smith</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>15</td>\n",
       "      <td>Thomas Mays</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>3</td>\n",
       "      <td>Lori Turner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>63</td>\n",
       "      <td>Sarah Graham</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>52</td>\n",
       "      <td>Joshua Fuller</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>54</td>\n",
       "      <td>Melissa Perez</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>24</td>\n",
       "      <td>Jennifer Washington</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2</td>\n",
       "      <td>Warren Hunt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>35</td>\n",
       "      <td>Lisa Cruz</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>97</td>\n",
       "      <td>Jessica Whitney</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>68</td>\n",
       "      <td>Destiny Jordan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>82</td>\n",
       "      <td>Jaime Wilkerson</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>74</td>\n",
       "      <td>Justin Ford</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>94</td>\n",
       "      <td>Mr. Tracy Fuentes PhD</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>40</td>\n",
       "      <td>Kristen Solis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>15</td>\n",
       "      <td>Thomas Mays</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>56</td>\n",
       "      <td>Sheila Smith</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>59</td>\n",
       "      <td>Donna Arnold</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>94</td>\n",
       "      <td>Mr. Tracy Fuentes PhD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>53</td>\n",
       "      <td>Tammy Johnson</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>77</td>\n",
       "      <td>Erin Morgan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>23</td>\n",
       "      <td>Stephen Webb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>30</td>\n",
       "      <td>Steven Weeks</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>92</td>\n",
       "      <td>Christine Koch</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "      <td>Warren Hunt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>11</td>\n",
       "      <td>Valerie Richardson</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>8</td>\n",
       "      <td>Tanya Ramirez</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                   Name  Transact\n",
       "0      1         Barbara Hodges         2\n",
       "1      2            Warren Hunt         4\n",
       "2      3            Lori Turner         1\n",
       "3      4             Chase Soto         8\n",
       "4      5         Cameron Walker         8\n",
       "5      6        Kristine Larsen         7\n",
       "6      7          Thomas Flores         3\n",
       "7      8          Tanya Ramirez         2\n",
       "8      9        Jonathan Miller         6\n",
       "9     10            Karen Banks         6\n",
       "10    11     Valerie Richardson         2\n",
       "11    12      Dr. Gerald Murphy         5\n",
       "12     6        Kristine Larsen         4\n",
       "13    13            Michele Lee         4\n",
       "14    14         Gary Davis DDS         5\n",
       "15    15            Thomas Mays         4\n",
       "16    16       Stephen Saunders         1\n",
       "17    17     Christopher Hudson         2\n",
       "18    18           Kirk Buckley         2\n",
       "19    19        Nicholas French         6\n",
       "20    20          Melissa Smith         6\n",
       "21    21            Mark Jensen        10\n",
       "22    22            Dwayne Cook         5\n",
       "23     6        Kristine Larsen         1\n",
       "24    23           Stephen Webb         8\n",
       "25    24    Jennifer Washington         8\n",
       "26    25          Margaret Berg         8\n",
       "27    26      Johnathan Russell         5\n",
       "28    27      Cassandra Pearson         9\n",
       "29    28           Julia Watson         8\n",
       "..   ...                    ...       ...\n",
       "970  100      Kathleen Thompson         5\n",
       "971   84           Cheryl Brown         1\n",
       "972    9        Jonathan Miller         1\n",
       "973   58            Bryce Smith        10\n",
       "974   15            Thomas Mays         6\n",
       "975    3            Lori Turner         1\n",
       "976   63           Sarah Graham        10\n",
       "977   52          Joshua Fuller         3\n",
       "978   54          Melissa Perez         8\n",
       "979   24    Jennifer Washington         1\n",
       "980    2            Warren Hunt         1\n",
       "981   35              Lisa Cruz         4\n",
       "982   97        Jessica Whitney         6\n",
       "983   68         Destiny Jordan         1\n",
       "984   82        Jaime Wilkerson        10\n",
       "985   74            Justin Ford         5\n",
       "986   94  Mr. Tracy Fuentes PhD        10\n",
       "987   40          Kristen Solis         4\n",
       "988   15            Thomas Mays         4\n",
       "989   56           Sheila Smith         8\n",
       "990   59           Donna Arnold        10\n",
       "991   94  Mr. Tracy Fuentes PhD         8\n",
       "992   53          Tammy Johnson         6\n",
       "993   77            Erin Morgan         3\n",
       "994   23           Stephen Webb         4\n",
       "995   30           Steven Weeks         8\n",
       "996   92         Christine Koch         4\n",
       "997    2            Warren Hunt         7\n",
       "998   11     Valerie Richardson         8\n",
       "999    8          Tanya Ramirez         3\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-421-d4c02276ddf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mde_anonymise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_available\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS2L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-415-4ba3b69cbbbf>\u001b[0m in \u001b[0;36mde_anonymise\u001b[0;34m(df, column_name, list_available, S2L)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msyn_value\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlive_value\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mS2L\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msyn_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlive_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "de_anonymise(df,\"ID\",list_available,S2L)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_csv( \"anonymised.csv\", index=False , sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for a small scale translation with existing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df is the dataframe with the data to anonymise. We use a plain csv loader that comes with Pandas.\n",
    "Depending on the format you need to beef up this command to load or otherwise process the data into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We load the translation table, available keys and input file\")\n",
    "L2S , S2L = load_translation_table('translation.csv')\n",
    "df= pd.read_csv('input.csv')\n",
    "list_available=load_available_slots(\"available_ids.csv\")\n",
    "\n",
    "print (L2S.keys())\n",
    "print (S2L.keys())\n",
    "print (list_available)\n",
    "\n",
    "print(\"Now We try to save the table and load the table again\")\n",
    "save_translation_table(\"translation.csv\", L2S)\n",
    "L2S , S2L = load_translation_table('translation.csv')\n",
    "print (L2S.keys())\n",
    "print (S2L.keys())\n",
    "\n",
    "\n",
    "print (\"Now we will erase the the list_available\")\n",
    "list_available= create_syn_range(1,10)\n",
    "print (\"Created list with \" + str(len(list_available) + \" elements\")\n",
    "\n",
    "expand_available_syns(list_available, S2L,1,40)\n",
    "save_available_syns(\"available_ids.csv\", list_available)\n",
    "\n",
    "\n",
    "check_available_syns(list_available, S2L, L2S, True)\n",
    "print (\"Current list of available Syns:\")\n",
    "print (list_available)\n",
    "\n",
    "new_syn, L2S, S2L = assign_syn_to_live(7777, list_available, L2S, S2L)\n",
    "print(new_syn)\n",
    "print(list_available)\n",
    "print (L2S)\n",
    "print (S2L)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
