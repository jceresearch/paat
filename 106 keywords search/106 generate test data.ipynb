{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wikipedia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51a6ea507ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m \u001b[0;31m#Regular expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wikipedia'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import re #Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path('./test_data').mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path('./output').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['News analytics',\n",
       " 'Audit trail',\n",
       " 'The Audit',\n",
       " 'Entity-level controls',\n",
       " 'Web analytics',\n",
       " 'Audit working papers',\n",
       " 'Certified Internal Control Auditors',\n",
       " 'Business analytics',\n",
       " 'Learning analytics',\n",
       " 'Financial audit',\n",
       " 'Internal audit',\n",
       " 'Internal control',\n",
       " 'Controlled internal drug release',\n",
       " 'Predictive analytics',\n",
       " 'Audit (disambiguation)',\n",
       " 'Audit committee',\n",
       " 'Analytics',\n",
       " 'Audit plan',\n",
       " 'Committee of Sponsoring Organizations of the Treadway Commission',\n",
       " 'Institute of Internal Auditors',\n",
       " 'Verisk Analytics',\n",
       " 'Google Analytics',\n",
       " 'Analytic',\n",
       " 'Locus of control',\n",
       " 'Information technology controls',\n",
       " 'Audit',\n",
       " 'Audit evidence',\n",
       " 'Prescriptive analytics',\n",
       " 'Internal model (motor control)',\n",
       " 'Information technology audit']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords=[\"audit\",\"COSO commmittee\", \"internal control\",\"analytics\"]\n",
    "results=[]\n",
    "for k in keywords:\n",
    "    r = wikipedia.search(k)\n",
    "    results.extend(r)\n",
    "results= list(set(results))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News analytics\n",
      "Audit trail\n",
      "The Audit\n",
      "Entity-level controls\n",
      "Web analytics\n",
      "Audit working papers\n",
      "Reached the cap for downloading articles\n"
     ]
    }
   ],
   "source": [
    "articles=[]\n",
    "cap=5 #number of articles to retrieve in total\n",
    "n=0\n",
    "for t in results:  \n",
    "    print(t)\n",
    "    try:\n",
    "        wiki = wikipedia.page(t)\n",
    "          # Extract the plain text content of the page, excluding images, tables, and other data.\n",
    "        text = wiki.content\n",
    "        # Replace '==' with '' (an empty string)\n",
    "        text = text.replace('==', '')\n",
    "        text = text.replace('@', '')\n",
    "        # Replace '\\n' (a new line) with '' & end the string at $1000.\n",
    "        text = text.replace('\\n', '')[:-12]\n",
    "        \n",
    "        articles.append([t, text,wiki.url])\n",
    "        n=n+1 # counting the pages received\n",
    "        if n>cap:\n",
    "            print(\"Reached the cap for downloading articles\")\n",
    "            break\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        options= e.options\n",
    "        for o in options:\n",
    "            if o not in results:\n",
    "                results.append(o)\n",
    "    except Exception:\n",
    "        print(\"Other error while trying to read page: \"+ t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    alphabets= \"([A-Za-z])\"\n",
    "    suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "    starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "    acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "    prefixes = \"(Mr|St|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|Mt)[.]\"\n",
    "    websites = \"[.](com|net|org|io|gov|me|edu|co|uk)\"\n",
    "    digits = \"([0-9])\"\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\"<stop> \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(\"(\\w*)[.](\\w+@)\",\"\\\\1<prd>\\\\2\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"<excl>\\\"\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"<quest>\\\"\")\n",
    "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
    "    if \"e.g.\" in text: text = text.replace(\"e.g.\",\"e<prd>g<prd>\") \n",
    "    if \"i.e.\" in text: text = text.replace(\"i.e.\",\"i<prd>e<prd>\")\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    text = text.replace(\"<excl>\",\"!\")\n",
    "    text = text.replace(\"<quest>\",\"?\")\n",
    "    text = text.replace(\"<stop><stop>\",\"<stop>\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    #sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4247"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=[]\n",
    "page_title=[]\n",
    "page_url=[]\n",
    "for a in articles:\n",
    "    s=split_into_sentences(a[1])\n",
    "    t= [a[0]] * len(s)\n",
    "    u= [a[2]] * len(s)\n",
    "    sentences.extend(s)\n",
    "    page_title.extend(t)\n",
    "    page_url.extend(u)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_title</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>page_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>News analytics</td>\n",
       "      <td>News analysis refers to the measurement of the...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News_analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>News analytics</td>\n",
       "      <td>Some of these attributes are: sentiment, relev...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News_analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>News analytics</td>\n",
       "      <td>Expressing news stories as numbers and metadat...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News_analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>News analytics</td>\n",
       "      <td>This data is often used in financial markets a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News_analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>News analytics</td>\n",
       "      <td>News analytics are usually derived through aut...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/News_analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_title                                  article_sentences  \\\n",
       "0  News analytics  News analysis refers to the measurement of the...   \n",
       "1  News analytics  Some of these attributes are: sentiment, relev...   \n",
       "2  News analytics  Expressing news stories as numbers and metadat...   \n",
       "3  News analytics  This data is often used in financial markets a...   \n",
       "4  News analytics  News analytics are usually derived through aut...   \n",
       "\n",
       "                                       page_url  \n",
       "0  https://en.wikipedia.org/wiki/News_analytics  \n",
       "1  https://en.wikipedia.org/wiki/News_analytics  \n",
       "2  https://en.wikipedia.org/wiki/News_analytics  \n",
       "3  https://en.wikipedia.org/wiki/News_analytics  \n",
       "4  https://en.wikipedia.org/wiki/News_analytics  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat=list(zip(page_title,sentences,page_url))\n",
    "df = pd.DataFrame(concat,columns=['page_title','article_sentences','page_url'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4247, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./test_data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
