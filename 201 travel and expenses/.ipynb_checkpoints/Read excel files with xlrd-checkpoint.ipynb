{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\dev\\ipython\\read_excel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "import xlrd  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\dev\\ipython\\read_excel\\testdata\\test2.xlsx\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "xlsfile=os.getcwd() + r'\\testdata\\test2.xlsx'\n",
    "print xlsfile\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "ts= strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "book = xlrd.open_workbook(xlsfile)\n",
    "n= book.nsheets\n",
    "print n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Processing sheet Expenses1\n",
      "8 700000\n",
      "Name\n",
      "Processing sheet Expenses2\n",
      "8 800000\n"
     ]
    }
   ],
   "source": [
    "input_frames=[]\n",
    "for x in range(0, n-1):\n",
    "    sh=book.sheet_by_index(x)\n",
    "    cellA1= sh.cell_value(0,0)\n",
    "    print cellA1\n",
    "    print \"Processing sheet \" + book.sheet_names()[x]\n",
    "    if cellA1==\"Name\":\n",
    "         \n",
    "        \n",
    "        num_cols = sh.ncols   # Number of columns\n",
    "        num_rows = sh.nrows\n",
    "        print num_cols, num_rows\n",
    "        data=[]\n",
    "        for row_idx in range(0, num_rows):    # Iterate through rows use sh.nrows for all rows    \n",
    "            row_data=[]\n",
    "            for col_idx in range(0, num_cols-1):  # Iterate through columns\n",
    "                \n",
    "                \n",
    "                \n",
    "                cell_obj = sh.cell(row_idx, col_idx)  # Get cell object by row, col\n",
    "                cell_value= cell_obj.value\n",
    "                cell_type = sh.cell_type(row_idx, col_idx)\n",
    "                \n",
    "                if cell_type == xlrd.XL_CELL_DATE:\n",
    "                    get_col= xlrd.xldate.xldate_as_datetime (cell_value, book.datemode)\n",
    "                elif cell_type == xlrd.XL_CELL_NUMBER:\n",
    "                    get_col = int(cell_value)\n",
    "                else:\n",
    "                    get_col = unicode(cell_value)\n",
    "               \n",
    "                row_data.append(get_col)\n",
    "            data.append(row_data)\n",
    "\n",
    "        frame=pd.DataFrame(data[1:],columns=data[0])\n",
    "        #We add here a column for the source sheet and a timestamp\n",
    "        frame[\"SourceSheet\"]=sh.name\n",
    "        frame[\"Timestamp\"]= ts\n",
    "        input_frames.append (frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 records\n",
      "      Name  Expenses       Date  \\\n",
      "0     Juan       351 2015-11-03   \n",
      "1  Aleksei      3134 2015-11-07   \n",
      "2     Arne      2619 2015-04-06   \n",
      "3    Hiten      2654 2015-10-17   \n",
      "4   Najwan      2905 2015-05-31   \n",
      "5  Aleksei      1322 2015-05-10   \n",
      "6      Guy       199 2015-12-10   \n",
      "7    Sarah       964 2015-12-18   \n",
      "8   Vishal      3123 2015-10-10   \n",
      "9     Amit      3198 2015-08-04   \n",
      "\n",
      "                                         Description Approval date_approval  \\\n",
      "0  m nonumy civibus. Eum possim tincidunt necessi...     fese    2015-11-30   \n",
      "1   suas viderer alterum an vim. Ei mucius theoph...     arty    2015-12-06   \n",
      "2  onumy ut quo, mei ei adhuc erant dicant. Ex vi...     hyde    2015-05-06   \n",
      "3  ulis deseruisse pro id, dico accusamus te mei....     wart    2015-11-16   \n",
      "4  mus te mei. Ad diam modus mea. Soleat qualisqu...     dewa    2015-06-21   \n",
      "5  ro primis feugiat id, conceptam reprimique lib...     erty    2015-05-28   \n",
      "6   ignota vivendum cum, ea possim reprimique cum...     rete    2015-12-27   \n",
      "7  ut. Sit dicant scripserit ne, iudico forensibu...     usde    2016-01-03   \n",
      "8  atibus at. Pro primis feugiat id, conceptam re...     tesi    2015-11-02   \n",
      "9  m ius, pro id diam nonumy civibus. Eum possim ...     horu    2015-08-20   \n",
      "\n",
      "    Date_pay SourceSheet            Timestamp  \n",
      "0 2015-12-17   Expenses1  2015-12-23 14:15:29  \n",
      "1 2015-12-21   Expenses1  2015-12-23 14:15:29  \n",
      "2 2015-05-24   Expenses1  2015-12-23 14:15:29  \n",
      "3 2015-12-02   Expenses1  2015-12-23 14:15:29  \n",
      "4 2015-07-11   Expenses1  2015-12-23 14:15:29  \n",
      "5 2015-06-16   Expenses1  2015-12-23 14:15:29  \n",
      "6 2016-01-16   Expenses1  2015-12-23 14:15:29  \n",
      "7 2016-01-21   Expenses1  2015-12-23 14:15:29  \n",
      "8 2015-11-19   Expenses1  2015-12-23 14:15:29  \n",
      "9 2015-09-09   Expenses1  2015-12-23 14:15:29  \n"
     ]
    }
   ],
   "source": [
    "#Here we concatenate the multiple dataframes we created , one per sheet\n",
    "# the ignore_index option is so that the main index is recreated so each row will have a unique ID \n",
    "if len(input_frames) >0:   \n",
    "    df = pd.concat(input_frames, ignore_index=True)\n",
    "print \"Top 10 records\"\n",
    "print df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count (non null):\n",
      "Name             1499998\n",
      "Expenses         1499998\n",
      "Date             1499998\n",
      "Description      1499998\n",
      "Approval         1499998\n",
      "date_approval    1499998\n",
      "Date_pay         1499998\n",
      "SourceSheet      1499998\n",
      "Timestamp        1499998\n",
      "dtype: int64\n",
      "Min value:15000\n",
      "Max value:-444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name                     object\n",
       "Expenses                  int64\n",
       "Date             datetime64[ns]\n",
       "Description              object\n",
       "Approval                 object\n",
       "date_approval    datetime64[ns]\n",
       "Date_pay         datetime64[ns]\n",
       "SourceSheet              object\n",
       "Timestamp                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Record count (non null):\"\n",
    "print df.count()\n",
    "print \"Min value:\"+ str(df[\"Expenses\"].max())\n",
    "print \"Max value:\" + str(df[\"Expenses\"].min())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is an optional command to set the index, if we had some column that can act as index, otherwise, we get the default row number  on import\n",
    "#df.set_index(\"Name\", inplace=True, drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "            Name  Expenses       Date  \\\n",
      "486090    Joanna        39 2015-08-13   \n",
      "1418995  Stephan        40 2015-04-27   \n",
      "1055103  Aleksei        54 2015-10-19   \n",
      "105866   Stephen        63 2015-07-22   \n",
      "1323067     Arne        64 2015-02-10   \n",
      "1175076  Stephen        79 2015-08-26   \n",
      "677047     Sarah        82 2015-05-17   \n",
      "446914     Anshu        83 2015-01-13   \n",
      "1207469   Vishal        85 2015-03-07   \n",
      "825530    Roshan       104 2015-04-08   \n",
      "1344971  Stephen       106 2015-01-11   \n",
      "458323    Vishal       109 2015-11-14   \n",
      "609535     Sarah       115 2015-03-21   \n",
      "234363    Joanna       119 2015-11-27   \n",
      "1142575    Robin       121 2015-03-02   \n",
      "1418622     Arne       136 2015-06-24   \n",
      "1397773   Roshan       136 2015-07-18   \n",
      "791716     Sarah       148 2015-03-15   \n",
      "17648        Guy       165 2015-01-02   \n",
      "787968     Hiten       183 2015-10-25   \n",
      "1451220     Arne       206 2016-01-01   \n",
      "379371     Sarah       226 2015-03-19   \n",
      "212852      Amit       233 2015-07-04   \n",
      "862208     Sarah       234 2015-07-29   \n",
      "1471752    Robin       246 2015-08-09   \n",
      "510710      Juan       257 2015-10-03   \n",
      "1351641   Vishal       268 2015-05-25   \n",
      "610749      Amit       282 2015-12-23   \n",
      "1004322    Hiten       300 2015-10-27   \n",
      "756375     Sarah       301 2015-12-22   \n",
      "...          ...       ...        ...   \n",
      "177672       Guy       630 2015-05-29   \n",
      "418250     Robin       637 2015-05-28   \n",
      "101168      Amit       639 2015-02-16   \n",
      "158349   Stephen       662 2015-11-01   \n",
      "293833     Sarah       689 2015-12-29   \n",
      "323996   Aleksei       698 2015-05-13   \n",
      "263627    Joanna       700 2015-06-25   \n",
      "274966     Craig       707 2015-11-14   \n",
      "1261875  Matthew       707 2015-11-12   \n",
      "173172   Stephan       748 2015-04-30   \n",
      "748501   Matthew       753 2015-08-09   \n",
      "945418    Roshan       755 2015-12-20   \n",
      "87963      Robin       762 2015-10-03   \n",
      "1217151   Najwan       766 2015-10-01   \n",
      "1447457   Vishal       793 2015-06-10   \n",
      "316800      Paul       794 2015-01-03   \n",
      "1303535  Stephan       801 2015-03-28   \n",
      "379878   Aleksei       811 2015-07-28   \n",
      "663552       Guy       812 2015-06-13   \n",
      "371665      Juan       816 2015-10-06   \n",
      "321782     Hiten       818 2015-11-22   \n",
      "798588     Sarah       838 2015-02-19   \n",
      "185178   Stephen       839 2015-05-12   \n",
      "246903     Anshu       841 2015-07-01   \n",
      "699115     Sarah       844 2015-05-11   \n",
      "308661     Hiten       855 2015-08-29   \n",
      "1471163    Robin       860 2015-04-23   \n",
      "652645   Aleksei       879 2015-08-27   \n",
      "1435444    Robin       886 2015-04-17   \n",
      "625387    Vishal       889 2015-01-18   \n",
      "\n",
      "                                               Description Approval  \\\n",
      "486090    te lucilius assentior. Eum et erant utamur. T...     sewe   \n",
      "1418995   te lucilius assentior. Eum et erant utamur. T...     tefe   \n",
      "1055103  ntior. Eum et erant utamur. Te aperiri sadipsc...     etes   \n",
      "105866    reprimique liberavisse ei has, ut duo prima d...     ydet   \n",
      "1323067  vituperatoribus te. Magna nostrum pericula an ...     rtym   \n",
      "1175076  ceptam reprimique liberavisse ei has, ut duo p...     rtyp   \n",
      "677047   m dolor sit amet, eu sint antiopam ius, pro id...     rtym   \n",
      "446914   inati cum. Menandri dissentiunt pri ad. Harum ...     etho   \n",
      "1207469  lis deseruisse pro id, dico accusamus te mei. ...     leth   \n",
      "825530    vix, ad choro ignota vivendum cum, ea possim ...     etho   \n",
      "1344971  eruisse pro id, dico accusamus te mei. Ad diam...     sewe   \n",
      "458323   lutpat complectitur ut. Sit dicant scripserit ...     erty   \n",
      "609535   rentur ius ei, pri erant dolorem vituperatorib...     sewe   \n",
      "234363   onderum prodesset pri. Quas nonumy ut quo, mei...     ymus   \n",
      "1142575  um possim tincidunt necessitatibus at. Pro pri...     yple   \n",
      "1418622  vendum cum, ea possim reprimique cum. An suas ...     etes   \n",
      "1397773  uo, suas viderer alterum an vim. Ei mucius the...     fese   \n",
      "791716   . Ad diam modus mea. Soleat qualisque has cu, ...     usde   \n",
      "17648    ea possim reprimique cum. An suas illud nomina...     idur   \n",
      "787968   entur ius ei, pri erant dolorem vituperatoribu...     tefe   \n",
      "1451220  umo ocurreret duo ne, est facer dictas mediocr...     ethe   \n",
      "379371   conceptam reprimique liberavisse ei has, ut du...     ethe   \n",
      "212852   or sit amet, eu sint antiopam ius, pro id diam...     ewee   \n",
      "862208   in, cum ad probo porro elaboraret. Cibo vivend...     esid   \n",
      "1471752  ncidunt necessitatibus at. Pro primis feugiat ...     usde   \n",
      "510710   Harum labitur evertitur id duo, duis eloquenti...     rtyp   \n",
      "1351641   ignota vivendum cum, ea possim reprimique cum...     horu   \n",
      "610749    forensibus referrentur ius ei, pri erant dolo...     ymus   \n",
      "1004322  bus referrentur ius ei, pri erant dolorem vitu...     ethe   \n",
      "756375   am nonumy civibus. Eum possim tincidunt necess...     rete   \n",
      "...                                                    ...      ...   \n",
      "177672   assentior. Eum et erant utamur. Te aperiri sad...     ugun   \n",
      "418250   ea, periculis deseruisse pro id, dico accusamu...     efes   \n",
      "101168   uas nonumy ut quo, mei ei adhuc erant dicant. ...     leth   \n",
      "158349    scripserit ne, iudico forensibus referrentur ...     ethe   \n",
      "293833   or sit amet, eu sint antiopam ius, pro id diam...     reth   \n",
      "323996   iocritatem in, cum ad probo porro elaboraret. ...     tesi   \n",
      "263627   Quas nonumy ut quo, mei ei adhuc erant dicant....     wart   \n",
      "274966   unt necessitatibus at. Pro primis feugiat id, ...     plet   \n",
      "1261875  Pro primis feugiat id, conceptam reprimique li...     esid   \n",
      "173172    vivendum duo ea, periculis deseruisse pro id,...     phyd   \n",
      "748501   seruisse pro id, dico accusamus te mei. Ad dia...     horu   \n",
      "945418   opam ius, pro id diam nonumy civibus. Eum poss...     rugu   \n",
      "87963    diam nonumy civibus. Eum possim tincidunt nece...     erty   \n",
      "1217151  uas nonumy ut quo, mei ei adhuc erant dicant. ...     sdew   \n",
      "1447457  ant dolorem vituperatoribus te. Magna nostrum ...     thor   \n",
      "316800   mediocritatem in, cum ad probo porro elaborare...     horu   \n",
      "1303535  mur. Te aperiri sadipscing ius, cum ad legere ...     etes   \n",
      "379878    antiopam ius, pro id diam nonumy civibus. Eum...     etes   \n",
      "663552   t complectitur ut. Sit dicant scripserit ne, i...     wart   \n",
      "371665   diam modus mea. Soleat qualisque has cu, vel t...     rugu   \n",
      "321782    sensibus vituperatoribus vis an. Ut labore po...     rete   \n",
      "798588   r ut. Sit dicant scripserit ne, iudico forensi...     ugun   \n",
      "185178    ius ei, pri erant dolorem vituperatoribus te....     idur   \n",
      "246903   ocurreret duo ne, est facer dictas mediocritat...     rete   \n",
      "699115   elaboraret his no, ius volutpat complectitur u...     musd   \n",
      "308661   titur ut. Sit dicant scripserit ne, iudico for...     sdew   \n",
      "1471163  iam mea an. His porro appetere euripidis an, b...     ewee   \n",
      "652645   t necessitatibus at. Pro primis feugiat id, co...     ymus   \n",
      "1435444  r. Te aperiri sadipscing ius, cum ad legere po...     tefe   \n",
      "625387   culis deseruisse pro id, dico accusamus te mei...     leth   \n",
      "\n",
      "        date_approval   Date_pay SourceSheet            Timestamp  \n",
      "486090     2015-08-29 2015-09-16   Expenses1  2015-12-23 14:15:29  \n",
      "1418995    2015-05-13 2015-05-28   Expenses2  2015-12-23 14:15:29  \n",
      "1055103    2015-11-11 2015-11-28   Expenses2  2015-12-23 14:15:29  \n",
      "105866     2015-08-20 2015-09-05   Expenses1  2015-12-23 14:15:29  \n",
      "1323067    2015-03-01 2015-03-18   Expenses2  2015-12-23 14:15:29  \n",
      "1175076    2015-09-17 2015-10-04   Expenses2  2015-12-23 14:15:29  \n",
      "677047     2015-06-06 2015-06-25   Expenses1  2015-12-23 14:15:29  \n",
      "446914     2015-02-07 2015-02-24   Expenses1  2015-12-23 14:15:29  \n",
      "1207469    2015-04-02 2015-04-17   Expenses2  2015-12-23 14:15:29  \n",
      "825530     2015-04-26 2015-05-15   Expenses2  2015-12-23 14:15:29  \n",
      "1344971    2015-02-08 2015-02-23   Expenses2  2015-12-23 14:15:29  \n",
      "458323     2015-12-03 2015-12-21   Expenses1  2015-12-23 14:15:29  \n",
      "609535     2015-04-05 2015-04-25   Expenses1  2015-12-23 14:15:29  \n",
      "234363     2015-12-17 2016-01-03   Expenses1  2015-12-23 14:15:29  \n",
      "1142575    2015-03-31 2015-04-20   Expenses2  2015-12-23 14:15:29  \n",
      "1418622    2015-07-16 2015-08-03   Expenses2  2015-12-23 14:15:29  \n",
      "1397773    2015-08-12 2015-08-31   Expenses2  2015-12-23 14:15:29  \n",
      "791716     2015-04-01 2015-04-18   Expenses2  2015-12-23 14:15:29  \n",
      "17648      2015-01-23 2015-02-09   Expenses1  2015-12-23 14:15:29  \n",
      "787968     2015-11-23 2015-12-13   Expenses2  2015-12-23 14:15:29  \n",
      "1451220    2016-01-20 2016-02-09   Expenses2  2015-12-23 14:15:29  \n",
      "379371     2015-04-06 2015-04-23   Expenses1  2015-12-23 14:15:29  \n",
      "212852     2015-07-31 2015-08-19   Expenses1  2015-12-23 14:15:29  \n",
      "862208     2015-08-20 2015-09-09   Expenses2  2015-12-23 14:15:29  \n",
      "1471752    2015-08-30 2015-09-17   Expenses2  2015-12-23 14:15:29  \n",
      "510710     2015-10-28 2015-11-15   Expenses1  2015-12-23 14:15:29  \n",
      "1351641    2015-06-11 2015-07-01   Expenses2  2015-12-23 14:15:29  \n",
      "610749     2016-01-20 2016-02-06   Expenses1  2015-12-23 14:15:29  \n",
      "1004322    2015-11-24 2015-12-11   Expenses2  2015-12-23 14:15:29  \n",
      "756375     2016-01-14 2016-02-01   Expenses2  2015-12-23 14:15:29  \n",
      "...               ...        ...         ...                  ...  \n",
      "177672     2015-06-21 2015-07-08   Expenses1  2015-12-23 14:15:29  \n",
      "418250     2015-06-18 2015-07-04   Expenses1  2015-12-23 14:15:29  \n",
      "101168     2015-03-17 2015-04-04   Expenses1  2015-12-23 14:15:29  \n",
      "158349     2015-11-20 2015-12-08   Expenses1  2015-12-23 14:15:29  \n",
      "293833     2016-01-16 2016-02-04   Expenses1  2015-12-23 14:15:29  \n",
      "323996     2015-06-05 2015-06-25   Expenses1  2015-12-23 14:15:29  \n",
      "263627     2015-07-19 2015-08-06   Expenses1  2015-12-23 14:15:29  \n",
      "274966     2015-12-01 2015-12-17   Expenses1  2015-12-23 14:15:29  \n",
      "1261875    2015-12-02 2015-12-18   Expenses2  2015-12-23 14:15:29  \n",
      "173172     2015-05-21 2015-06-09   Expenses1  2015-12-23 14:15:29  \n",
      "748501     2015-08-26 2015-09-12   Expenses2  2015-12-23 14:15:29  \n",
      "945418     2016-01-17 2016-02-01   Expenses2  2015-12-23 14:15:29  \n",
      "87963      2015-10-26 2015-11-14   Expenses1  2015-12-23 14:15:29  \n",
      "1217151    2015-10-29 2015-11-14   Expenses2  2015-12-23 14:15:29  \n",
      "1447457    2015-07-08 2015-07-26   Expenses2  2015-12-23 14:15:29  \n",
      "316800     2015-02-01 2015-02-19   Expenses1  2015-12-23 14:15:29  \n",
      "1303535    2015-04-14 2015-04-30   Expenses2  2015-12-23 14:15:29  \n",
      "379878     2015-08-22 2015-09-08   Expenses1  2015-12-23 14:15:29  \n",
      "663552     2015-07-08 2015-07-23   Expenses1  2015-12-23 14:15:29  \n",
      "371665     2015-10-25 2015-11-14   Expenses1  2015-12-23 14:15:29  \n",
      "321782     2015-12-12 2016-01-01   Expenses1  2015-12-23 14:15:29  \n",
      "798588     2015-03-12 2015-03-31   Expenses2  2015-12-23 14:15:29  \n",
      "185178     2015-06-01 2015-06-20   Expenses1  2015-12-23 14:15:29  \n",
      "246903     2015-07-25 2015-08-12   Expenses1  2015-12-23 14:15:29  \n",
      "699115     2015-06-06 2015-06-23   Expenses1  2015-12-23 14:15:29  \n",
      "308661     2015-09-19 2015-10-09   Expenses1  2015-12-23 14:15:29  \n",
      "1471163    2015-05-17 2015-06-04   Expenses2  2015-12-23 14:15:29  \n",
      "652645     2015-09-25 2015-10-12   Expenses1  2015-12-23 14:15:29  \n",
      "1435444    2015-05-08 2015-05-25   Expenses2  2015-12-23 14:15:29  \n",
      "625387     2015-02-03 2015-02-22   Expenses1  2015-12-23 14:15:29  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Now we operate on the DF\n",
    "dupli_df= df[df.duplicated(['Name','Date', 'Expenses',\"Date_pay\", \"Description\", \"Approval\"], keep=False)].sort_values(by=[\"Expenses\"])\n",
    "print len(dupli_df)\n",
    "print  dupli_df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "try:\n",
    "    os.remove('testdata/test2_duplicates.xlsx')\n",
    "    writer = pd.ExcelWriter('testdata/test2_duplicates.xlsx', engine='xlsxwriter')\n",
    "    dupli_df.to_excel(writer, sheet_name='Sheet1')\n",
    "except:\n",
    "    print \"error creating/saving excel file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
