{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated \n",
    "21/2/2021\n",
    "These example routines use a special library in Python called fuzzywuzzy which implements various strategies for ranking similarity. Absolutely use it. There are other basic libraries but then you need to program the logic on top to make the best choices.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are talking several 100K records things will become exponential and you may not be able to really run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import Levenshtein\n",
    "from Levenshtein import ratio\n",
    "#Note: installing the python-Levenshtein module alongside fuzzywuzzy can increase performance\n",
    "\n",
    "#we need this for the alternative method of self matching, ie fuzzy duplicates \n",
    "from itertools import combinations \n",
    "\n",
    "\n",
    "\n",
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words. In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "73\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "74\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "77\n",
      "58\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import string\n",
    "import math\n",
    "\n",
    "#To check if setting the max size to a fixed number is faster as apparenntly there are\n",
    "#some optimisations for fixed size.\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def token_sort(s):\n",
    "    s=str(s)\n",
    "    s=s.translate(str.maketrans('', '', string.punctuation))\n",
    "    sl= str.split(s)\n",
    "    sl.sort()\n",
    "    s= \"\".join(sl)\n",
    "    return s\n",
    "\n",
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'].replace(\"\\'\", '',regex= True , inplace=True)\n",
    "    df['fuzzy'].replace(r'\\s', ' ', regex = True, inplace = True)\n",
    "    df['fuzzy'].replace(\"\",np.nan,regex=True, inplace=True)\n",
    "    #This will directly remove accented chars and enie , not replace with the vowel or n   \n",
    "    #df['fuzzy'] = df['fuzzy'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    #This will also remove accented chars \n",
    "    #from string import printable\n",
    "    #st = set(printable)\n",
    "    #df[\"fuzzy\"] = df[\"fuzzy\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))   \n",
    "    #This will retain the characters but standardise for compatibility, there are various libraries that do that too.  \n",
    "    df[\"fuzzy\"]= df[\"fuzzy\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[\"fuzzy\"].replace('[^a-z1-9 ]', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' ltd',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' plc',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' llp',\" \",regex=True, inplace=True)   \n",
    "    df['fuzzy'].replace(' limited',\" \", regex=True , inplace=True)\n",
    "    df['fuzzy'].replace(\"mr \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"mrs \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"ms \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"miss \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' +', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    list_token_sort=[token_sort(s) for s in df[\"fuzzy\"]]\n",
    "    s = pd.Series(list_token_sort)\n",
    "    df['fuzzy'] = s.values\n",
    "    df.set_index('fuzzy')\n",
    "    return list(df['fuzzy'][~pd.isnull(df.fuzzy)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linenew', 'inaqui', 'entrytab', 'lucia', 'nan', 'oneillryan', 'anamaria', '2ndjohnsmith', 'druckerpeter', 'emmawatson', 'bezosjeff', 'bezosjeff']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>expected</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New\\rLine</td>\n",
       "      <td>new line</td>\n",
       "      <td>linenew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iñaqui</td>\n",
       "      <td>inaqui</td>\n",
       "      <td>inaqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tab\\tEntry</td>\n",
       "      <td>tab entry</td>\n",
       "      <td>entrytab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucía</td>\n",
       "      <td>lucia</td>\n",
       "      <td>lucia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ryan     O'Neill</td>\n",
       "      <td>ryan oneill</td>\n",
       "      <td>oneillryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ana-María</td>\n",
       "      <td>ana maria</td>\n",
       "      <td>anamaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Smith 2nd</td>\n",
       "      <td>john smith 2nd</td>\n",
       "      <td>2ndjohnsmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter＿Drücker</td>\n",
       "      <td>peter drucker</td>\n",
       "      <td>druckerpeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emma_Watson</td>\n",
       "      <td>emma watson</td>\n",
       "      <td>emmawatson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>jeff bezos</td>\n",
       "      <td>bezosjeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jeff   . Bezos</td>\n",
       "      <td>jeff bezos</td>\n",
       "      <td>bezosjeff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 input        expected         fuzzy\n",
       "0            New\\rLine        new line       linenew\n",
       "1             Iñaqui            inaqui        inaqui\n",
       "2           Tab\\tEntry       tab entry      entrytab\n",
       "3                Lucía           lucia         lucia\n",
       "4                                  NaN           nan\n",
       "5     Ryan     O'Neill     ryan oneill    oneillryan\n",
       "6            Ana-María       ana maria      anamaria\n",
       "7       John Smith 2nd  john smith 2nd  2ndjohnsmith\n",
       "8        Peter＿Drücker   peter drucker  druckerpeter\n",
       "9          Emma_Watson     emma watson    emmawatson\n",
       "10          Jeff Bezos      jeff bezos     bezosjeff\n",
       "11    jeff   . Bezos        jeff bezos     bezosjeff"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [[\"  New\\rLine\",\"new line\"],['Iñaqui  ', 'inaqui'], [\"Tab\\tEntry\", \"tab entry\"], ['Lucía',\"lucia\"], [\"\",\"NaN\"], [\"Ryan     O'Neill\",\"ryan oneill\"],[\"Ana-María\",\"ana maria\"],[\"John Smith 2nd\",\"john smith 2nd\"],[\"Peter\\uFF3FDrücker\",\"peter drucker\"],[\"Emma\\u005FWatson\",\"emma watson\"],[\"Jeff Bezos\",\"jeff bezos\"],[\"  jeff   . Bezos  \",\"jeff bezos\"]]\n",
    "test_df = pd.DataFrame(test_data, columns = ['input', 'expected']) \n",
    "test_list= create_fuzzy_column(test_df,'input')\n",
    "print(test_list)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine of checking one file against another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other artifacts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1980\n"
     ]
    }
   ],
   "source": [
    "primary_list=list(set(create_fuzzy_column(df_long,\"full_name\"))) \n",
    "#we do set to remove duplicates and reduce the comparisons, we will pick all the exact duplicates\n",
    "#anyway when we reconstruct the hits\n",
    "print(df_long.shape)\n",
    "print(len(primary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 15)\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "secondary_list= list(set(create_fuzzy_column(df_short,\"full_name\")))\n",
    "print(df_short.shape)\n",
    "print(len(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) #Returns tuple of best match and percent fit.\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]]['member_id'].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]]['member_id'].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['primary','secondary','perc_match','key_primary','key_secondary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>garciakatherine</td>\n",
       "      <td>garciahkatherine</td>\n",
       "      <td>97</td>\n",
       "      <td>[7876034075542]</td>\n",
       "      <td>[9706101060165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>michaeltaylor</td>\n",
       "      <td>michaeltaylor</td>\n",
       "      <td>100</td>\n",
       "      <td>[2836812545211]</td>\n",
       "      <td>[5847830015911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrewhernandez</td>\n",
       "      <td>andrewhernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[2340862914892]</td>\n",
       "      <td>[358339665507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jamesmartin</td>\n",
       "      <td>jamesmartin</td>\n",
       "      <td>100</td>\n",
       "      <td>[7957927902845]</td>\n",
       "      <td>[7488960271747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>christinataylor</td>\n",
       "      <td>christiantaylor</td>\n",
       "      <td>93</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>garyvelazquez</td>\n",
       "      <td>garyvazquez</td>\n",
       "      <td>92</td>\n",
       "      <td>[9757549417066]</td>\n",
       "      <td>[8677112089685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hernandezmary</td>\n",
       "      <td>hernandezmary</td>\n",
       "      <td>100</td>\n",
       "      <td>[6492089346744]</td>\n",
       "      <td>[7534575761576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>joesmith</td>\n",
       "      <td>josesmith</td>\n",
       "      <td>94</td>\n",
       "      <td>[3880509524088]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>andrewsmith</td>\n",
       "      <td>andreasmith</td>\n",
       "      <td>91</td>\n",
       "      <td>[1989665637228]</td>\n",
       "      <td>[1896374821001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>robertvasquez</td>\n",
       "      <td>robertvelasquez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9237091857812]</td>\n",
       "      <td>[4936975106842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>danielgonzales</td>\n",
       "      <td>danielgonzales</td>\n",
       "      <td>100</td>\n",
       "      <td>[7993593208263]</td>\n",
       "      <td>[140312516230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>henrymartinez</td>\n",
       "      <td>henrymartin</td>\n",
       "      <td>92</td>\n",
       "      <td>[6982911494472]</td>\n",
       "      <td>[9971387465151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>davidwilliams</td>\n",
       "      <td>davidwilliams</td>\n",
       "      <td>100</td>\n",
       "      <td>[3922931562549]</td>\n",
       "      <td>[229720631152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>brownchristopher</td>\n",
       "      <td>brownchristopher</td>\n",
       "      <td>100</td>\n",
       "      <td>[502887664677]</td>\n",
       "      <td>[1970815105834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             primary         secondary  perc_match      key_primary  \\\n",
       "0    garciakatherine  garciahkatherine          97  [7876034075542]   \n",
       "1      michaeltaylor     michaeltaylor         100  [2836812545211]   \n",
       "2    andrewhernandez   andrewhernandez         100  [2340862914892]   \n",
       "3      collinsgeorge     collinsgeorge         100  [5179019038436]   \n",
       "4        jamesmartin       jamesmartin         100  [7957927902845]   \n",
       "5    christinataylor   christiantaylor          93   [648337018130]   \n",
       "6      garyvelazquez       garyvazquez          92  [9757549417066]   \n",
       "7     alvarezjessica    alvarezjessica         100  [9790621226361]   \n",
       "8      hernandezmary     hernandezmary         100  [6492089346744]   \n",
       "9           joesmith         josesmith          94  [3880509524088]   \n",
       "10       andrewsmith       andreasmith          91  [1989665637228]   \n",
       "11       oliviasmith       oliviasmith         100  [1067119077629]   \n",
       "12     robertvasquez   robertvelasquez          93  [9237091857812]   \n",
       "13    danielgonzales    danielgonzales         100  [7993593208263]   \n",
       "14     henrymartinez       henrymartin          92  [6982911494472]   \n",
       "15     davidwilliams     davidwilliams         100  [3922931562549]   \n",
       "16  brownchristopher  brownchristopher         100   [502887664677]   \n",
       "17    katherinesmith    katherinesmith         100  [8986386973416]   \n",
       "\n",
       "      key_secondary  \n",
       "0   [9706101060165]  \n",
       "1   [5847830015911]  \n",
       "2    [358339665507]  \n",
       "3   [1306491549530]  \n",
       "4   [7488960271747]  \n",
       "5   [1399534976844]  \n",
       "6   [8677112089685]  \n",
       "7   [9250994501583]  \n",
       "8   [7534575761576]  \n",
       "9   [4617626102085]  \n",
       "10  [1896374821001]  \n",
       "11  [4358287106424]  \n",
       "12  [4936975106842]  \n",
       "13   [140312516230]  \n",
       "14  [9971387465151]  \n",
       "15   [229720631152]  \n",
       "16  [1970815105834]  \n",
       "17  [7563384088130]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>25437 Cynthia Flats Apt. 058</td>\n",
       "      <td>Ginamouth</td>\n",
       "      <td>Benin</td>\n",
       "      <td>1963-04-05</td>\n",
       "      <td>Gary</td>\n",
       "      <td>25437 Cynthia Flats Apt. 058, Ginamouth, Benin</td>\n",
       "      <td>Gary Velazquez</td>\n",
       "      <td>M</td>\n",
       "      <td>Velazquez</td>\n",
       "      <td>9757549417066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>garyvelazquez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                       address       city country        dob  \\\n",
       "44          44  25437 Cynthia Flats Apt. 058  Ginamouth   Benin 1963-04-05   \n",
       "\n",
       "   first_name                                    full_address       full_name  \\\n",
       "44       Gary  25437 Cynthia Flats Apt. 058, Ginamouth, Benin  Gary Velazquez   \n",
       "\n",
       "   gender  last_name      member_id middle_name suffix title          fuzzy  \n",
       "44      M  Velazquez  9757549417066         NaN    NaN   Dr.  garyvelazquez  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>11033 Patricia Prairie Apt. 822</td>\n",
       "      <td>Port Elizabethchester</td>\n",
       "      <td>Palau</td>\n",
       "      <td>2000-09-28</td>\n",
       "      <td>Gary</td>\n",
       "      <td>11033 Patricia Prairie Apt. 822, Port Elizabet...</td>\n",
       "      <td>Vazquez, Gary</td>\n",
       "      <td>M</td>\n",
       "      <td>Vazquez</td>\n",
       "      <td>8677112089685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>garyvazquez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                          address                   city  \\\n",
       "400         400  11033 Patricia Prairie Apt. 822  Port Elizabethchester   \n",
       "\n",
       "    country        dob first_name  \\\n",
       "400   Palau 2000-09-28       Gary   \n",
       "\n",
       "                                          full_address      full_name gender  \\\n",
       "400  11033 Patricia Prairie Apt. 822, Port Elizabet...  Vazquez, Gary      M   \n",
       "\n",
       "    last_name      member_id middle_name suffix title        fuzzy  \n",
       "400   Vazquez  8677112089685         NaN    NaN   Dr.  garyvazquez  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for fuzzy duplicates within one file\n",
    "\n",
    "Because we are comparing against itself, the main loop will grow exponentially with the size of the file, very soon you will be looking at millions of iterations. Think carefully how to reduce the dataset to something relevant and manageable.\n",
    "\n",
    "There are alternative methods for large datasets that involve tokenising parts of the texts and scale better possibly reducing accuracy . These are detailed in another notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This method below uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc.\n",
    "We need to import the itertools library for its \"combinations\" function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "2000\n",
      "1999000 combinations to compute. Careful if this number is large, it may take a long time\n"
     ]
    }
   ],
   "source": [
    "list_to_check= create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(list_to_check))\n",
    "\n",
    "item_combinations=list(combinations(list_to_check, 2))\n",
    "print(len(item_combinations), \"combinations to compute. Careful if this number is large, it may take a long time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dupes=df_long[df_long['fuzzy'].duplicated(keep=False)].sort_values(by=\"fuzzy\", ascending=False)\n",
    "df_dupes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzzy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amandathompson</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthonylewis</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michaelsullivan</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laurensmith</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>josephsmith</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonesthomas</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnmiller</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huntmichael</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hernandezjacqueline</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heathertaylor</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diazkevin</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>davidsmith</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daniellewilliams</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colejoseph</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christophermoore</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brownlinda</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brownjohn</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brianwilliams</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billytaylor</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michaelthomas</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  address  city  country  dob  first_name  \\\n",
       "fuzzy                                                                      \n",
       "amandathompson                2        2     2        2    2           2   \n",
       "anthonylewis                  2        2     2        2    2           2   \n",
       "michaelsullivan               2        2     2        2    2           2   \n",
       "laurensmith                   2        2     2        2    2           2   \n",
       "josephsmith                   2        2     2        2    2           2   \n",
       "jonesthomas                   2        2     2        2    2           2   \n",
       "johnmiller                    2        2     2        2    2           2   \n",
       "huntmichael                   2        2     2        2    2           2   \n",
       "hernandezjacqueline           2        2     2        2    2           2   \n",
       "heathertaylor                 2        2     2        2    2           2   \n",
       "diazkevin                     2        2     2        2    2           2   \n",
       "davidsmith                    2        2     2        2    2           2   \n",
       "daniellewilliams              2        2     2        2    2           2   \n",
       "colejoseph                    2        2     2        2    2           2   \n",
       "christophermoore              2        2     2        2    2           2   \n",
       "brownlinda                    2        2     2        2    2           2   \n",
       "brownjohn                     2        2     2        2    2           2   \n",
       "brianwilliams                 2        2     2        2    2           2   \n",
       "billytaylor                   2        2     2        2    2           2   \n",
       "michaelthomas                 2        2     2        2    2           2   \n",
       "\n",
       "                     full_address  full_name  gender  last_name  member_id  \\\n",
       "fuzzy                                                                        \n",
       "amandathompson                  2          2       2          2          2   \n",
       "anthonylewis                    2          2       2          2          2   \n",
       "michaelsullivan                 2          2       2          2          2   \n",
       "laurensmith                     2          2       2          2          2   \n",
       "josephsmith                     2          2       2          2          2   \n",
       "jonesthomas                     2          2       2          2          2   \n",
       "johnmiller                      2          2       2          2          2   \n",
       "huntmichael                     2          2       2          2          2   \n",
       "hernandezjacqueline             2          2       2          2          2   \n",
       "heathertaylor                   2          2       2          2          2   \n",
       "diazkevin                       2          2       2          2          2   \n",
       "davidsmith                      2          2       2          2          2   \n",
       "daniellewilliams                2          2       2          2          2   \n",
       "colejoseph                      2          2       2          2          2   \n",
       "christophermoore                2          2       2          2          2   \n",
       "brownlinda                      2          2       2          2          2   \n",
       "brownjohn                       2          2       2          2          2   \n",
       "brianwilliams                   2          2       2          2          2   \n",
       "billytaylor                     2          2       2          2          2   \n",
       "michaelthomas                   2          2       2          2          2   \n",
       "\n",
       "                     middle_name  suffix  title  \n",
       "fuzzy                                            \n",
       "amandathompson                 0       0      2  \n",
       "anthonylewis                   0       0      2  \n",
       "michaelsullivan                0       0      2  \n",
       "laurensmith                    0       0      2  \n",
       "josephsmith                    0       0      2  \n",
       "jonesthomas                    0       0      2  \n",
       "johnmiller                     0       0      2  \n",
       "huntmichael                    0       0      2  \n",
       "hernandezjacqueline            0       0      2  \n",
       "heathertaylor                  0       0      2  \n",
       "diazkevin                      0       0      2  \n",
       "davidsmith                     0       0      2  \n",
       "daniellewilliams               0       0      2  \n",
       "colejoseph                     0       0      2  \n",
       "christophermoore               0       0      2  \n",
       "brownlinda                     0       0      2  \n",
       "brownjohn                      0       0      2  \n",
       "brianwilliams                  0       0      2  \n",
       "billytaylor                    0       0      2  \n",
       "michaelthomas                  0       0      2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dupes.groupby(\"fuzzy\").count().sort_values(by=\"full_name\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-May-2021 20:53:26\n",
      "20-May-2021 20:53:30\n",
      "Minutes 0.06\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "matches = []\n",
    "@lru_cache(maxsize=None)\n",
    "def get_ratio(a,b):\n",
    "    #r = fuzz.token_sort_ratio(a,b)# because the fuzzying preprocesing we did already does token sort, it is not needed.\n",
    "    #r=fuzz.ratio(a,b)\n",
    "    r=ratio(a,b)*100 #this uses the Levinshtein libary directly, should be fast\n",
    "    return r\n",
    "\n",
    "for x in item_combinations:\n",
    "    s=get_ratio(x[0],x[1])\n",
    "    if s>80:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        \n",
    "print (datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "print (\"Minutes\", round((datetime.datetime.now()-start).total_seconds()/(60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])\n",
    "likely_matches = df_matches[df_matches.score > 90]\n",
    "print(likely_matches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "likely_matches_deduped=likely_matches.drop_duplicates() #we could have exact duplicates in the original file\n",
    "print(likely_matches_deduped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list_fat=[]\n",
    "output_list_thin=[]\n",
    "match_group=1\n",
    "for index,row in likely_matches.iterrows():\n",
    "    key1=df_long.loc[df_long['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    if row['x1']==row['x2']:\n",
    "        key2=[] #it is an self match so we count it only once\n",
    "    else:\n",
    "        key2=df_long.loc[df_long['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    key_conso=key1+key2\n",
    "    for k in key_conso:\n",
    "        v=df_long[df_long['member_id']==k]['full_name'].to_list()[0] #optional we get the original value\n",
    "        #we could use indexes for extra performance but anyway this routine cannot be run in huge tables\n",
    "        #as the combination would quickly get to tens of millions to check.\n",
    "        output_list_thin.append([k,match_group,row[2],v])\n",
    "    output_list_fat.append([row[0], row[1], row[2], key1, key2, len(key_conso),match_group])\n",
    "    match_group +=1 \n",
    "    \n",
    "output= pd.DataFrame(output_list_fat, columns=['x1','x2','score','k1','k2','countkeys','match_group']).sort_values(by=['score'],ascending=False)\n",
    "output_thin=pd.DataFrame(output_list_thin,columns=['id','match_group','score','value']).sort_values(by=['score'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>score</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>countkeys</th>\n",
       "      <th>match_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christophermoore</td>\n",
       "      <td>christophermoore</td>\n",
       "      <td>100</td>\n",
       "      <td>[1360800895169, 7072377543230]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anthonylewis</td>\n",
       "      <td>anthonylewis</td>\n",
       "      <td>100</td>\n",
       "      <td>[9294051750262, 2118643743364]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brianwilliams</td>\n",
       "      <td>brianwilliams</td>\n",
       "      <td>100</td>\n",
       "      <td>[406297274061, 55177040885]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>laurensmith</td>\n",
       "      <td>laurensmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8579400177275, 8950577347478]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>huntmichael</td>\n",
       "      <td>huntmichael</td>\n",
       "      <td>100</td>\n",
       "      <td>[2447864260207, 3632687508653]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x1                x2  score                              k1  \\\n",
       "0   christophermoore  christophermoore    100  [1360800895169, 7072377543230]   \n",
       "12      anthonylewis      anthonylewis    100  [9294051750262, 2118643743364]   \n",
       "25     brianwilliams     brianwilliams    100     [406297274061, 55177040885]   \n",
       "24       laurensmith       laurensmith    100  [8579400177275, 8950577347478]   \n",
       "23       huntmichael       huntmichael    100  [2447864260207, 3632687508653]   \n",
       "\n",
       "    k2  countkeys  match_group  \n",
       "0   []          2            1  \n",
       "12  []          2           13  \n",
       "25  []          2           26  \n",
       "24  []          2           25  \n",
       "23  []          2           24  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_thin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0bfce765e7b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_thin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'match_group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_thin' is not defined"
     ]
    }
   ],
   "source": [
    "output_thin.iloc[0:40].sort_values(by='match_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
