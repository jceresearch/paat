{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated \n",
    "21/2/2021\n",
    "These example routines use a special library in Python called fuzzywuzzy which implements various strategies for ranking similarity. Absolutely use it. There are other basic libraries but then you need to program the logic on top to make the best choices.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are talking several 100K records things will become exponential and you may not be able to really run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import Levenshtein\n",
    "from Levenshtein import ratio\n",
    "#Note: apparently installing the python-Levenshtein module alongside fuzzywuzzy can increase performance\n",
    "\n",
    "#we need this for the alternative method of self matching, ie fuzzy duplicates \n",
    "from itertools import combinations \n",
    "\n",
    "\n",
    "\n",
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words. In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "62\n73\n64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59\n74\n100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "57\n77\n58\n95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import string\n",
    "import math\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def token_sort(s):\n",
    "    s=str(s)\n",
    "    s=s.translate(str.maketrans('', '', string.punctuation))\n",
    "    sl= str.split(s)\n",
    "    sl.sort()\n",
    "    s= \"\".join(sl)\n",
    "    return s\n",
    "\n",
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'].replace(\"\\'\", '',regex= True , inplace=True)\n",
    "    df['fuzzy'].replace(r'\\s', ' ', regex = True, inplace = True)\n",
    "    df['fuzzy'].replace(\"\",np.nan,regex=True, inplace=True)\n",
    "    #This will directly remove accented chars and enie , not replace with the vowel or n   \n",
    "    #df['fuzzy'] = df['fuzzy'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    #This will also remove accented chars \n",
    "    #from string import printable\n",
    "    #st = set(printable)\n",
    "    #df[\"fuzzy\"] = df[\"fuzzy\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))   \n",
    "    #This will retain the characters but standardise for compatibility, there are various libraries that do that too.  \n",
    "    df[\"fuzzy\"]= df[\"fuzzy\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[\"fuzzy\"].replace('[^a-z1-9 ]', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' ltd',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' plc',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' llp',\" \",regex=True, inplace=True)   \n",
    "    df['fuzzy'].replace(' limited',\" \", regex=True , inplace=True)\n",
    "    df['fuzzy'].replace(\"mr \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"mrs \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"ms \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"miss \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' +', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    list_token_sort=[token_sort(s) for s in df[\"fuzzy\"]]\n",
    "    s = pd.Series(list_token_sort)\n",
    "    df['fuzzy'] = s.values\n",
    "    df.set_index('fuzzy')\n",
    "    return list(df['fuzzy'][~pd.isnull(df.fuzzy)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['linenew', 'inaqui', 'entrytab', 'lucia', 'nan', 'oneillryan', 'anamaria', '2ndjohnsmith', 'druckerpeter', 'emmawatson', 'bezosjeff', 'bezosjeff']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 input        expected         fuzzy\n",
       "0            New\\rLine        new line       linenew\n",
       "1             Iñaqui            inaqui        inaqui\n",
       "2           Tab\\tEntry       tab entry      entrytab\n",
       "3                Lucía           lucia         lucia\n",
       "4                                  NaN           nan\n",
       "5     Ryan     O'Neill     ryan oneill    oneillryan\n",
       "6            Ana-María       ana maria      anamaria\n",
       "7       John Smith 2nd  john smith 2nd  2ndjohnsmith\n",
       "8        Peter＿Drücker   peter drucker  druckerpeter\n",
       "9          Emma_Watson     emma watson    emmawatson\n",
       "10          Jeff Bezos      jeff bezos     bezosjeff\n",
       "11    jeff   . Bezos        jeff bezos     bezosjeff"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>expected</th>\n      <th>fuzzy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New\\rLine</td>\n      <td>new line</td>\n      <td>linenew</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Iñaqui</td>\n      <td>inaqui</td>\n      <td>inaqui</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Tab\\tEntry</td>\n      <td>tab entry</td>\n      <td>entrytab</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lucía</td>\n      <td>lucia</td>\n      <td>lucia</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Ryan     O'Neill</td>\n      <td>ryan oneill</td>\n      <td>oneillryan</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ana-María</td>\n      <td>ana maria</td>\n      <td>anamaria</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>John Smith 2nd</td>\n      <td>john smith 2nd</td>\n      <td>2ndjohnsmith</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Peter＿Drücker</td>\n      <td>peter drucker</td>\n      <td>druckerpeter</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Emma_Watson</td>\n      <td>emma watson</td>\n      <td>emmawatson</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Jeff Bezos</td>\n      <td>jeff bezos</td>\n      <td>bezosjeff</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>jeff   . Bezos</td>\n      <td>jeff bezos</td>\n      <td>bezosjeff</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "test_data = [[\"  New\\rLine\",\"new line\"],['Iñaqui  ', 'inaqui'], [\"Tab\\tEntry\", \"tab entry\"], ['Lucía',\"lucia\"], [\"\",\"NaN\"], [\"Ryan     O'Neill\",\"ryan oneill\"],[\"Ana-María\",\"ana maria\"],[\"John Smith 2nd\",\"john smith 2nd\"],[\"Peter\\uFF3FDrücker\",\"peter drucker\"],[\"Emma\\u005FWatson\",\"emma watson\"],[\"Jeff Bezos\",\"jeff bezos\"],[\"  jeff   . Bezos  \",\"jeff bezos\"]]\n",
    "test_df = pd.DataFrame(test_data, columns = ['input', 'expected']) \n",
    "test_list= create_fuzzy_column(test_df,'input')\n",
    "print(test_list)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine of checking one file against another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other artifacts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2000, 15)\n1980\n"
     ]
    }
   ],
   "source": [
    "primary_list=list(set(create_fuzzy_column(df_long,\"full_name\"))) \n",
    "#we do set to remove duplicates and reduce the comparisons, we will pick all the exact duplicates\n",
    "#anyway when we reconstruct the hits\n",
    "print(df_long.shape)\n",
    "print(len(primary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(500, 15)\n500\n"
     ]
    }
   ],
   "source": [
    "secondary_list= list(set(create_fuzzy_column(df_short,\"full_name\")))\n",
    "print(df_short.shape)\n",
    "print(len(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) #Returns tuple of best match and percent fit.\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]]['member_id'].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]]['member_id'].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['primary','secondary','perc_match','key_primary','key_secondary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             primary         secondary  perc_match      key_primary  \\\n",
       "0        jamesmartin       jamesmartin         100  [7957927902845]   \n",
       "1        oliviasmith       oliviasmith         100  [1067119077629]   \n",
       "2    andrewhernandez   andrewhernandez         100  [2340862914892]   \n",
       "3      collinsgeorge     collinsgeorge         100  [5179019038436]   \n",
       "4      hernandezmary     hernandezmary         100  [6492089346744]   \n",
       "5   brownchristopher  brownchristopher         100   [502887664677]   \n",
       "6      davidwilliams     davidwilliams         100  [3922931562549]   \n",
       "7    christinataylor   christiantaylor          93   [648337018130]   \n",
       "8     alvarezjessica    alvarezjessica         100  [9790621226361]   \n",
       "9     danielgonzales    danielgonzales         100  [7993593208263]   \n",
       "10     henrymartinez       henrymartin          92  [6982911494472]   \n",
       "11          joesmith         josesmith          94  [3880509524088]   \n",
       "12     michaeltaylor     michaeltaylor         100  [2836812545211]   \n",
       "13     garyvelazquez       garyvazquez          92  [9757549417066]   \n",
       "14    katherinesmith    katherinesmith         100  [8986386973416]   \n",
       "15       andrewsmith       andreasmith          91  [1989665637228]   \n",
       "16     robertvasquez   robertvelasquez          93  [9237091857812]   \n",
       "17   garciakatherine  garciahkatherine          97  [7876034075542]   \n",
       "\n",
       "      key_secondary  \n",
       "0   [7488960271747]  \n",
       "1   [4358287106424]  \n",
       "2    [358339665507]  \n",
       "3   [1306491549530]  \n",
       "4   [7534575761576]  \n",
       "5   [1970815105834]  \n",
       "6    [229720631152]  \n",
       "7   [1399534976844]  \n",
       "8   [9250994501583]  \n",
       "9    [140312516230]  \n",
       "10  [9971387465151]  \n",
       "11  [4617626102085]  \n",
       "12  [5847830015911]  \n",
       "13  [8677112089685]  \n",
       "14  [7563384088130]  \n",
       "15  [1896374821001]  \n",
       "16  [4936975106842]  \n",
       "17  [9706101060165]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primary</th>\n      <th>secondary</th>\n      <th>perc_match</th>\n      <th>key_primary</th>\n      <th>key_secondary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>jamesmartin</td>\n      <td>jamesmartin</td>\n      <td>100</td>\n      <td>[7957927902845]</td>\n      <td>[7488960271747]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>oliviasmith</td>\n      <td>oliviasmith</td>\n      <td>100</td>\n      <td>[1067119077629]</td>\n      <td>[4358287106424]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>andrewhernandez</td>\n      <td>andrewhernandez</td>\n      <td>100</td>\n      <td>[2340862914892]</td>\n      <td>[358339665507]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>collinsgeorge</td>\n      <td>collinsgeorge</td>\n      <td>100</td>\n      <td>[5179019038436]</td>\n      <td>[1306491549530]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hernandezmary</td>\n      <td>hernandezmary</td>\n      <td>100</td>\n      <td>[6492089346744]</td>\n      <td>[7534575761576]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>brownchristopher</td>\n      <td>brownchristopher</td>\n      <td>100</td>\n      <td>[502887664677]</td>\n      <td>[1970815105834]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>davidwilliams</td>\n      <td>davidwilliams</td>\n      <td>100</td>\n      <td>[3922931562549]</td>\n      <td>[229720631152]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>christinataylor</td>\n      <td>christiantaylor</td>\n      <td>93</td>\n      <td>[648337018130]</td>\n      <td>[1399534976844]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>alvarezjessica</td>\n      <td>alvarezjessica</td>\n      <td>100</td>\n      <td>[9790621226361]</td>\n      <td>[9250994501583]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>danielgonzales</td>\n      <td>danielgonzales</td>\n      <td>100</td>\n      <td>[7993593208263]</td>\n      <td>[140312516230]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>henrymartinez</td>\n      <td>henrymartin</td>\n      <td>92</td>\n      <td>[6982911494472]</td>\n      <td>[9971387465151]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>joesmith</td>\n      <td>josesmith</td>\n      <td>94</td>\n      <td>[3880509524088]</td>\n      <td>[4617626102085]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>michaeltaylor</td>\n      <td>michaeltaylor</td>\n      <td>100</td>\n      <td>[2836812545211]</td>\n      <td>[5847830015911]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>garyvelazquez</td>\n      <td>garyvazquez</td>\n      <td>92</td>\n      <td>[9757549417066]</td>\n      <td>[8677112089685]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>katherinesmith</td>\n      <td>katherinesmith</td>\n      <td>100</td>\n      <td>[8986386973416]</td>\n      <td>[7563384088130]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>andrewsmith</td>\n      <td>andreasmith</td>\n      <td>91</td>\n      <td>[1989665637228]</td>\n      <td>[1896374821001]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>robertvasquez</td>\n      <td>robertvelasquez</td>\n      <td>93</td>\n      <td>[9237091857812]</td>\n      <td>[4936975106842]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>garciakatherine</td>\n      <td>garciahkatherine</td>\n      <td>97</td>\n      <td>[7876034075542]</td>\n      <td>[9706101060165]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0                       address          city  country  \\\n",
       "1957        1957  3069 Kimberly Ways Suite 864  Port Michael  Iceland   \n",
       "\n",
       "            dob first_name                                       full_address  \\\n",
       "1957 1949-10-01      David  3069 Kimberly Ways Suite 864, Port Michael, Ic...   \n",
       "\n",
       "           full_name gender last_name      member_id middle_name suffix title  \\\n",
       "1957  David Williams      M  Williams  3922931562549         NaN    NaN   Mr.   \n",
       "\n",
       "              fuzzy  \n",
       "1957  davidwilliams  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>address</th>\n      <th>city</th>\n      <th>country</th>\n      <th>dob</th>\n      <th>first_name</th>\n      <th>full_address</th>\n      <th>full_name</th>\n      <th>gender</th>\n      <th>last_name</th>\n      <th>member_id</th>\n      <th>middle_name</th>\n      <th>suffix</th>\n      <th>title</th>\n      <th>fuzzy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1957</th>\n      <td>1957</td>\n      <td>3069 Kimberly Ways Suite 864</td>\n      <td>Port Michael</td>\n      <td>Iceland</td>\n      <td>1949-10-01</td>\n      <td>David</td>\n      <td>3069 Kimberly Ways Suite 864, Port Michael, Ic...</td>\n      <td>David Williams</td>\n      <td>M</td>\n      <td>Williams</td>\n      <td>3922931562549</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mr.</td>\n      <td>davidwilliams</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0            address         city country        dob first_name  \\\n",
       "6           6  753 Leonard Ridge  West Andrea  Monaco 1976-11-11      David   \n",
       "\n",
       "                             full_address       full_name gender last_name  \\\n",
       "6  753 Leonard Ridge, West Andrea, Monaco  David Williams      M  Williams   \n",
       "\n",
       "      member_id middle_name suffix title          fuzzy  \n",
       "6  229720631152         NaN    NaN   Mr.  davidwilliams  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>address</th>\n      <th>city</th>\n      <th>country</th>\n      <th>dob</th>\n      <th>first_name</th>\n      <th>full_address</th>\n      <th>full_name</th>\n      <th>gender</th>\n      <th>last_name</th>\n      <th>member_id</th>\n      <th>middle_name</th>\n      <th>suffix</th>\n      <th>title</th>\n      <th>fuzzy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>753 Leonard Ridge</td>\n      <td>West Andrea</td>\n      <td>Monaco</td>\n      <td>1976-11-11</td>\n      <td>David</td>\n      <td>753 Leonard Ridge, West Andrea, Monaco</td>\n      <td>David Williams</td>\n      <td>M</td>\n      <td>Williams</td>\n      <td>229720631152</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mr.</td>\n      <td>davidwilliams</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for fuzzy duplicates within one file\n",
    "\n",
    "Because we are comparing against itself, the main loop will grow exponentially with the size of the file, very soon you will be looking at millions of iterations. Think carefully how to reduce the dataset to something relevant and manageable.\n",
    "\n",
    "There are alternative methods for large datasets that involve tokenising parts of the texts and scale better possibly reducing accuracy . These are detailed in another notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This method below uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc.\n",
    "We need to import the itertools library for its \"combinations\" function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2000, 15)\n",
      "2000\n",
      "1999000 combinations to compute. Careful if this number is large, it may take a long time\n"
     ]
    }
   ],
   "source": [
    "list_to_check= create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(list_to_check))\n",
    "\n",
    "item_combinations=list(combinations(list_to_check, 2))\n",
    "print(len(item_combinations), \"combinations to compute. Careful if this number is large, it may take a long time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(40, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df_dupes=df_long[df_long['fuzzy'].duplicated(keep=False)].sort_values(by=\"fuzzy\", ascending=False)\n",
    "df_dupes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     Unnamed: 0  address  city  country  dob  first_name  \\\n",
       "fuzzy                                                                      \n",
       "amandathompson                2        2     2        2    2           2   \n",
       "anthonylewis                  2        2     2        2    2           2   \n",
       "michaelsullivan               2        2     2        2    2           2   \n",
       "laurensmith                   2        2     2        2    2           2   \n",
       "josephsmith                   2        2     2        2    2           2   \n",
       "jonesthomas                   2        2     2        2    2           2   \n",
       "johnmiller                    2        2     2        2    2           2   \n",
       "huntmichael                   2        2     2        2    2           2   \n",
       "hernandezjacqueline           2        2     2        2    2           2   \n",
       "heathertaylor                 2        2     2        2    2           2   \n",
       "diazkevin                     2        2     2        2    2           2   \n",
       "davidsmith                    2        2     2        2    2           2   \n",
       "daniellewilliams              2        2     2        2    2           2   \n",
       "colejoseph                    2        2     2        2    2           2   \n",
       "christophermoore              2        2     2        2    2           2   \n",
       "brownlinda                    2        2     2        2    2           2   \n",
       "brownjohn                     2        2     2        2    2           2   \n",
       "brianwilliams                 2        2     2        2    2           2   \n",
       "billytaylor                   2        2     2        2    2           2   \n",
       "michaelthomas                 2        2     2        2    2           2   \n",
       "\n",
       "                     full_address  full_name  gender  last_name  member_id  \\\n",
       "fuzzy                                                                        \n",
       "amandathompson                  2          2       2          2          2   \n",
       "anthonylewis                    2          2       2          2          2   \n",
       "michaelsullivan                 2          2       2          2          2   \n",
       "laurensmith                     2          2       2          2          2   \n",
       "josephsmith                     2          2       2          2          2   \n",
       "jonesthomas                     2          2       2          2          2   \n",
       "johnmiller                      2          2       2          2          2   \n",
       "huntmichael                     2          2       2          2          2   \n",
       "hernandezjacqueline             2          2       2          2          2   \n",
       "heathertaylor                   2          2       2          2          2   \n",
       "diazkevin                       2          2       2          2          2   \n",
       "davidsmith                      2          2       2          2          2   \n",
       "daniellewilliams                2          2       2          2          2   \n",
       "colejoseph                      2          2       2          2          2   \n",
       "christophermoore                2          2       2          2          2   \n",
       "brownlinda                      2          2       2          2          2   \n",
       "brownjohn                       2          2       2          2          2   \n",
       "brianwilliams                   2          2       2          2          2   \n",
       "billytaylor                     2          2       2          2          2   \n",
       "michaelthomas                   2          2       2          2          2   \n",
       "\n",
       "                     middle_name  suffix  title  \n",
       "fuzzy                                            \n",
       "amandathompson                 0       0      2  \n",
       "anthonylewis                   0       0      2  \n",
       "michaelsullivan                0       0      2  \n",
       "laurensmith                    0       0      2  \n",
       "josephsmith                    0       0      2  \n",
       "jonesthomas                    0       0      2  \n",
       "johnmiller                     0       0      2  \n",
       "huntmichael                    0       0      2  \n",
       "hernandezjacqueline            0       0      2  \n",
       "heathertaylor                  0       0      2  \n",
       "diazkevin                      0       0      2  \n",
       "davidsmith                     0       0      2  \n",
       "daniellewilliams               0       0      2  \n",
       "colejoseph                     0       0      2  \n",
       "christophermoore               0       0      2  \n",
       "brownlinda                     0       0      2  \n",
       "brownjohn                      0       0      2  \n",
       "brianwilliams                  0       0      2  \n",
       "billytaylor                    0       0      2  \n",
       "michaelthomas                  0       0      2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>address</th>\n      <th>city</th>\n      <th>country</th>\n      <th>dob</th>\n      <th>first_name</th>\n      <th>full_address</th>\n      <th>full_name</th>\n      <th>gender</th>\n      <th>last_name</th>\n      <th>member_id</th>\n      <th>middle_name</th>\n      <th>suffix</th>\n      <th>title</th>\n    </tr>\n    <tr>\n      <th>fuzzy</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>amandathompson</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>anthonylewis</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>michaelsullivan</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>laurensmith</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>josephsmith</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>jonesthomas</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>johnmiller</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>huntmichael</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>hernandezjacqueline</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>heathertaylor</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>diazkevin</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>davidsmith</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>daniellewilliams</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>colejoseph</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>christophermoore</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>brownlinda</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>brownjohn</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>brianwilliams</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>billytaylor</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>michaelthomas</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df_dupes.groupby(\"fuzzy\").count().sort_values(by=\"full_name\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "09-May-2021 19:38:03\n",
      "09-May-2021 19:38:06\n",
      "Minutes 0.06\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "matches = []\n",
    "@lru_cache(maxsize=None)\n",
    "def get_ratio(a,b):\n",
    "    #r = fuzz.token_sort_ratio(a,b)# because the fuzzying preprocesing we did already does token sort, it is not needed.\n",
    "    #r=fuzz.ratio(a,b)\n",
    "    r=ratio(a,b)*100 #this uses the Levinshtein libary directly, should be fast\n",
    "    return r\n",
    "\n",
    "for x in item_combinations:\n",
    "    s=get_ratio(x[0],x[1])\n",
    "    if s>80:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        \n",
    "print (datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "print (\"Minutes\", round((datetime.datetime.now()-start).total_seconds()/(60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])\n",
    "likely_matches = df_matches[df_matches.score > 90]\n",
    "print(likely_matches.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "likely_matches_deduped=likely_matches.drop_duplicates() #we could have exact duplicates in the original file\n",
    "print(likely_matches_deduped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list_fat=[]\n",
    "output_list_thin=[]\n",
    "match_group=1\n",
    "for index,row in likely_matches.iterrows():\n",
    "    key1=df_long.loc[df_long['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    if row['x1']==row['x2']:\n",
    "        key2=[] #it is an self match so we count it only once\n",
    "    else:\n",
    "        key2=df_long.loc[df_long['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    key_conso=key1+key2\n",
    "    for k in key_conso:\n",
    "        v=df_long[df_long['member_id']==k]['full_name'].to_list()[0] #optional we get the original value\n",
    "        #we could use indexes for extra performance but anyway this routine cannot be run in huge tables\n",
    "        #as the combination would quickly get to tens of millions to check.\n",
    "        output_list_thin.append([k,match_group,row[2],v])\n",
    "    output_list_fat.append([row[0], row[1], row[2], key1, key2, len(key_conso),match_group])\n",
    "    match_group +=1 \n",
    "    \n",
    "output= pd.DataFrame(output_list_fat, columns=['x1','x2','score','k1','k2','countkeys','match_group']).sort_values(by=['score'],ascending=False)\n",
    "output_thin=pd.DataFrame(output_list_thin,columns=['id','match_group','score','value']).sort_values(by=['score'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  x1                x2  score                              k1  \\\n",
       "0   christophermoore  christophermoore    100  [1360800895169, 7072377543230]   \n",
       "12      anthonylewis      anthonylewis    100  [9294051750262, 2118643743364]   \n",
       "25     brianwilliams     brianwilliams    100     [406297274061, 55177040885]   \n",
       "24       laurensmith       laurensmith    100  [8579400177275, 8950577347478]   \n",
       "23       huntmichael       huntmichael    100  [2447864260207, 3632687508653]   \n",
       "\n",
       "    k2  countkeys  match_group  \n",
       "0   []          2            1  \n",
       "12  []          2           13  \n",
       "25  []          2           26  \n",
       "24  []          2           25  \n",
       "23  []          2           24  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>score</th>\n      <th>k1</th>\n      <th>k2</th>\n      <th>countkeys</th>\n      <th>match_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>christophermoore</td>\n      <td>christophermoore</td>\n      <td>100</td>\n      <td>[1360800895169, 7072377543230]</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>anthonylewis</td>\n      <td>anthonylewis</td>\n      <td>100</td>\n      <td>[9294051750262, 2118643743364]</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>brianwilliams</td>\n      <td>brianwilliams</td>\n      <td>100</td>\n      <td>[406297274061, 55177040885]</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>laurensmith</td>\n      <td>laurensmith</td>\n      <td>100</td>\n      <td>[8579400177275, 8950577347478]</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>huntmichael</td>\n      <td>huntmichael</td>\n      <td>100</td>\n      <td>[2447864260207, 3632687508653]</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>match_group</th>\n",
       "      <th>score</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1360800895169</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Christopher Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7072377543230</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Christopher Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>825827228877</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Sullivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9520235523057</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Sullivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7039363481297</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>Amanda Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>231280510563</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>Amanda Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5433696913272</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>Taylor, Billy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7794666749030</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>Billy Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5400110077162</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2828385250821</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9432861001628</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>Heather Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8844950381619</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>Heather Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7537589811664</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3747334520428</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7506296213450</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>John Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8673512181554</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>John Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9001733828207</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>Jacqueline Hernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3916487516460</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>Jacqueline Hernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2118643743364</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>Anthony Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9294051750262</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>Lewis, Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8914835563291</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>Diaz, Kevin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1445917465778</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>Kevin Diaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6774632622452</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>John Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6261795470414</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>John Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>184447183004</td>\n",
       "      <td>21</td>\n",
       "      <td>100</td>\n",
       "      <td>Linda Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3213723680900</td>\n",
       "      <td>21</td>\n",
       "      <td>100</td>\n",
       "      <td>Linda Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6332467549384</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>David Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3054578050438</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>David Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3175587312222</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>Thomas Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7249915988253</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>Thomas Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8127440448529</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>Danielle Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>952131193062</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>Danielle Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2447864260207</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3632687508653</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8950577347478</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>Lauren Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8579400177275</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>Lauren Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>55177040885</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>Brian Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>406297274061</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>Brian Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7345449199476</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4716904989414</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Cole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  match_group  score                 value\n",
       "0   1360800895169            1    100     Christopher Moore\n",
       "1   7072377543230            1    100     Christopher Moore\n",
       "4    825827228877            3    100      Michael Sullivan\n",
       "5   9520235523057            3    100      Michael Sullivan\n",
       "9   7039363481297            5    100       Amanda Thompson\n",
       "10   231280510563            5    100       Amanda Thompson\n",
       "12  5433696913272            6    100         Taylor, Billy\n",
       "11  7794666749030            6    100          Billy Taylor\n",
       "18  5400110077162            9    100          Joseph Smith\n",
       "17  2828385250821            9    100          Joseph Smith\n",
       "19  9432861001628           10    100        Heather Taylor\n",
       "20  8844950381619           10    100        Heather Taylor\n",
       "22  7537589811664           11    100        Michael Thomas\n",
       "21  3747334520428           11    100        Michael Thomas\n",
       "24  7506296213450           12    100            John Brown\n",
       "23  8673512181554           12    100            John Brown\n",
       "26  9001733828207           13    100  Jacqueline Hernandez\n",
       "25  3916487516460           13    100  Jacqueline Hernandez\n",
       "28  2118643743364           14    100         Anthony Lewis\n",
       "27  9294051750262           14    100        Lewis, Anthony\n",
       "31  8914835563291           16    100           Diaz, Kevin\n",
       "32  1445917465778           16    100            Kevin Diaz\n",
       "39  6774632622452           19    100           John Miller\n",
       "40  6261795470414           19    100           John Miller\n",
       "45   184447183004           21    100           Linda Brown\n",
       "44  3213723680900           21    100           Linda Brown\n",
       "46  6332467549384           22    100           David Smith\n",
       "47  3054578050438           22    100           David Smith\n",
       "50  3175587312222           24    100          Thomas Jones\n",
       "51  7249915988253           24    100          Thomas Jones\n",
       "52  8127440448529           25    100     Danielle Williams\n",
       "53   952131193062           25    100     Danielle Williams\n",
       "59  2447864260207           28    100          Michael Hunt\n",
       "60  3632687508653           28    100          Michael Hunt\n",
       "62  8950577347478           29    100          Lauren Smith\n",
       "61  8579400177275           29    100          Lauren Smith\n",
       "64    55177040885           30    100        Brian Williams\n",
       "63   406297274061           30    100        Brian Williams\n",
       "73  7345449199476           34    100           Joseph Cole\n",
       "72  4716904989414           34    100           Joseph Cole"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_thin.iloc[0:40].sort_values(by='match_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd08fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}