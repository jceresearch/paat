{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated \n",
    "21/2/2021\n",
    "These example routines use a special library in Python called fuzzywuzzy which implements various strategies for ranking similarity. Absolutely use it. There are other basic libraries but then you need to program the logic on top to make the best choices.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are talking several 100K records things will become exponential and you may not be able to really run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "#import Levenshtein\n",
    "#Note: apparently installing the python-Levenshtein module alongside fuzzywuzzy can increase performance\n",
    "\n",
    "#we need this for the alternative method of self matching, ie fuzzy duplicates \n",
    "from itertools import combinations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words. In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "73\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "74\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "77\n",
      "58\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lucia', 'tab entry', 'emma watson', 'ana maria', 'new line', 'inaqui', 'ryan oneill', 'peter drucker', 'john smith 2nd']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>expected</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New\\rLine</td>\n",
       "      <td>new line</td>\n",
       "      <td>new line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iñaqui</td>\n",
       "      <td>inaqui</td>\n",
       "      <td>inaqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tab\\tEntry</td>\n",
       "      <td>tab entry</td>\n",
       "      <td>tab entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucía</td>\n",
       "      <td>lucia</td>\n",
       "      <td>lucia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ryan     O'Neill</td>\n",
       "      <td>ryan oneill</td>\n",
       "      <td>ryan oneill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ana-María</td>\n",
       "      <td>ana maria</td>\n",
       "      <td>ana maria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Smith 2nd</td>\n",
       "      <td>john smith 2nd</td>\n",
       "      <td>john smith 2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter＿Drücker</td>\n",
       "      <td>peter drucker</td>\n",
       "      <td>peter drucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emma_Watson</td>\n",
       "      <td>emma watson</td>\n",
       "      <td>emma watson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input        expected           fuzzy\n",
       "0         New\\rLine        new line        new line\n",
       "1          Iñaqui            inaqui          inaqui\n",
       "2        Tab\\tEntry       tab entry       tab entry\n",
       "3             Lucía           lucia           lucia\n",
       "4                                               NaN\n",
       "5  Ryan     O'Neill     ryan oneill     ryan oneill\n",
       "6         Ana-María       ana maria       ana maria\n",
       "7    John Smith 2nd  john smith 2nd  john smith 2nd\n",
       "8     Peter＿Drücker   peter drucker   peter drucker\n",
       "9       Emma_Watson     emma watson     emma watson"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'].replace(\"\\'\", '',regex= True , inplace=True)\n",
    "    df['fuzzy'].replace(r'\\s', ' ', regex = True, inplace = True)\n",
    "    df['fuzzy'].replace(\"\",np.nan,regex=False, inplace=True)\n",
    "    #This will directly remove accented chars and enie , not replace with the vowel or n   \n",
    "    #df['fuzzy'] = df['fuzzy'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    #This will also remove accented chars \n",
    "    #from string import printable\n",
    "    #st = set(printable)\n",
    "    #df[\"fuzzy\"] = df[\"fuzzy\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))   \n",
    "    \n",
    "    #This will retain the characters but standardise for compatibility, there are various libraries that do that too.  \n",
    "    df[\"fuzzy\"]= df[\"fuzzy\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "    df[\"fuzzy\"].replace('[^a-z0-9 ]', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' +', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    df.set_index('fuzzy')\n",
    "    return list(set(df['fuzzy'][~pd.isnull(df.fuzzy)]))\n",
    "\n",
    "test_data = [[\"  New\\rLine\",\"new line\"],['Iñaqui  ', 'inaqui'], [\"Tab\\tEntry\", \"tab entry\"], ['Lucía',\"lucia\"], [\"\",\"\"], [\"Ryan     O'Neill\",\"ryan oneill\"],[\"Ana-María\",\"ana maria\"],[\"John Smith 2nd\",\"john smith 2nd\"],[\"Peter\\uFF3FDrücker\",\"peter drucker\"],[\"Emma\\u005FWatson\",\"emma watson\"]]\n",
    "test_df = pd.DataFrame(test_data, columns = ['input', 'expected']) \n",
    "test_list= create_fuzzy_column(test_df,'input')\n",
    "print(test_list)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine of checking one file against another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84724 Nicole Villages Suite 945</td>\n",
       "      <td>Leetown</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>84724 Nicole Villages Suite 945, Leetown, New ...</td>\n",
       "      <td>Deborah Nunez</td>\n",
       "      <td>F</td>\n",
       "      <td>Nunez</td>\n",
       "      <td>5102279799502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>658 Aaron Vista Apt. 239</td>\n",
       "      <td>Mistyborough</td>\n",
       "      <td>Micronesia</td>\n",
       "      <td>1958-03-25</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>658 Aaron Vista Apt. 239, Mistyborough, Micron...</td>\n",
       "      <td>Nathan Baker</td>\n",
       "      <td>M</td>\n",
       "      <td>Baker</td>\n",
       "      <td>2719238400725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>66108 Vasquez Course</td>\n",
       "      <td>Jeffreymouth</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>1961-07-01</td>\n",
       "      <td>Ronald</td>\n",
       "      <td>66108 Vasquez Course, Jeffreymouth, Serbia</td>\n",
       "      <td>Ronald Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>Smith</td>\n",
       "      <td>5344277168281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>117 Wood Turnpike Apt. 562</td>\n",
       "      <td>North Christopher</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>1951-12-14</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>117 Wood Turnpike Apt. 562, North Christopher,...</td>\n",
       "      <td>Douglas Stephanie Ramirez</td>\n",
       "      <td>M</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>9262734362101</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7483 Nguyen Square</td>\n",
       "      <td>North Benjamin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1950-12-06</td>\n",
       "      <td>Alex</td>\n",
       "      <td>7483 Nguyen Square, North Benjamin, Germany</td>\n",
       "      <td>Alex Curry</td>\n",
       "      <td>M</td>\n",
       "      <td>Curry</td>\n",
       "      <td>2504631179862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          address               city  \\\n",
       "0           0  84724 Nicole Villages Suite 945            Leetown   \n",
       "1           1         658 Aaron Vista Apt. 239       Mistyborough   \n",
       "2           2             66108 Vasquez Course       Jeffreymouth   \n",
       "3           3       117 Wood Turnpike Apt. 562  North Christopher   \n",
       "4           4               7483 Nguyen Square     North Benjamin   \n",
       "\n",
       "       country        dob first_name  \\\n",
       "0  New Zealand 2009-11-05    Deborah   \n",
       "1   Micronesia 1958-03-25     Nathan   \n",
       "2       Serbia 1961-07-01     Ronald   \n",
       "3   Montenegro 1951-12-14    Douglas   \n",
       "4      Germany 1950-12-06       Alex   \n",
       "\n",
       "                                        full_address  \\\n",
       "0  84724 Nicole Villages Suite 945, Leetown, New ...   \n",
       "1  658 Aaron Vista Apt. 239, Mistyborough, Micron...   \n",
       "2         66108 Vasquez Course, Jeffreymouth, Serbia   \n",
       "3  117 Wood Turnpike Apt. 562, North Christopher,...   \n",
       "4        7483 Nguyen Square, North Benjamin, Germany   \n",
       "\n",
       "                   full_name gender last_name      member_id middle_name  \\\n",
       "0              Deborah Nunez      F     Nunez  5102279799502         NaN   \n",
       "1               Nathan Baker      M     Baker  2719238400725         NaN   \n",
       "2               Ronald Smith      M     Smith  5344277168281         NaN   \n",
       "3  Douglas Stephanie Ramirez      M   Ramirez  9262734362101   Stephanie   \n",
       "4                 Alex Curry      M     Curry  2504631179862         NaN   \n",
       "\n",
       "  suffix title  \n",
       "0    NaN   Dr.  \n",
       "1    NaN   Mr.  \n",
       "2    NaN   Mr.  \n",
       "3    NaN   Mr.  \n",
       "4    NaN   Mr.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98006 Daniel Causeway</td>\n",
       "      <td>Morenoborough</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>1940-10-13</td>\n",
       "      <td>Cynthia</td>\n",
       "      <td>98006 Daniel Causeway, Morenoborough, Palestin...</td>\n",
       "      <td>Cynthia Brandy Brown</td>\n",
       "      <td>F</td>\n",
       "      <td>Brown</td>\n",
       "      <td>4005263871981</td>\n",
       "      <td>Brandy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3871 Stevens Lane Apt. 513</td>\n",
       "      <td>East Margaret</td>\n",
       "      <td>Seychelles</td>\n",
       "      <td>1982-02-03</td>\n",
       "      <td>John</td>\n",
       "      <td>3871 Stevens Lane Apt. 513, East Margaret, Sey...</td>\n",
       "      <td>John Campbell</td>\n",
       "      <td>M</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>5593277759078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>707 Nichole Run</td>\n",
       "      <td>New Jerrybury</td>\n",
       "      <td>France</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>Tara</td>\n",
       "      <td>707 Nichole Run, New Jerrybury, France</td>\n",
       "      <td>Tara Amanda Manning</td>\n",
       "      <td>F</td>\n",
       "      <td>Manning</td>\n",
       "      <td>9253704032896</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>29214 Christopher Lodge</td>\n",
       "      <td>Lake Andrew</td>\n",
       "      <td>Isle of Man</td>\n",
       "      <td>1955-11-13</td>\n",
       "      <td>Michaela</td>\n",
       "      <td>29214 Christopher Lodge, Lake Andrew, Isle of Man</td>\n",
       "      <td>Michaela Brock</td>\n",
       "      <td>F</td>\n",
       "      <td>Brock</td>\n",
       "      <td>4666408668950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31860 Earl Stravenue Suite 296</td>\n",
       "      <td>Vickiburgh</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1974-02-17</td>\n",
       "      <td>Peter</td>\n",
       "      <td>31860 Earl Stravenue Suite 296, Vickiburgh, Be...</td>\n",
       "      <td>Peter Perez</td>\n",
       "      <td>M</td>\n",
       "      <td>Perez</td>\n",
       "      <td>4289840277902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         address           city  \\\n",
       "0           0           98006 Daniel Causeway  Morenoborough   \n",
       "1           1      3871 Stevens Lane Apt. 513  East Margaret   \n",
       "2           2                 707 Nichole Run  New Jerrybury   \n",
       "3           3         29214 Christopher Lodge    Lake Andrew   \n",
       "4           4  31860 Earl Stravenue Suite 296     Vickiburgh   \n",
       "\n",
       "                 country        dob first_name  \\\n",
       "0  Palestinian Territory 1940-10-13    Cynthia   \n",
       "1             Seychelles 1982-02-03       John   \n",
       "2                 France 2017-09-13       Tara   \n",
       "3            Isle of Man 1955-11-13   Michaela   \n",
       "4                Belgium 1974-02-17      Peter   \n",
       "\n",
       "                                        full_address             full_name  \\\n",
       "0  98006 Daniel Causeway, Morenoborough, Palestin...  Cynthia Brandy Brown   \n",
       "1  3871 Stevens Lane Apt. 513, East Margaret, Sey...         John Campbell   \n",
       "2             707 Nichole Run, New Jerrybury, France   Tara Amanda Manning   \n",
       "3  29214 Christopher Lodge, Lake Andrew, Isle of Man        Michaela Brock   \n",
       "4  31860 Earl Stravenue Suite 296, Vickiburgh, Be...           Peter Perez   \n",
       "\n",
       "  gender last_name      member_id middle_name suffix title  \n",
       "0      F     Brown  4005263871981      Brandy    NaN  Mrs.  \n",
       "1      M  Campbell  5593277759078         NaN    NaN   Mr.  \n",
       "2      F   Manning  9253704032896      Amanda    NaN  Mrs.  \n",
       "3      F     Brock  4666408668950         NaN    NaN   Dr.  \n",
       "4      M     Perez  4289840277902         NaN    NaN   Mr.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other artifacts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "primary_list=create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(primary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 15)\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "secondary_list= create_fuzzy_column(df_short,\"full_name\")\n",
    "print(df_short.shape)\n",
    "print(len(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) #Returns tuple of best match and percent fit.\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]]['member_id'].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]]['member_id'].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['primary','secondary','perc_match','key_primary','key_secondary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[6492089346744]</td>\n",
       "      <td>[7534575761576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>100</td>\n",
       "      <td>[7993593208263]</td>\n",
       "      <td>[140312516230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrew smith</td>\n",
       "      <td>andrea smith</td>\n",
       "      <td>92</td>\n",
       "      <td>[1989665637228]</td>\n",
       "      <td>[1896374821001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joe smith</td>\n",
       "      <td>smith, jose</td>\n",
       "      <td>95</td>\n",
       "      <td>[3880509524088]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joseph smith</td>\n",
       "      <td>smith, jose</td>\n",
       "      <td>91</td>\n",
       "      <td>[2828385250821, 5400110077162]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jamie owens</td>\n",
       "      <td>james owens</td>\n",
       "      <td>91</td>\n",
       "      <td>[2377196554883]</td>\n",
       "      <td>[410879923414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>james martin</td>\n",
       "      <td>james martin</td>\n",
       "      <td>100</td>\n",
       "      <td>[7957927902845]</td>\n",
       "      <td>[7488960271747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>george collins</td>\n",
       "      <td>george collins</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>christopher brown</td>\n",
       "      <td>christopher brown</td>\n",
       "      <td>100</td>\n",
       "      <td>[502887664677]</td>\n",
       "      <td>[1970815105834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>katherine smith</td>\n",
       "      <td>katherine smith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>henry martinez</td>\n",
       "      <td>henry martin</td>\n",
       "      <td>92</td>\n",
       "      <td>[6982911494472]</td>\n",
       "      <td>[9971387465151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gary velazquez</td>\n",
       "      <td>vazquez, gary</td>\n",
       "      <td>92</td>\n",
       "      <td>[9757549417066]</td>\n",
       "      <td>[8677112089685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>david williams</td>\n",
       "      <td>david williams</td>\n",
       "      <td>100</td>\n",
       "      <td>[3922931562549]</td>\n",
       "      <td>[229720631152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vasquez, robert</td>\n",
       "      <td>robert velasquez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9237091857812]</td>\n",
       "      <td>[4936975106842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>katherine garcia</td>\n",
       "      <td>garcia, katherine h</td>\n",
       "      <td>94</td>\n",
       "      <td>[7876034075542]</td>\n",
       "      <td>[9706101060165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[2340862914892]</td>\n",
       "      <td>[358339665507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>michael taylor</td>\n",
       "      <td>michael taylor</td>\n",
       "      <td>100</td>\n",
       "      <td>[2836812545211]</td>\n",
       "      <td>[5847830015911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>olivia smith</td>\n",
       "      <td>smith, olivia</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>christina taylor</td>\n",
       "      <td>christian taylor</td>\n",
       "      <td>94</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              primary            secondary  perc_match  \\\n",
       "0      mary hernandez       mary hernandez         100   \n",
       "1     daniel gonzales      daniel gonzales         100   \n",
       "2        andrew smith         andrea smith          92   \n",
       "3           joe smith          smith, jose          95   \n",
       "4        joseph smith          smith, jose          91   \n",
       "5         jamie owens          james owens          91   \n",
       "6        james martin         james martin         100   \n",
       "7      george collins       george collins         100   \n",
       "8   christopher brown    christopher brown         100   \n",
       "9     katherine smith      katherine smith         100   \n",
       "10     henry martinez         henry martin          92   \n",
       "11     gary velazquez        vazquez, gary          92   \n",
       "12     david williams       david williams         100   \n",
       "13    vasquez, robert     robert velasquez          93   \n",
       "14    jessica alvarez      jessica alvarez         100   \n",
       "15   katherine garcia  garcia, katherine h          94   \n",
       "16   andrew hernandez     andrew hernandez         100   \n",
       "17     michael taylor       michael taylor         100   \n",
       "18       olivia smith        smith, olivia         100   \n",
       "19   christina taylor     christian taylor          94   \n",
       "\n",
       "                       key_primary    key_secondary  \n",
       "0                  [6492089346744]  [7534575761576]  \n",
       "1                  [7993593208263]   [140312516230]  \n",
       "2                  [1989665637228]  [1896374821001]  \n",
       "3                  [3880509524088]  [4617626102085]  \n",
       "4   [2828385250821, 5400110077162]  [4617626102085]  \n",
       "5                  [2377196554883]   [410879923414]  \n",
       "6                  [7957927902845]  [7488960271747]  \n",
       "7                  [5179019038436]  [1306491549530]  \n",
       "8                   [502887664677]  [1970815105834]  \n",
       "9                  [8986386973416]  [7563384088130]  \n",
       "10                 [6982911494472]  [9971387465151]  \n",
       "11                 [9757549417066]  [8677112089685]  \n",
       "12                 [3922931562549]   [229720631152]  \n",
       "13                 [9237091857812]  [4936975106842]  \n",
       "14                 [9790621226361]  [9250994501583]  \n",
       "15                 [7876034075542]  [9706101060165]  \n",
       "16                 [2340862914892]   [358339665507]  \n",
       "17                 [2836812545211]  [5847830015911]  \n",
       "18                 [1067119077629]  [4358287106424]  \n",
       "19                  [648337018130]  [1399534976844]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>2360 Michelle Keys Apt. 147</td>\n",
       "      <td>Port Belindaburgh</td>\n",
       "      <td>Guam</td>\n",
       "      <td>1942-11-23</td>\n",
       "      <td>James</td>\n",
       "      <td>2360 Michelle Keys Apt. 147, Port Belindaburgh...</td>\n",
       "      <td>James Martin</td>\n",
       "      <td>M</td>\n",
       "      <td>Martin</td>\n",
       "      <td>7957927902845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>james martin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                      address               city country  \\\n",
       "1124        1124  2360 Michelle Keys Apt. 147  Port Belindaburgh    Guam   \n",
       "\n",
       "            dob first_name                                       full_address  \\\n",
       "1124 1942-11-23      James  2360 Michelle Keys Apt. 147, Port Belindaburgh...   \n",
       "\n",
       "         full_name gender last_name      member_id middle_name suffix title  \\\n",
       "1124  James Martin      M    Martin  7957927902845         NaN    NaN   Dr.   \n",
       "\n",
       "             fuzzy  \n",
       "1124  james martin  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>046 Melvin Parkway</td>\n",
       "      <td>South Christina</td>\n",
       "      <td>Antarctica (the territory South of 60 deg S)</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>James</td>\n",
       "      <td>046 Melvin Parkway, South Christina, Antarctic...</td>\n",
       "      <td>James Martin</td>\n",
       "      <td>M</td>\n",
       "      <td>Martin</td>\n",
       "      <td>7488960271747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>james martin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             address             city  \\\n",
       "477         477  046 Melvin Parkway  South Christina   \n",
       "\n",
       "                                          country        dob first_name  \\\n",
       "477  Antarctica (the territory South of 60 deg S) 2017-05-12      James   \n",
       "\n",
       "                                          full_address     full_name gender  \\\n",
       "477  046 Melvin Parkway, South Christina, Antarctic...  James Martin      M   \n",
       "\n",
       "    last_name      member_id middle_name suffix title         fuzzy  \n",
       "477    Martin  7488960271747         NaN    NaN   Dr.  james martin  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of checking for fuzzy duplicates within one file\n",
    "\n",
    "You need to make sure the value is a string.  \n",
    "You can also here concatenate a few fields to do fuzzy matching across a few fields,  \n",
    "though it maybe better to do separate similarity checks and then work on those scores\n",
    "\n",
    "The routines below would be useful for finding fuzzy duplicates within a file... \n",
    "Because we are comparing against itself, the main loop will grow exponentially with the size of the file, very soon you will be looking at millions of iterations. Think carefully how to reduce the dataset to something relevant and manageable.\n",
    "\n",
    "There are alternative methods for large datasets that involve tokenising parts of the texts and scale better possibly reducing accuracy . These are detailed in another notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'] = df['fuzzy'].str.replace('\\'', ' ')\n",
    "    df['fuzzy'] = df['fuzzy'].str.replace(' +', ' ')\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    df.set_index('fuzzy')\n",
    "    return list(set(df['fuzzy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6592a6cfd155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test_data/data_long.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlist_to_check\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_fuzzy_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"full_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_to_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df =pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "print(df.shape)\n",
    "list_to_check= create_fuzzy_column(df,\"full_name\")\n",
    "print(df.shape)\n",
    "print(len(list_to_check))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-21 20:15:20.278468\n",
      "2021-02-21 20:18:30.023952\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "print(datetime.now())\n",
    "for item in list_to_check:\n",
    "    match = process.extract(item, list_to_check, scorer=fuzz.token_sort_ratio, limit=2 ) #Returns 2 best matches, one will be itself!\n",
    "    matches.append([item,match[0],match[1]])\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['joseph haynes', 'joseph hayes', 96],\n",
       " ['lewis, anthony', 'anthony lewis', 100],\n",
       " ['michael sullivan', 'mitchell sullivan', 91],\n",
       " ['billy taylor', 'taylor, billy', 100],\n",
       " ['tina simmons', 'tina simon', 91],\n",
       " ['amy torres', 'tammy torres', 91],\n",
       " ['tina simon', 'tina simmons', 91],\n",
       " ['joseph hayes', 'joseph haynes', 96],\n",
       " ['bradley curtis', 'curtis brady', 92],\n",
       " ['roy adams', 'troy adams', 95],\n",
       " ['daniel williams', 'danielle williams', 94],\n",
       " ['tammy torres', 'amy torres', 91],\n",
       " ['johnny miller', 'john miller', 92],\n",
       " ['kevin diaz', 'diaz, kevin', 100],\n",
       " ['john miller', 'johnny miller', 92],\n",
       " ['joseph gonzalez', 'jose gonzalez', 93],\n",
       " ['michael dunn', 'michael duncan', 92],\n",
       " ['diaz, kevin', 'kevin diaz', 100],\n",
       " ['joseph hall', 'joseph ball', 91],\n",
       " ['joseph ball', 'joseph hall', 91],\n",
       " ['curtis brady', 'bradley curtis', 92],\n",
       " ['michael duncan', 'michael dunn', 92],\n",
       " ['jose gonzalez', 'joseph gonzalez', 93],\n",
       " ['anthony lewis', 'lewis, anthony', 100],\n",
       " ['matthew j moore', 'matthew moore', 93],\n",
       " ['mitchell sullivan', 'michael sullivan', 91],\n",
       " ['matthew moore', 'matthew j moore', 93],\n",
       " ['taylor, billy', 'billy taylor', 100],\n",
       " ['danielle williams', 'daniel williams', 94],\n",
       " ['troy adams', 'roy adams', 95]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to remove the self hit\n",
    "matches_clean=[]\n",
    "for x in matches:\n",
    "    if x[0] == x[1][0]:\n",
    "        a= x[0]\n",
    "        b= x[2][0]\n",
    "        c= x[2][1]\n",
    "    else:\n",
    "        a= x[0]\n",
    "        b= x[1][0]\n",
    "        c= x[1][1]        \n",
    "    matches_clean.append([a,b,c])\n",
    "    \n",
    "likely_matches=[]\n",
    "likely_matches= [[x[0],x[1], x[2]] for x in matches_clean if x[2]>90]\n",
    "likely_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative method with a manual iteration  \n",
    "\n",
    "This method uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "item_combinations=list(combinations(list_to_check, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for x in item_combinations:\n",
    "    s = fuzz.token_sort_ratio(x[0],x[1])\n",
    "    if s>60:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])\n",
    "\n",
    "likely_matches = df_matches[df_matches.score > 90]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching records as we did a fuzzy match on the simplified and unique values, so there could be more than one per hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 5)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list=[]\n",
    "for index,row in likely_matches.iterrows():\n",
    "    key1=df.loc[df['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    key2=df.loc[df['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    output_list.append([row['x1'],row['x2'], row['score'], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['x1','x2','score','k1','k2'])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>score</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>amy torres</td>\n",
       "      <td>tammy torres</td>\n",
       "      <td>91</td>\n",
       "      <td>[2700300227159]</td>\n",
       "      <td>[4066256017823]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>joseph ball</td>\n",
       "      <td>joseph hall</td>\n",
       "      <td>91</td>\n",
       "      <td>[4437763835086]</td>\n",
       "      <td>[9554307555868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>billy taylor</td>\n",
       "      <td>taylor, billy</td>\n",
       "      <td>100</td>\n",
       "      <td>[7794666749030]</td>\n",
       "      <td>[5433696913272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>joseph gonzalez</td>\n",
       "      <td>jose gonzalez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9305307561485]</td>\n",
       "      <td>[4774921940030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mitchell sullivan</td>\n",
       "      <td>michael sullivan</td>\n",
       "      <td>91</td>\n",
       "      <td>[1296517170926]</td>\n",
       "      <td>[825827228877, 9520235523057]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>daniel williams</td>\n",
       "      <td>danielle williams</td>\n",
       "      <td>94</td>\n",
       "      <td>[6978712771492]</td>\n",
       "      <td>[8127440448529, 952131193062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>tina simon</td>\n",
       "      <td>tina simmons</td>\n",
       "      <td>91</td>\n",
       "      <td>[9856537464638]</td>\n",
       "      <td>[2883744213749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>matthew j moore</td>\n",
       "      <td>matthew moore</td>\n",
       "      <td>93</td>\n",
       "      <td>[3450342297878]</td>\n",
       "      <td>[3873363814785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>michael dunn</td>\n",
       "      <td>michael duncan</td>\n",
       "      <td>92</td>\n",
       "      <td>[8955508677235]</td>\n",
       "      <td>[6750866325253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>joseph haynes</td>\n",
       "      <td>joseph hayes</td>\n",
       "      <td>96</td>\n",
       "      <td>[4272394152283]</td>\n",
       "      <td>[4795669425207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>diaz, kevin</td>\n",
       "      <td>kevin diaz</td>\n",
       "      <td>100</td>\n",
       "      <td>[8914835563291]</td>\n",
       "      <td>[1445917465778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>bradley curtis</td>\n",
       "      <td>curtis brady</td>\n",
       "      <td>92</td>\n",
       "      <td>[8317444954571]</td>\n",
       "      <td>[9926822808017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>troy adams</td>\n",
       "      <td>roy adams</td>\n",
       "      <td>95</td>\n",
       "      <td>[9415236987604]</td>\n",
       "      <td>[8904361580121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>anthony lewis</td>\n",
       "      <td>lewis, anthony</td>\n",
       "      <td>100</td>\n",
       "      <td>[2118643743364]</td>\n",
       "      <td>[9294051750262]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>john miller</td>\n",
       "      <td>johnny miller</td>\n",
       "      <td>92</td>\n",
       "      <td>[6774632622452, 6261795470414]</td>\n",
       "      <td>[4268725868367]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x1                 x2  score  \\\n",
       "0          amy torres       tammy torres     91   \n",
       "1         joseph ball        joseph hall     91   \n",
       "2        billy taylor      taylor, billy    100   \n",
       "3     joseph gonzalez      jose gonzalez     93   \n",
       "4   mitchell sullivan   michael sullivan     91   \n",
       "5     daniel williams  danielle williams     94   \n",
       "6          tina simon       tina simmons     91   \n",
       "7     matthew j moore      matthew moore     93   \n",
       "8        michael dunn     michael duncan     92   \n",
       "9       joseph haynes       joseph hayes     96   \n",
       "10        diaz, kevin         kevin diaz    100   \n",
       "11     bradley curtis       curtis brady     92   \n",
       "12         troy adams          roy adams     95   \n",
       "13      anthony lewis     lewis, anthony    100   \n",
       "14        john miller      johnny miller     92   \n",
       "\n",
       "                                k1                             k2  \n",
       "0                  [2700300227159]                [4066256017823]  \n",
       "1                  [4437763835086]                [9554307555868]  \n",
       "2                  [7794666749030]                [5433696913272]  \n",
       "3                  [9305307561485]                [4774921940030]  \n",
       "4                  [1296517170926]  [825827228877, 9520235523057]  \n",
       "5                  [6978712771492]  [8127440448529, 952131193062]  \n",
       "6                  [9856537464638]                [2883744213749]  \n",
       "7                  [3450342297878]                [3873363814785]  \n",
       "8                  [8955508677235]                [6750866325253]  \n",
       "9                  [4272394152283]                [4795669425207]  \n",
       "10                 [8914835563291]                [1445917465778]  \n",
       "11                 [8317444954571]                [9926822808017]  \n",
       "12                 [9415236987604]                [8904361580121]  \n",
       "13                 [2118643743364]                [9294051750262]  \n",
       "14  [6774632622452, 6261795470414]                [4268725868367]  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
