{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated \n",
    "21/2/2021\n",
    "These example routines use a special library in Python called fuzzywuzzy which implements various strategies for ranking similarity. Absolutely use it. There are other basic libraries but then you need to program the logic on top to make the best choices.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are talking several 100K records things will become exponential and you may not be able to really run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/mobile/Containers/Data/Application/E26F1E42-C4E9-412E-98C9-C0D10CAA235E/Documents/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "#import Levenshtein\n",
    "#Note: apparently installing the python-Levenshtein module alongside fuzzywuzzy can increase performance\n",
    "\n",
    "#we need this for the alternative method of self matching, ie fuzzy duplicates \n",
    "from itertools import combinations \n",
    "\n",
    "\n",
    "\n",
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words. In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "73\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "74\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "77\n",
      "58\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new line', 'ana maria', 'peter drucker', 'emma watson', 'tab entry', 'inaqui', 'lucia', 'ryan oneill', 'john smith 2nd']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>expected</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New\\rLine</td>\n",
       "      <td>new line</td>\n",
       "      <td>new line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iñaqui</td>\n",
       "      <td>inaqui</td>\n",
       "      <td>inaqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tab\\tEntry</td>\n",
       "      <td>tab entry</td>\n",
       "      <td>tab entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucía</td>\n",
       "      <td>lucia</td>\n",
       "      <td>lucia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ryan     O'Neill</td>\n",
       "      <td>ryan oneill</td>\n",
       "      <td>ryan oneill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ana-María</td>\n",
       "      <td>ana maria</td>\n",
       "      <td>ana maria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Smith 2nd</td>\n",
       "      <td>john smith 2nd</td>\n",
       "      <td>john smith 2nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter＿Drücker</td>\n",
       "      <td>peter drucker</td>\n",
       "      <td>peter drucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emma_Watson</td>\n",
       "      <td>emma watson</td>\n",
       "      <td>emma watson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input        expected           fuzzy\n",
       "0         New\\rLine        new line        new line\n",
       "1          Iñaqui            inaqui          inaqui\n",
       "2        Tab\\tEntry       tab entry       tab entry\n",
       "3             Lucía           lucia           lucia\n",
       "4                               NaN             NaN\n",
       "5  Ryan     O'Neill     ryan oneill     ryan oneill\n",
       "6         Ana-María       ana maria       ana maria\n",
       "7    John Smith 2nd  john smith 2nd  john smith 2nd\n",
       "8     Peter＿Drücker   peter drucker   peter drucker\n",
       "9       Emma_Watson     emma watson     emma watson"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'].replace(\"\\'\", '',regex= True , inplace=True)\n",
    "    df['fuzzy'].replace(r'\\s', ' ', regex = True, inplace = True)\n",
    "    df['fuzzy'].replace(\"\",np.nan,regex=False, inplace=True)\n",
    "    #This will directly remove accented chars and enie , not replace with the vowel or n   \n",
    "    #df['fuzzy'] = df['fuzzy'].str.encode('ascii', 'ignore').str.decode('ascii')    \n",
    "    #This will also remove accented chars \n",
    "    #from string import printable\n",
    "    #st = set(printable)\n",
    "    #df[\"fuzzy\"] = df[\"fuzzy\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))      \n",
    "    #This will retain the characters but standardise for compatibility, there are various libraries that do that too.  \n",
    "    df[\"fuzzy\"]= df[\"fuzzy\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[\"fuzzy\"].replace('[^a-z0-9 ]', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' +', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    df.set_index('fuzzy')\n",
    "    return list(set(df['fuzzy'][~pd.isnull(df.fuzzy)]))\n",
    "\n",
    "test_data = [[\"  New\\rLine\",\"new line\"],['Iñaqui  ', 'inaqui'], [\"Tab\\tEntry\", \"tab entry\"], ['Lucía',\"lucia\"], [\"\",\"NaN\"], [\"Ryan     O'Neill\",\"ryan oneill\"],[\"Ana-María\",\"ana maria\"],[\"John Smith 2nd\",\"john smith 2nd\"],[\"Peter\\uFF3FDrücker\",\"peter drucker\"],[\"Emma\\u005FWatson\",\"emma watson\"]]\n",
    "test_df = pd.DataFrame(test_data, columns = ['input', 'expected']) \n",
    "test_list= create_fuzzy_column(test_df,'input')\n",
    "print(test_list)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine of checking one file against another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other artifacts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "primary_list=create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(primary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 15)\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "secondary_list= create_fuzzy_column(df_short,\"full_name\")\n",
    "print(df_short.shape)\n",
    "print(len(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) #Returns tuple of best match and percent fit.\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]]['member_id'].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]]['member_id'].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['primary','secondary','perc_match','key_primary','key_secondary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>james martin</td>\n",
       "      <td>james martin</td>\n",
       "      <td>100</td>\n",
       "      <td>[7957927902845]</td>\n",
       "      <td>[7488960271747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>christopher brown</td>\n",
       "      <td>christopher brown</td>\n",
       "      <td>100</td>\n",
       "      <td>[502887664677]</td>\n",
       "      <td>[1970815105834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>100</td>\n",
       "      <td>[7993593208263]</td>\n",
       "      <td>[140312516230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>katherine garcia</td>\n",
       "      <td>garcia katherine h</td>\n",
       "      <td>94</td>\n",
       "      <td>[7876034075542]</td>\n",
       "      <td>[9706101060165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joe smith</td>\n",
       "      <td>smith jose</td>\n",
       "      <td>95</td>\n",
       "      <td>[3880509524088]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[2340862914892]</td>\n",
       "      <td>[358339665507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>christina taylor</td>\n",
       "      <td>christian taylor</td>\n",
       "      <td>94</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>katherine smith</td>\n",
       "      <td>katherine smith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>michael taylor</td>\n",
       "      <td>michael taylor</td>\n",
       "      <td>100</td>\n",
       "      <td>[2836812545211]</td>\n",
       "      <td>[5847830015911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[6492089346744]</td>\n",
       "      <td>[7534575761576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gary velazquez</td>\n",
       "      <td>vazquez gary</td>\n",
       "      <td>92</td>\n",
       "      <td>[9757549417066]</td>\n",
       "      <td>[8677112089685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>david williams</td>\n",
       "      <td>david williams</td>\n",
       "      <td>100</td>\n",
       "      <td>[3922931562549]</td>\n",
       "      <td>[229720631152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>george collins</td>\n",
       "      <td>george collins</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jamie owens</td>\n",
       "      <td>james owens</td>\n",
       "      <td>91</td>\n",
       "      <td>[2377196554883]</td>\n",
       "      <td>[410879923414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>joseph smith</td>\n",
       "      <td>smith jose</td>\n",
       "      <td>91</td>\n",
       "      <td>[2828385250821, 5400110077162]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>henry martinez</td>\n",
       "      <td>henry martin</td>\n",
       "      <td>92</td>\n",
       "      <td>[6982911494472]</td>\n",
       "      <td>[9971387465151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olivia smith</td>\n",
       "      <td>smith olivia</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>andrew smith</td>\n",
       "      <td>andrea smith</td>\n",
       "      <td>92</td>\n",
       "      <td>[1989665637228]</td>\n",
       "      <td>[1896374821001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vasquez robert</td>\n",
       "      <td>robert velasquez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9237091857812]</td>\n",
       "      <td>[4936975106842]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              primary           secondary  perc_match  \\\n",
       "0        james martin        james martin         100   \n",
       "1   christopher brown   christopher brown         100   \n",
       "2     daniel gonzales     daniel gonzales         100   \n",
       "3    katherine garcia  garcia katherine h          94   \n",
       "4           joe smith          smith jose          95   \n",
       "5    andrew hernandez    andrew hernandez         100   \n",
       "6    christina taylor    christian taylor          94   \n",
       "7     katherine smith     katherine smith         100   \n",
       "8      michael taylor      michael taylor         100   \n",
       "9      mary hernandez      mary hernandez         100   \n",
       "10     gary velazquez        vazquez gary          92   \n",
       "11    jessica alvarez     jessica alvarez         100   \n",
       "12     david williams      david williams         100   \n",
       "13     george collins      george collins         100   \n",
       "14        jamie owens         james owens          91   \n",
       "15       joseph smith          smith jose          91   \n",
       "16     henry martinez        henry martin          92   \n",
       "17       olivia smith        smith olivia         100   \n",
       "18       andrew smith        andrea smith          92   \n",
       "19     vasquez robert    robert velasquez          93   \n",
       "\n",
       "                       key_primary    key_secondary  \n",
       "0                  [7957927902845]  [7488960271747]  \n",
       "1                   [502887664677]  [1970815105834]  \n",
       "2                  [7993593208263]   [140312516230]  \n",
       "3                  [7876034075542]  [9706101060165]  \n",
       "4                  [3880509524088]  [4617626102085]  \n",
       "5                  [2340862914892]   [358339665507]  \n",
       "6                   [648337018130]  [1399534976844]  \n",
       "7                  [8986386973416]  [7563384088130]  \n",
       "8                  [2836812545211]  [5847830015911]  \n",
       "9                  [6492089346744]  [7534575761576]  \n",
       "10                 [9757549417066]  [8677112089685]  \n",
       "11                 [9790621226361]  [9250994501583]  \n",
       "12                 [3922931562549]   [229720631152]  \n",
       "13                 [5179019038436]  [1306491549530]  \n",
       "14                 [2377196554883]   [410879923414]  \n",
       "15  [2828385250821, 5400110077162]  [4617626102085]  \n",
       "16                 [6982911494472]  [9971387465151]  \n",
       "17                 [1067119077629]  [4358287106424]  \n",
       "18                 [1989665637228]  [1896374821001]  \n",
       "19                 [9237091857812]  [4936975106842]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>209 Richard Glens</td>\n",
       "      <td>Smithborough</td>\n",
       "      <td>Peru</td>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>Christina</td>\n",
       "      <td>209 Richard Glens, Smithborough, Peru</td>\n",
       "      <td>Christina Taylor</td>\n",
       "      <td>F</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>648337018130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>christina taylor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0            address          city country        dob  \\\n",
       "1216        1216  209 Richard Glens  Smithborough    Peru 2015-04-04   \n",
       "\n",
       "     first_name                           full_address         full_name  \\\n",
       "1216  Christina  209 Richard Glens, Smithborough, Peru  Christina Taylor   \n",
       "\n",
       "     gender last_name     member_id middle_name suffix title             fuzzy  \n",
       "1216      F    Taylor  648337018130         NaN    NaN  Mrs.  christina taylor  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>335 Becker Falls Suite 886</td>\n",
       "      <td>Lake Willieton</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>1942-02-13</td>\n",
       "      <td>Christian</td>\n",
       "      <td>335 Becker Falls Suite 886, Lake Willieton, Be...</td>\n",
       "      <td>Christian Taylor</td>\n",
       "      <td>M</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>1399534976844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>christian taylor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                     address            city  country  \\\n",
       "205         205  335 Becker Falls Suite 886  Lake Willieton  Belarus   \n",
       "\n",
       "           dob first_name                                       full_address  \\\n",
       "205 1942-02-13  Christian  335 Becker Falls Suite 886, Lake Willieton, Be...   \n",
       "\n",
       "            full_name gender last_name      member_id middle_name suffix  \\\n",
       "205  Christian Taylor      M    Taylor  1399534976844         NaN    NaN   \n",
       "\n",
       "    title             fuzzy  \n",
       "205   Mr.  christian taylor  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of checking for fuzzy duplicates within one file\n",
    "\n",
    "You need to make sure the value is a string.  \n",
    "You can also here concatenate a few fields to do fuzzy matching across a few fields,  \n",
    "though it maybe better to do separate similarity checks and then work on those scores\n",
    "\n",
    "The routines below would be useful for finding fuzzy duplicates within a file... \n",
    "Because we are comparing against itself, the main loop will grow exponentially with the size of the file, very soon you will be looking at millions of iterations. Think carefully how to reduce the dataset to something relevant and manageable.\n",
    "\n",
    "There are alternative methods for large datasets that involve tokenising parts of the texts and scale better possibly reducing accuracy . These are detailed in another notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "list_to_check= create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(list_to_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-15 21:15:29.168651\n",
      "2021-04-15 21:17:24.201498\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "print(datetime.now())\n",
    "for item in list_to_check:\n",
    "    match = process.extract(item, list_to_check, scorer=fuzz.token_sort_ratio, limit=2 ) #Returns 2 best matches, one will be itself!\n",
    "    matches.append([item,match[0],match[1]])\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tina simon', 'tina simmons', 91],\n",
       " ['billy taylor', 'taylor billy', 100],\n",
       " ['diaz kevin', 'kevin diaz', 100],\n",
       " ['kevin diaz', 'diaz kevin', 100],\n",
       " ['johnny miller', 'john miller', 92],\n",
       " ['jose gonzalez', 'joseph gonzalez', 93],\n",
       " ['matthew j moore', 'matthew moore', 93],\n",
       " ['joseph hall', 'joseph ball', 91],\n",
       " ['joseph ball', 'joseph hall', 91],\n",
       " ['bradley curtis', 'curtis brady', 92],\n",
       " ['danielle williams', 'daniel williams', 94],\n",
       " ['taylor billy', 'billy taylor', 100],\n",
       " ['michael sullivan', 'mitchell sullivan', 91],\n",
       " ['curtis brady', 'bradley curtis', 92],\n",
       " ['matthew moore', 'matthew j moore', 93],\n",
       " ['anthony lewis', 'lewis anthony', 100],\n",
       " ['michael dunn', 'michael duncan', 92],\n",
       " ['john miller', 'johnny miller', 92],\n",
       " ['roy adams', 'troy adams', 95],\n",
       " ['michael duncan', 'michael dunn', 92],\n",
       " ['joseph haynes', 'joseph hayes', 96],\n",
       " ['tina simmons', 'tina simon', 91],\n",
       " ['joseph hayes', 'joseph haynes', 96],\n",
       " ['troy adams', 'roy adams', 95],\n",
       " ['tammy torres', 'amy torres', 91],\n",
       " ['lewis anthony', 'anthony lewis', 100],\n",
       " ['daniel williams', 'danielle williams', 94],\n",
       " ['joseph gonzalez', 'jose gonzalez', 93],\n",
       " ['mitchell sullivan', 'michael sullivan', 91],\n",
       " ['amy torres', 'tammy torres', 91]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to remove the self hit\n",
    "matches_clean=[]\n",
    "for x in matches:\n",
    "    if x[0] == x[1][0]:\n",
    "        a= x[0]\n",
    "        b= x[2][0]\n",
    "        c= x[2][1]\n",
    "    else:\n",
    "        a= x[0]\n",
    "        b= x[1][0]\n",
    "        c= x[1][1]        \n",
    "    matches_clean.append([a,b,c])\n",
    "    \n",
    "likely_matches=[]\n",
    "likely_matches= [[x[0],x[1], x[2]] for x in matches_clean if x[2]>90]\n",
    "likely_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative method with a manual iteration  \n",
    "\n",
    "This method uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc.\n",
    "We need to import the itertools library for its \"combinations\" function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 14)\n",
      "1983\n",
      "1965153 combinations to compute. Careful if this number is large, it may take a long time\n"
     ]
    }
   ],
   "source": [
    "list_to_check= create_fuzzy_column(df_long,\"full_name\")\n",
    "print(df_long.shape)\n",
    "print(len(list_to_check))\n",
    "\n",
    "item_combinations=list(combinations(list_to_check, 2))\n",
    "print(len(item_combinations), \"combinations to compute. Careful if this number is large, it may take a long time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for x in item_combinations:\n",
    "    s = fuzz.token_sort_ratio(x[0],x[1])\n",
    "    if s>60:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])\n",
    "likely_matches = df_matches[df_matches.score > 90]\n",
    "likely_matches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching records as we did a fuzzy match on the simplified and unique values, so there could be more than one per hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list_fat=[]\n",
    "output_list_thin=[]\n",
    "n=1\n",
    "for index,row in likely_matches.iterrows():\n",
    "    key1=df_long.loc[df_long['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    key2=df_long.loc[df_long['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    key_conso=key1+key2\n",
    "    for k in key_conso:\n",
    "        v=df_long[df_long['member_id']==k]['full_name'].to_list()[0] #optional we get the original value\n",
    "        #we could use indexes for extra performance but anyway this routine cannot be run in huge tables\n",
    "        #as the combination would quickly get to tens of millions to check.\n",
    "        output_list_thin.append([k,n,row[2],v])\n",
    "        n=n+1 \n",
    "    output_list_fat.append([row[0], row[1], row[2], key1, key2, len(key_conso)])\n",
    "    \n",
    "output= pd.DataFrame(output_list_fat, columns=['x1','x2','score','k1','k2','countkeys']).sort_values(by=['score'],ascending=False)\n",
    "output_thin=pd.DataFrame(output_list_thin,columns=['id','match_group','score','value']).sort_values(by=['score'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>score</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>countkeys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>billy taylor</td>\n",
       "      <td>taylor billy</td>\n",
       "      <td>100</td>\n",
       "      <td>[7794666749030]</td>\n",
       "      <td>[5433696913272]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diaz kevin</td>\n",
       "      <td>kevin diaz</td>\n",
       "      <td>100</td>\n",
       "      <td>[8914835563291]</td>\n",
       "      <td>[1445917465778]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anthony lewis</td>\n",
       "      <td>lewis anthony</td>\n",
       "      <td>100</td>\n",
       "      <td>[2118643743364]</td>\n",
       "      <td>[9294051750262]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>joseph haynes</td>\n",
       "      <td>joseph hayes</td>\n",
       "      <td>96</td>\n",
       "      <td>[4272394152283]</td>\n",
       "      <td>[4795669425207]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roy adams</td>\n",
       "      <td>troy adams</td>\n",
       "      <td>95</td>\n",
       "      <td>[8904361580121]</td>\n",
       "      <td>[9415236987604]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1             x2  score               k1               k2  \\\n",
       "1    billy taylor   taylor billy    100  [7794666749030]  [5433696913272]   \n",
       "2      diaz kevin     kevin diaz    100  [8914835563291]  [1445917465778]   \n",
       "10  anthony lewis  lewis anthony    100  [2118643743364]  [9294051750262]   \n",
       "13  joseph haynes   joseph hayes     96  [4272394152283]  [4795669425207]   \n",
       "12      roy adams     troy adams     95  [8904361580121]  [9415236987604]   \n",
       "\n",
       "    countkeys  \n",
       "1           2  \n",
       "2           2  \n",
       "10          2  \n",
       "13          2  \n",
       "12          2  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>match_group</th>\n",
       "      <th>score</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9294051750262</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>Lewis, Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7794666749030</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>Billy Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5433696913272</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>Taylor, Billy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8914835563291</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>Diaz, Kevin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1445917465778</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>Kevin Diaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  match_group  score           value\n",
       "24  9294051750262           25    100  Lewis, Anthony\n",
       "2   7794666749030            3    100    Billy Taylor\n",
       "3   5433696913272            4    100   Taylor, Billy\n",
       "4   8914835563291            5    100     Diaz, Kevin\n",
       "5   1445917465778            6    100      Kevin Diaz"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_thin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
