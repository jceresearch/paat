{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated 2/11/2020\n",
    "\n",
    "These example routines use a special library in Python called fuzzywuzzy which implements various strategies for ranking similarity. Absolutely use it. There are other basic libraries but then you need to program the logic on top to make the best choices.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are talking several 100K records things will become exponential and you may not be able to really run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import Levenshtein\n",
    "#Note: apparently installing the python-Levenshtein module alongside fuzzywuzzy can increase performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words. In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "73\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "74\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "77\n",
      "58\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine of checking one file against another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84724 Nicole Villages Suite 945</td>\n",
       "      <td>Leetown</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>84724 Nicole Villages Suite 945, Leetown, New ...</td>\n",
       "      <td>Deborah Nunez</td>\n",
       "      <td>F</td>\n",
       "      <td>Nunez</td>\n",
       "      <td>5102279799502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>658 Aaron Vista Apt. 239</td>\n",
       "      <td>Mistyborough</td>\n",
       "      <td>Micronesia</td>\n",
       "      <td>1958-03-25</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>658 Aaron Vista Apt. 239, Mistyborough, Micron...</td>\n",
       "      <td>Nathan Baker</td>\n",
       "      <td>M</td>\n",
       "      <td>Baker</td>\n",
       "      <td>2719238400725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66108 Vasquez Course</td>\n",
       "      <td>Jeffreymouth</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>1961-07-01</td>\n",
       "      <td>Ronald</td>\n",
       "      <td>66108 Vasquez Course, Jeffreymouth, Serbia</td>\n",
       "      <td>Ronald Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>Smith</td>\n",
       "      <td>5344277168281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>117 Wood Turnpike Apt. 562</td>\n",
       "      <td>North Christopher</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>1951-12-14</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>117 Wood Turnpike Apt. 562, North Christopher,...</td>\n",
       "      <td>Douglas Stephanie Ramirez</td>\n",
       "      <td>M</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>9262734362101</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7483 Nguyen Square</td>\n",
       "      <td>North Benjamin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1950-12-06</td>\n",
       "      <td>Alex</td>\n",
       "      <td>7483 Nguyen Square, North Benjamin, Germany</td>\n",
       "      <td>Alex Curry</td>\n",
       "      <td>M</td>\n",
       "      <td>Curry</td>\n",
       "      <td>2504631179862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          address               city  \\\n",
       "0           0  84724 Nicole Villages Suite 945            Leetown   \n",
       "1           1         658 Aaron Vista Apt. 239       Mistyborough   \n",
       "2           2             66108 Vasquez Course       Jeffreymouth   \n",
       "3           3       117 Wood Turnpike Apt. 562  North Christopher   \n",
       "4           4               7483 Nguyen Square     North Benjamin   \n",
       "\n",
       "       country        dob first_name  \\\n",
       "0  New Zealand 2009-11-05    Deborah   \n",
       "1   Micronesia 1958-03-25     Nathan   \n",
       "2       Serbia 1961-07-01     Ronald   \n",
       "3   Montenegro 1951-12-14    Douglas   \n",
       "4      Germany 1950-12-06       Alex   \n",
       "\n",
       "                                        full_address  \\\n",
       "0  84724 Nicole Villages Suite 945, Leetown, New ...   \n",
       "1  658 Aaron Vista Apt. 239, Mistyborough, Micron...   \n",
       "2         66108 Vasquez Course, Jeffreymouth, Serbia   \n",
       "3  117 Wood Turnpike Apt. 562, North Christopher,...   \n",
       "4        7483 Nguyen Square, North Benjamin, Germany   \n",
       "\n",
       "                   full_name gender last_name      member_id middle_name  \\\n",
       "0              Deborah Nunez      F     Nunez  5102279799502         NaN   \n",
       "1               Nathan Baker      M     Baker  2719238400725         NaN   \n",
       "2               Ronald Smith      M     Smith  5344277168281         NaN   \n",
       "3  Douglas Stephanie Ramirez      M   Ramirez  9262734362101   Stephanie   \n",
       "4                 Alex Curry      M     Curry  2504631179862         NaN   \n",
       "\n",
       "  suffix title  \n",
       "0    NaN   Dr.  \n",
       "1    NaN   Mr.  \n",
       "2    NaN   Mr.  \n",
       "3    NaN   Mr.  \n",
       "4    NaN   Mr.  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98006 Daniel Causeway</td>\n",
       "      <td>Morenoborough</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>1940-10-13</td>\n",
       "      <td>Cynthia</td>\n",
       "      <td>98006 Daniel Causeway, Morenoborough, Palestin...</td>\n",
       "      <td>Cynthia Brandy Brown</td>\n",
       "      <td>F</td>\n",
       "      <td>Brown</td>\n",
       "      <td>4005263871981</td>\n",
       "      <td>Brandy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3871 Stevens Lane Apt. 513</td>\n",
       "      <td>East Margaret</td>\n",
       "      <td>Seychelles</td>\n",
       "      <td>1982-02-03</td>\n",
       "      <td>John</td>\n",
       "      <td>3871 Stevens Lane Apt. 513, East Margaret, Sey...</td>\n",
       "      <td>John Campbell</td>\n",
       "      <td>M</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>5593277759078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>707 Nichole Run</td>\n",
       "      <td>New Jerrybury</td>\n",
       "      <td>France</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>Tara</td>\n",
       "      <td>707 Nichole Run, New Jerrybury, France</td>\n",
       "      <td>Tara Amanda Manning</td>\n",
       "      <td>F</td>\n",
       "      <td>Manning</td>\n",
       "      <td>9253704032896</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29214 Christopher Lodge</td>\n",
       "      <td>Lake Andrew</td>\n",
       "      <td>Isle of Man</td>\n",
       "      <td>1955-11-13</td>\n",
       "      <td>Michaela</td>\n",
       "      <td>29214 Christopher Lodge, Lake Andrew, Isle of Man</td>\n",
       "      <td>Michaela Brock</td>\n",
       "      <td>F</td>\n",
       "      <td>Brock</td>\n",
       "      <td>4666408668950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31860 Earl Stravenue Suite 296</td>\n",
       "      <td>Vickiburgh</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1974-02-17</td>\n",
       "      <td>Peter</td>\n",
       "      <td>31860 Earl Stravenue Suite 296, Vickiburgh, Be...</td>\n",
       "      <td>Peter Perez</td>\n",
       "      <td>M</td>\n",
       "      <td>Perez</td>\n",
       "      <td>4289840277902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         address           city  \\\n",
       "0           0           98006 Daniel Causeway  Morenoborough   \n",
       "1           1      3871 Stevens Lane Apt. 513  East Margaret   \n",
       "2           2                 707 Nichole Run  New Jerrybury   \n",
       "3           3         29214 Christopher Lodge    Lake Andrew   \n",
       "4           4  31860 Earl Stravenue Suite 296     Vickiburgh   \n",
       "\n",
       "                 country        dob first_name  \\\n",
       "0  Palestinian Territory 1940-10-13    Cynthia   \n",
       "1             Seychelles 1982-02-03       John   \n",
       "2                 France 2017-09-13       Tara   \n",
       "3            Isle of Man 1955-11-13   Michaela   \n",
       "4                Belgium 1974-02-17      Peter   \n",
       "\n",
       "                                        full_address             full_name  \\\n",
       "0  98006 Daniel Causeway, Morenoborough, Palestin...  Cynthia Brandy Brown   \n",
       "1  3871 Stevens Lane Apt. 513, East Margaret, Sey...         John Campbell   \n",
       "2             707 Nichole Run, New Jerrybury, France   Tara Amanda Manning   \n",
       "3  29214 Christopher Lodge, Lake Andrew, Isle of Man        Michaela Brock   \n",
       "4  31860 Earl Stravenue Suite 296, Vickiburgh, Be...           Peter Perez   \n",
       "\n",
       "  gender last_name      member_id middle_name suffix title  \n",
       "0      F     Brown  4005263871981      Brandy    NaN  Mrs.  \n",
       "1      M  Campbell  5593277759078         NaN    NaN   Mr.  \n",
       "2      F   Manning  9253704032896      Amanda    NaN  Mrs.  \n",
       "3      F     Brock  4666408668950         NaN    NaN   Dr.  \n",
       "4      M     Perez  4289840277902         NaN    NaN   Mr.  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other charts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "df_long['fuzzy']=df_long['full_name'].str.lower()\n",
    "df_long['fuzzy'] = df_long['fuzzy'].str.replace('\\'', ' ')\n",
    "df_long['fuzzy'] = df_long['fuzzy'].str.replace(' +', ' ')\n",
    "df_long['fuzzy'] = df_long['fuzzy'].str.strip()\n",
    "df_long.set_index('fuzzy')\n",
    "print(df_long.shape)\n",
    "primary_list= list(set(df_long['fuzzy']))\n",
    "print(len(primary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "df_short['fuzzy']=df_short['full_name'].str.lower()\n",
    "df_short['fuzzy'] = df_short['fuzzy'].str.replace('\\'', ' ')\n",
    "df_short['fuzzy'] = df_short['fuzzy'].str.replace(' +', ' ')\n",
    "df_short['fuzzy'] = df_short['fuzzy'].str.strip()\n",
    "df_short.set_index('fuzzy')\n",
    "secondary_list= list(set(df_short['fuzzy']))\n",
    "print(len(secondary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) #Returns tuple of best match and percent fit.\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]]['member_id'].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]]['member_id'].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['primary','secondry','perc_match','key_primary','key_secondary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondry</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>andrew hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[2340862914892]</td>\n",
       "      <td>[358339665507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>david williams</td>\n",
       "      <td>david williams</td>\n",
       "      <td>100</td>\n",
       "      <td>[3922931562549]</td>\n",
       "      <td>[229720631152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>mary hernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[6492089346744]</td>\n",
       "      <td>[7534575761576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>james martin</td>\n",
       "      <td>james martin</td>\n",
       "      <td>100</td>\n",
       "      <td>[7957927902845]</td>\n",
       "      <td>[7488960271747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>michael taylor</td>\n",
       "      <td>michael taylor</td>\n",
       "      <td>100</td>\n",
       "      <td>[2836812545211]</td>\n",
       "      <td>[5847830015911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>christopher brown</td>\n",
       "      <td>christopher brown</td>\n",
       "      <td>100</td>\n",
       "      <td>[502887664677]</td>\n",
       "      <td>[1970815105834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>katherine garcia</td>\n",
       "      <td>garcia, katherine h</td>\n",
       "      <td>94</td>\n",
       "      <td>[7876034075542]</td>\n",
       "      <td>[9706101060165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>george collins</td>\n",
       "      <td>george collins</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>olivia smith</td>\n",
       "      <td>smith, olivia</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>katherine smith</td>\n",
       "      <td>katherine smith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>andrew smith</td>\n",
       "      <td>andrea smith</td>\n",
       "      <td>92</td>\n",
       "      <td>[1989665637228]</td>\n",
       "      <td>[1896374821001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>jamie owens</td>\n",
       "      <td>james owens</td>\n",
       "      <td>91</td>\n",
       "      <td>[2377196554883]</td>\n",
       "      <td>[410879923414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>daniel gonzales</td>\n",
       "      <td>100</td>\n",
       "      <td>[7993593208263]</td>\n",
       "      <td>[140312516230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>joe smith</td>\n",
       "      <td>smith, jose</td>\n",
       "      <td>95</td>\n",
       "      <td>[3880509524088]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>henry martinez</td>\n",
       "      <td>henry martin</td>\n",
       "      <td>92</td>\n",
       "      <td>[6982911494472]</td>\n",
       "      <td>[9971387465151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>christina taylor</td>\n",
       "      <td>christian taylor</td>\n",
       "      <td>94</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>vasquez, robert</td>\n",
       "      <td>robert velasquez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9237091857812]</td>\n",
       "      <td>[4936975106842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>joseph smith</td>\n",
       "      <td>smith, jose</td>\n",
       "      <td>91</td>\n",
       "      <td>[2828385250821, 5400110077162]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>jessica alvarez</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>gary velazquez</td>\n",
       "      <td>vazquez, gary</td>\n",
       "      <td>92</td>\n",
       "      <td>[9757549417066]</td>\n",
       "      <td>[8677112089685]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              primary             secondry  perc_match  \\\n",
       "0    andrew hernandez     andrew hernandez         100   \n",
       "1      david williams       david williams         100   \n",
       "2      mary hernandez       mary hernandez         100   \n",
       "3        james martin         james martin         100   \n",
       "4      michael taylor       michael taylor         100   \n",
       "5   christopher brown    christopher brown         100   \n",
       "6    katherine garcia  garcia, katherine h          94   \n",
       "7      george collins       george collins         100   \n",
       "8        olivia smith        smith, olivia         100   \n",
       "9     katherine smith      katherine smith         100   \n",
       "10       andrew smith         andrea smith          92   \n",
       "11        jamie owens          james owens          91   \n",
       "12    daniel gonzales      daniel gonzales         100   \n",
       "13          joe smith          smith, jose          95   \n",
       "14     henry martinez         henry martin          92   \n",
       "15   christina taylor     christian taylor          94   \n",
       "16    vasquez, robert     robert velasquez          93   \n",
       "17       joseph smith          smith, jose          91   \n",
       "18    jessica alvarez      jessica alvarez         100   \n",
       "19     gary velazquez        vazquez, gary          92   \n",
       "\n",
       "                       key_primary    key_secondary  \n",
       "0                  [2340862914892]   [358339665507]  \n",
       "1                  [3922931562549]   [229720631152]  \n",
       "2                  [6492089346744]  [7534575761576]  \n",
       "3                  [7957927902845]  [7488960271747]  \n",
       "4                  [2836812545211]  [5847830015911]  \n",
       "5                   [502887664677]  [1970815105834]  \n",
       "6                  [7876034075542]  [9706101060165]  \n",
       "7                  [5179019038436]  [1306491549530]  \n",
       "8                  [1067119077629]  [4358287106424]  \n",
       "9                  [8986386973416]  [7563384088130]  \n",
       "10                 [1989665637228]  [1896374821001]  \n",
       "11                 [2377196554883]   [410879923414]  \n",
       "12                 [7993593208263]   [140312516230]  \n",
       "13                 [3880509524088]  [4617626102085]  \n",
       "14                 [6982911494472]  [9971387465151]  \n",
       "15                  [648337018130]  [1399534976844]  \n",
       "16                 [9237091857812]  [4936975106842]  \n",
       "17  [2828385250821, 5400110077162]  [4617626102085]  \n",
       "18                 [9790621226361]  [9250994501583]  \n",
       "19                 [9757549417066]  [8677112089685]  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "      <td>82975 Vargas Rapids Suite 444</td>\n",
       "      <td>Wilsonborough</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>2006-05-07</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>82975 Vargas Rapids Suite 444, Wilsonborough, ...</td>\n",
       "      <td>Katherine Garcia</td>\n",
       "      <td>F</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>7876034075542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>katherine garcia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                        address           city  country  \\\n",
       "671         671  82975 Vargas Rapids Suite 444  Wilsonborough  Ireland   \n",
       "\n",
       "           dob first_name                                       full_address  \\\n",
       "671 2006-05-07  Katherine  82975 Vargas Rapids Suite 444, Wilsonborough, ...   \n",
       "\n",
       "            full_name gender last_name      member_id middle_name suffix  \\\n",
       "671  Katherine Garcia      F    Garcia  7876034075542         NaN    NaN   \n",
       "\n",
       "    title             fuzzy  \n",
       "671   Dr.  katherine garcia  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>664 Jones Cape</td>\n",
       "      <td>North Diane</td>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>1963-05-02</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>664 Jones Cape, North Diane, Norfolk Island</td>\n",
       "      <td>Garcia, Katherine H</td>\n",
       "      <td>F</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>9706101060165</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>garcia, katherine h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         address         city         country        dob  \\\n",
       "213         213  664 Jones Cape  North Diane  Norfolk Island 1963-05-02   \n",
       "\n",
       "    first_name                                 full_address  \\\n",
       "213  Katherine  664 Jones Cape, North Diane, Norfolk Island   \n",
       "\n",
       "               full_name gender last_name      member_id middle_name suffix  \\\n",
       "213  Garcia, Katherine H      F    Garcia  9706101060165           H    NaN   \n",
       "\n",
       "    title                fuzzy  \n",
       "213   Dr.  garcia, katherine h  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of checking for fuzzy duplicates within one file\n",
    "\n",
    "You need to make sure the value is a string.  \n",
    "You can also here concatenate a few fields to do fuzzy matching across a few fields,  \n",
    "though it maybe better to do separate similarity checks and then work on those scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1983\n"
     ]
    }
   ],
   "source": [
    "df =pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "df['fuzzy'] =  df['full_name'].str.lower()\n",
    "df['fuzzy'] = df['fuzzy'].str.replace('\\'', ' ')\n",
    "df['fuzzy'] = df['fuzzy'].str.replace(' +', ' ')\n",
    "df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "print(df.shape)\n",
    "list_to_check= list(set(df['fuzzy']))\n",
    "print(len(list_to_check))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 09:57:31.187752\n",
      "2020-11-02 09:58:19.090258\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "print(datetime.now())\n",
    "for item in list_to_check:\n",
    "    match = process.extract(item, list_to_check, scorer=fuzz.token_sort_ratio, limit=2 ) #Returns 2 best matches, one will be itself!\n",
    "    matches.append([item,match[0],match[1]])\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['amy torres', 'tammy torres', 91],\n",
       " ['joseph ball', 'joseph hall', 91],\n",
       " ['billy taylor', 'taylor, billy', 100],\n",
       " ['joseph gonzalez', 'jose gonzalez', 93],\n",
       " ['mitchell sullivan', 'michael sullivan', 91],\n",
       " ['daniel williams', 'danielle williams', 94],\n",
       " ['jose gonzalez', 'joseph gonzalez', 93],\n",
       " ['tina simon', 'tina simmons', 91],\n",
       " ['michael sullivan', 'mitchell sullivan', 91],\n",
       " ['matthew j moore', 'matthew moore', 93],\n",
       " ['michael dunn', 'michael duncan', 92],\n",
       " ['danielle williams', 'daniel williams', 94],\n",
       " ['joseph haynes', 'joseph hayes', 96],\n",
       " ['diaz, kevin', 'kevin diaz', 100],\n",
       " ['michael duncan', 'michael dunn', 92],\n",
       " ['bradley curtis', 'curtis brady', 92],\n",
       " ['troy adams', 'roy adams', 95],\n",
       " ['anthony lewis', 'lewis, anthony', 100],\n",
       " ['curtis brady', 'bradley curtis', 92],\n",
       " ['taylor, billy', 'billy taylor', 100],\n",
       " ['john miller', 'johnny miller', 92],\n",
       " ['tina simmons', 'tina simon', 91],\n",
       " ['roy adams', 'troy adams', 95],\n",
       " ['kevin diaz', 'diaz, kevin', 100],\n",
       " ['matthew moore', 'matthew j moore', 93],\n",
       " ['lewis, anthony', 'anthony lewis', 100],\n",
       " ['joseph hall', 'joseph ball', 91],\n",
       " ['johnny miller', 'john miller', 92],\n",
       " ['tammy torres', 'amy torres', 91],\n",
       " ['joseph hayes', 'joseph haynes', 96]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to remove the self hit\n",
    "matches_clean=[]\n",
    "for x in matches:\n",
    "    if x[0] == x[1][0]:\n",
    "        a= x[0]\n",
    "        b= x[2][0]\n",
    "        c= x[2][1]\n",
    "    else:\n",
    "        a= x[0]\n",
    "        b= x[1][0]\n",
    "        c= x[1][1]        \n",
    "    matches_clean.append([a,b,c])\n",
    "    \n",
    "likely_matches=[]\n",
    "likely_matches= [[x[0],x[1], x[2]] for x in matches_clean if x[2]>90]\n",
    "likely_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative method with a manual iteration  \n",
    "\n",
    "This method uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "item_combinations=list(combinations(list_to_check, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for x in item_combinations:\n",
    "    s = fuzz.token_sort_ratio(x[0],x[1])\n",
    "    if s>60:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])\n",
    "\n",
    "likely_matches = df_matches[df_matches.score > 90]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching records as we did a fuzzy match on the simplified and unique values, so there could be more than one per hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 5)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list=[]\n",
    "for index,row in likely_matches.iterrows():\n",
    "    key1=df.loc[df['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    key2=df.loc[df['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    output_list.append([row['x1'],row['x2'], row['score'], key1, key2])\n",
    "output= pd.DataFrame(output_list, columns=['x1','x2','score','k1','k2'])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>score</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>amy torres</td>\n",
       "      <td>tammy torres</td>\n",
       "      <td>91</td>\n",
       "      <td>[2700300227159]</td>\n",
       "      <td>[4066256017823]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>joseph ball</td>\n",
       "      <td>joseph hall</td>\n",
       "      <td>91</td>\n",
       "      <td>[4437763835086]</td>\n",
       "      <td>[9554307555868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>billy taylor</td>\n",
       "      <td>taylor, billy</td>\n",
       "      <td>100</td>\n",
       "      <td>[7794666749030]</td>\n",
       "      <td>[5433696913272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>joseph gonzalez</td>\n",
       "      <td>jose gonzalez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9305307561485]</td>\n",
       "      <td>[4774921940030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mitchell sullivan</td>\n",
       "      <td>michael sullivan</td>\n",
       "      <td>91</td>\n",
       "      <td>[1296517170926]</td>\n",
       "      <td>[825827228877, 9520235523057]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>daniel williams</td>\n",
       "      <td>danielle williams</td>\n",
       "      <td>94</td>\n",
       "      <td>[6978712771492]</td>\n",
       "      <td>[8127440448529, 952131193062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>tina simon</td>\n",
       "      <td>tina simmons</td>\n",
       "      <td>91</td>\n",
       "      <td>[9856537464638]</td>\n",
       "      <td>[2883744213749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>matthew j moore</td>\n",
       "      <td>matthew moore</td>\n",
       "      <td>93</td>\n",
       "      <td>[3450342297878]</td>\n",
       "      <td>[3873363814785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>michael dunn</td>\n",
       "      <td>michael duncan</td>\n",
       "      <td>92</td>\n",
       "      <td>[8955508677235]</td>\n",
       "      <td>[6750866325253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>joseph haynes</td>\n",
       "      <td>joseph hayes</td>\n",
       "      <td>96</td>\n",
       "      <td>[4272394152283]</td>\n",
       "      <td>[4795669425207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>diaz, kevin</td>\n",
       "      <td>kevin diaz</td>\n",
       "      <td>100</td>\n",
       "      <td>[8914835563291]</td>\n",
       "      <td>[1445917465778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>bradley curtis</td>\n",
       "      <td>curtis brady</td>\n",
       "      <td>92</td>\n",
       "      <td>[8317444954571]</td>\n",
       "      <td>[9926822808017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>troy adams</td>\n",
       "      <td>roy adams</td>\n",
       "      <td>95</td>\n",
       "      <td>[9415236987604]</td>\n",
       "      <td>[8904361580121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>anthony lewis</td>\n",
       "      <td>lewis, anthony</td>\n",
       "      <td>100</td>\n",
       "      <td>[2118643743364]</td>\n",
       "      <td>[9294051750262]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>john miller</td>\n",
       "      <td>johnny miller</td>\n",
       "      <td>92</td>\n",
       "      <td>[6774632622452, 6261795470414]</td>\n",
       "      <td>[4268725868367]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x1                 x2  score  \\\n",
       "0          amy torres       tammy torres     91   \n",
       "1         joseph ball        joseph hall     91   \n",
       "2        billy taylor      taylor, billy    100   \n",
       "3     joseph gonzalez      jose gonzalez     93   \n",
       "4   mitchell sullivan   michael sullivan     91   \n",
       "5     daniel williams  danielle williams     94   \n",
       "6          tina simon       tina simmons     91   \n",
       "7     matthew j moore      matthew moore     93   \n",
       "8        michael dunn     michael duncan     92   \n",
       "9       joseph haynes       joseph hayes     96   \n",
       "10        diaz, kevin         kevin diaz    100   \n",
       "11     bradley curtis       curtis brady     92   \n",
       "12         troy adams          roy adams     95   \n",
       "13      anthony lewis     lewis, anthony    100   \n",
       "14        john miller      johnny miller     92   \n",
       "\n",
       "                                k1                             k2  \n",
       "0                  [2700300227159]                [4066256017823]  \n",
       "1                  [4437763835086]                [9554307555868]  \n",
       "2                  [7794666749030]                [5433696913272]  \n",
       "3                  [9305307561485]                [4774921940030]  \n",
       "4                  [1296517170926]  [825827228877, 9520235523057]  \n",
       "5                  [6978712771492]  [8127440448529, 952131193062]  \n",
       "6                  [9856537464638]                [2883744213749]  \n",
       "7                  [3450342297878]                [3873363814785]  \n",
       "8                  [8955508677235]                [6750866325253]  \n",
       "9                  [4272394152283]                [4795669425207]  \n",
       "10                 [8914835563291]                [1445917465778]  \n",
       "11                 [8317444954571]                [9926822808017]  \n",
       "12                 [9415236987604]                [8904361580121]  \n",
       "13                 [2118643743364]                [9294051750262]  \n",
       "14  [6774632622452, 6261795470414]                [4268725868367]  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
