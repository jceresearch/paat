{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of fuzzy matching \n",
    "\n",
    "updated 1/6/2021  \n",
    "\n",
    "These example routines use a library in Python called fuzzywuzzy which implements various strategies for ranking similarity.\n",
    "\n",
    "Note that this approach works for a relatively low number of records. If you are tackling several 100K records, the process will become exponential and you may not be able to run these. There are some approaches for large scale comparisons in a separate recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein library not installed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "from functools import lru_cache # This library implements in memory storage aka \"caching\" of the last recently used results, which helps to speed up *re* calculations when the same value appears again.\n",
    "import string\n",
    "import math\n",
    " \n",
    "\n",
    "try:\n",
    "    from Levenshtein import ratio, distance\n",
    "except:\n",
    "    print(\"Levenshtein library not installed\")\n",
    "#Installing the python-Levenshtein module alongside fuzzywuzzy will increase performance\n",
    "#as it comes with a C language implementation\n",
    "\n",
    "try:\n",
    "    import distance\n",
    "except:\n",
    "    print(\"Distance library not installed\")\n",
    "#this is another library that seems to implement text distance, but it is pure python too\n",
    "#so it will be slower\n",
    "\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "#we need this for the alternative method of self matching, ie fuzzy duplicates \n",
    "# we use combinations_with_replacement instead of combinations to include the self comparison\n",
    "# when there are many records that matches the pre-processed string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by  \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Levenshtein distance is a metric to measure how apart are two sequences of words.  \n",
    "In other words, it measures the minimum number of edits that you need to do to change a one-word sequence into the other. These edits can be insertions, deletions or substitutions. This metric was named after Vladimir Levenshtein, who originally considered it in 1965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 95\n",
      "Distance 1\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Distance= distance.levenshtein(Str1.lower(),Str2.lower())\n",
    "print(\"Ratio\",Ratio)\n",
    "print(\"Distance\",Distance) # Should be 1 after making all string same case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "73\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Los Angeles Lakers\"\n",
    "Str2 = \"L.A. Lakers\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.partial_ratio() is capable of detecting that both strings are referring to the Lakers. Thus, it yields 100% similarity. The way this works is by using an \"optimal partial\" logic. In other words, if the short string has length k and the longer string has the length m, then the algorithm seeks the score of the best matching length-k substring.\n",
    "\n",
    "Nevertheless, this approach is not foolproof. What happens when the strings comparison the same, but they are in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "74\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"united states v. nixon\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzz.token functions have an important advantage over ratio and partial_ratio. They tokenize the strings and preprocess them by turning them to lower case and getting rid of punctuation. In the case of fuzz.token_sort_ratio(), the string tokens get sorted alphabetically and then joined together. After that, a simple fuzz.ratio() is applied to obtain the similarity percentage. This allows cases such as court cases in this example to be marked as being the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, what happens if these two strings are of widely differing lengths? Thats where fuzz.token_set_ratio() comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "77\n",
      "58\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"The supreme court case of Nixon vs The United States\"\n",
    "Str2 = \"Nixon v. United States\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuzz.token_set_ratio() takes a more flexible approach than fuzz.token_sort_ratio(). Instead of just tokenizing the strings, sorting and then pasting the tokens back together, token_set_ratio performs a set operation that takes out the common tokens (the intersection) and then makes fuzz.ratio() pairwise comparisons between the following new strings:\n",
    "\n",
    "s1 = Sorted_tokens_in_intersection  \n",
    "s2 = Sorted_tokens_in_intersection + sorted_rest_of_str1_tokens  \n",
    "s3 = Sorted_tokens_in_intersection + sorted_rest_of_str2_tokens  \n",
    "The logic behind these comparisons is that since Sorted_tokens_in_intersection is always the same, the score will tend to go up as these words make up a larger chunk of the original strings or the remaining tokens are closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical examples  \n",
    "\n",
    "We are going now to do 2 examples, with slightly different approaches.  \n",
    "One is a file against another, to do a fuzzy lookup.  \n",
    "The other is a file against itself, to do a fuzzy duplicate detection/grouping.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to import the needed libraries and a common \"preprocessing\" function to cleanup the column we are going to use.  \n",
    "Fuzzywuzzy also does preprocessing, but I find that it may be better to do it manually in bulk ourselves to control exactly what we are dropping, there may be cases we want to ignore like special characters or abbreviations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None) #we enable the caching in this small piece, maxsize is set to unlimited, but we could add a limit , apparently having an actual limit makes it marginally faster in some conditions.\n",
    "def token_sort(s):\n",
    "    s=str(s)\n",
    "    s=s.translate(str.maketrans('', '', string.punctuation))\n",
    "    sl= str.split(s)\n",
    "    sl.sort()\n",
    "    s= \"\".join(sl)\n",
    "    return s\n",
    "\n",
    "def create_fuzzy_column(df,col_name):\n",
    "    df['fuzzy']=df[col_name].str.lower()\n",
    "    df['fuzzy'].replace(\"\\'\", '',regex= True , inplace=True)\n",
    "    df['fuzzy'].replace(r'\\s', ' ', regex = True, inplace = True)\n",
    "    df['fuzzy'].replace(\"\",np.nan,regex=True, inplace=True)\n",
    "    #This will directly remove accented chars and enie , not replace with the vowel or n   \n",
    "    #df['fuzzy'] = df['fuzzy'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    #This will also remove accented chars \n",
    "    #from string import printable\n",
    "    #st = set(printable)\n",
    "    #df[\"fuzzy\"] = df[\"fuzzy\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))   \n",
    "    #This will retain the characters but standardise for compatibility, there are various\n",
    "    #libraries that do that too.  \n",
    "    df[\"fuzzy\"]= df[\"fuzzy\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[\"fuzzy\"].replace('[^a-z1-9 ]', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' ltd',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' plc',\" \", regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' llp',\" \",regex=True, inplace=True)   \n",
    "    df['fuzzy'].replace(' limited',\" \", regex=True , inplace=True)\n",
    "    df['fuzzy'].replace(\"mr \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"mrs \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"ms \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(\"miss \",\" \",regex=True, inplace=True)\n",
    "    df['fuzzy'].replace(' +', ' ', regex=True, inplace=True)\n",
    "    df['fuzzy'] = df['fuzzy'].str.strip()\n",
    "    list_token_sort=[token_sort(s) for s in df[\"fuzzy\"]]\n",
    "    s = pd.Series(list_token_sort)\n",
    "    df['fuzzy'] = s.values\n",
    "    df.set_index('fuzzy')\n",
    "    return list(df['fuzzy'][~pd.isnull(df.fuzzy)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small test of the routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linenew', 'inaqui', 'entrytab', 'lucia', 'nan', 'oneillryan', 'anamaria', '2ndjohnsmith', 'druckerpeter', 'emmawatson', 'bezosjeff', 'bezosjeff', 'amazon']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>expected</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New\\rLine</td>\n",
       "      <td>linenew</td>\n",
       "      <td>linenew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iñaqui</td>\n",
       "      <td>inaqui</td>\n",
       "      <td>inaqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tab\\tEntry</td>\n",
       "      <td>entrytab</td>\n",
       "      <td>entrytab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucía</td>\n",
       "      <td>lucia</td>\n",
       "      <td>lucia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mr. Ryan     O'Neill</td>\n",
       "      <td>oneillryan</td>\n",
       "      <td>oneillryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ana-María</td>\n",
       "      <td>anamaria</td>\n",
       "      <td>anamaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John Smith 2nd</td>\n",
       "      <td>2ndjohnsmith</td>\n",
       "      <td>2ndjohnsmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter＿Drücker</td>\n",
       "      <td>druckerpeter</td>\n",
       "      <td>druckerpeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emma_Watson</td>\n",
       "      <td>emma watson</td>\n",
       "      <td>emmawatson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>bezosjeff</td>\n",
       "      <td>bezosjeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jeff   . Bezos</td>\n",
       "      <td>bezosjeff</td>\n",
       "      <td>bezosjeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amazon Ltd.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   input      expected         fuzzy\n",
       "0              New\\rLine       linenew       linenew\n",
       "1               Iñaqui          inaqui        inaqui\n",
       "2             Tab\\tEntry      entrytab      entrytab\n",
       "3                  Lucía         lucia         lucia\n",
       "4                                  NaN           nan\n",
       "5   Mr. Ryan     O'Neill    oneillryan    oneillryan\n",
       "6              Ana-María      anamaria      anamaria\n",
       "7         John Smith 2nd  2ndjohnsmith  2ndjohnsmith\n",
       "8          Peter＿Drücker  druckerpeter  druckerpeter\n",
       "9            Emma_Watson   emma watson    emmawatson\n",
       "10            Jeff Bezos     bezosjeff     bezosjeff\n",
       "11      jeff   . Bezos       bezosjeff     bezosjeff\n",
       "12           Amazon Ltd.        amazon        amazon"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [[\"  New\\rLine\",\"linenew\"],['Iñaqui  ', 'inaqui'], [\"Tab\\tEntry\", \"entrytab\"], ['Lucía',\"lucia\"], [\"\",\"NaN\"], [\"Mr. Ryan     O'Neill\",\"oneillryan\"],[\"Ana-María\",\"anamaria\"],[\"John Smith 2nd\",\"2ndjohnsmith\"],[\"Peter\\uFF3FDrücker\",\"druckerpeter\"],[\"Emma\\u005FWatson\",\"emma watson\"],[\"Jeff Bezos\",\"bezosjeff\"],[\"  jeff   . Bezos  \",\"bezosjeff\"],[\"Amazon Ltd.\",\"amazon\"]]\n",
    "test_df = pd.DataFrame(test_data, columns = ['input', 'expected']) \n",
    "test_list= create_fuzzy_column(test_df,'input')\n",
    "print(test_list)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a routine for checking one file against another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the fuzzy matching already ignores cases and special chars, it perhaps convenient to do a bit of cleanup in advance. This is because when you pick the unique values via \"set\" command and when you queries for potential matches afterwards, you would have a cleaner and smaller set of data. Possibly worth also removing other artifacts like aphostrophes and double spaces, trimming trailing spaces etc.\n",
    "\n",
    "Also note that using a generic fuzzy field makes the rest of the routine more reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short= pd.read_excel(\"./test_data/data_short.xlsx\")\n",
    "df_long=pd.read_excel(\"./test_data/data_long.xlsx\")\n",
    "field_to_match='full_name'\n",
    "row_id='member_id'  # unique identifier of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n"
     ]
    }
   ],
   "source": [
    "primary_list=list(set(create_fuzzy_column(df_long,field_to_match))) \n",
    "#we do set to remove duplicates and reduce the comparisons, we will pick all the exact duplicates\n",
    "#anyway when we reconstruct the hits\n",
    "print(df_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 15)\n"
     ]
    }
   ],
   "source": [
    "secondary_list= list(set(create_fuzzy_column(df_short,field_to_match)))\n",
    "print(df_short.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for item in primary_list:\n",
    "    if type(item) != str: # Checking base case. \n",
    "        pass\n",
    "    else:\n",
    "        match = process.extractOne(item, secondary_list, scorer=fuzz.token_sort_ratio) \n",
    "        #Returns tuple (pairs) of best match and percent fit.\n",
    "        #We are letting the algorithm pick the winner, so it is important to choose \n",
    "        #the right method. We used \"token sort ratio\" but you should check the variants\n",
    "        matches.append([item,match[0],match[1]])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we sort descending a list of lists by some field (and retrieve first 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['oliviasmith', 'oliviasmith', 100],\n",
       " ['katherinesmith', 'katherinesmith', 100],\n",
       " ['alvarezjessica', 'alvarezjessica', 100],\n",
       " ['collinsgeorge', 'collinsgeorge', 100],\n",
       " ['danielgonzales', 'danielgonzales', 100]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(matches, reverse=True, key=lambda x: x[2])[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we filter by some threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_matches=[]\n",
    "likely_matches= [x for x in matches if x[2]>90]\n",
    "len(likely_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is to recreate the actual records in the file with an identifier key, the reason is that we could technically have more than one hit per each duplicate found (if the file has duplicates itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list=[]\n",
    "for x in likely_matches:\n",
    "    key1=df_long.loc[df_long['fuzzy'] == x[0]][row_id].tolist()\n",
    "    key2=df_short.loc[df_short['fuzzy'] == x[1]][row_id].tolist()\n",
    "    output_list.append([x[0], x[1], x[2], key1, key2])\n",
    "# this produces yet another list of list, we better load it into a dataframe for convenience\n",
    "# key1 and key2 are lists because there could be more than one record for that fuzzyied string\n",
    "# one option is to just pick the first ie use key1[0] and key2[0] \n",
    "# another option is to use a routine to convert these into individual rows, see next example \n",
    "# where we do precisely that\n",
    "# another option is to do some hacks with excel to split that list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christinataylor</td>\n",
       "      <td>christiantaylor</td>\n",
       "      <td>93</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>danielgonzales</td>\n",
       "      <td>danielgonzales</td>\n",
       "      <td>100</td>\n",
       "      <td>[7993593208263]</td>\n",
       "      <td>[140312516230]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>davidwilliams</td>\n",
       "      <td>davidwilliams</td>\n",
       "      <td>100</td>\n",
       "      <td>[3922931562549]</td>\n",
       "      <td>[229720631152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>henrymartinez</td>\n",
       "      <td>henrymartin</td>\n",
       "      <td>92</td>\n",
       "      <td>[6982911494472]</td>\n",
       "      <td>[9971387465151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joesmith</td>\n",
       "      <td>josesmith</td>\n",
       "      <td>94</td>\n",
       "      <td>[3880509524088]</td>\n",
       "      <td>[4617626102085]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>garciakatherine</td>\n",
       "      <td>garciahkatherine</td>\n",
       "      <td>97</td>\n",
       "      <td>[7876034075542]</td>\n",
       "      <td>[9706101060165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>andrewsmith</td>\n",
       "      <td>andreasmith</td>\n",
       "      <td>91</td>\n",
       "      <td>[1989665637228]</td>\n",
       "      <td>[1896374821001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>garyvelazquez</td>\n",
       "      <td>garyvazquez</td>\n",
       "      <td>92</td>\n",
       "      <td>[9757549417066]</td>\n",
       "      <td>[8677112089685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jamesmartin</td>\n",
       "      <td>jamesmartin</td>\n",
       "      <td>100</td>\n",
       "      <td>[7957927902845]</td>\n",
       "      <td>[7488960271747]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>michaeltaylor</td>\n",
       "      <td>michaeltaylor</td>\n",
       "      <td>100</td>\n",
       "      <td>[2836812545211]</td>\n",
       "      <td>[5847830015911]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>robertvasquez</td>\n",
       "      <td>robertvelasquez</td>\n",
       "      <td>93</td>\n",
       "      <td>[9237091857812]</td>\n",
       "      <td>[4936975106842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>andrewhernandez</td>\n",
       "      <td>andrewhernandez</td>\n",
       "      <td>100</td>\n",
       "      <td>[2340862914892]</td>\n",
       "      <td>[358339665507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>brownchristopher</td>\n",
       "      <td>brownchristopher</td>\n",
       "      <td>100</td>\n",
       "      <td>[502887664677]</td>\n",
       "      <td>[1970815105834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hernandezmary</td>\n",
       "      <td>hernandezmary</td>\n",
       "      <td>100</td>\n",
       "      <td>[6492089346744]</td>\n",
       "      <td>[7534575761576]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             primary         secondary  ...      key_primary    key_secondary\n",
       "0        oliviasmith       oliviasmith  ...  [1067119077629]  [4358287106424]\n",
       "1     katherinesmith    katherinesmith  ...  [8986386973416]  [7563384088130]\n",
       "2    christinataylor   christiantaylor  ...   [648337018130]  [1399534976844]\n",
       "3     alvarezjessica    alvarezjessica  ...  [9790621226361]  [9250994501583]\n",
       "4      collinsgeorge     collinsgeorge  ...  [5179019038436]  [1306491549530]\n",
       "5     danielgonzales    danielgonzales  ...  [7993593208263]   [140312516230]\n",
       "6      davidwilliams     davidwilliams  ...  [3922931562549]   [229720631152]\n",
       "7      henrymartinez       henrymartin  ...  [6982911494472]  [9971387465151]\n",
       "8           joesmith         josesmith  ...  [3880509524088]  [4617626102085]\n",
       "9    garciakatherine  garciahkatherine  ...  [7876034075542]  [9706101060165]\n",
       "10       andrewsmith       andreasmith  ...  [1989665637228]  [1896374821001]\n",
       "11     garyvelazquez       garyvazquez  ...  [9757549417066]  [8677112089685]\n",
       "12       jamesmartin       jamesmartin  ...  [7957927902845]  [7488960271747]\n",
       "13     michaeltaylor     michaeltaylor  ...  [2836812545211]  [5847830015911]\n",
       "14     robertvasquez   robertvelasquez  ...  [9237091857812]  [4936975106842]\n",
       "15   andrewhernandez   andrewhernandez  ...  [2340862914892]   [358339665507]\n",
       "16  brownchristopher  brownchristopher  ...   [502887664677]  [1970815105834]\n",
       "17     hernandezmary     hernandezmary  ...  [6492089346744]  [7534575761576]\n",
       "\n",
       "[18 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output= pd.DataFrame(output_list, columns=['primary','secondary','perc_match','key_primary','key_secondary'])\n",
    "output[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.iat[0,2] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.iat[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>perc_match</th>\n",
       "      <th>key_primary</th>\n",
       "      <th>key_secondary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>oliviasmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[1067119077629]</td>\n",
       "      <td>[4358287106424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>katherinesmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8986386973416]</td>\n",
       "      <td>[7563384088130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christinataylor</td>\n",
       "      <td>christiantaylor</td>\n",
       "      <td>93</td>\n",
       "      <td>[648337018130]</td>\n",
       "      <td>[1399534976844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>alvarezjessica</td>\n",
       "      <td>100</td>\n",
       "      <td>[9790621226361]</td>\n",
       "      <td>[9250994501583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>collinsgeorge</td>\n",
       "      <td>100</td>\n",
       "      <td>[5179019038436]</td>\n",
       "      <td>[1306491549530]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           primary        secondary  ...      key_primary    key_secondary\n",
       "0      oliviasmith      oliviasmith  ...  [1067119077629]  [4358287106424]\n",
       "1   katherinesmith   katherinesmith  ...  [8986386973416]  [7563384088130]\n",
       "2  christinataylor  christiantaylor  ...   [648337018130]  [1399534976844]\n",
       "3   alvarezjessica   alvarezjessica  ...  [9790621226361]  [9250994501583]\n",
       "4    collinsgeorge    collinsgeorge  ...  [5179019038436]  [1306491549530]\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>1957</td>\n",
       "      <td>3069 Kimberly Ways Suite 864</td>\n",
       "      <td>Port Michael</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1949-10-01</td>\n",
       "      <td>David</td>\n",
       "      <td>3069 Kimberly Ways Suite 864, Port Michael, Ic...</td>\n",
       "      <td>David Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>Williams</td>\n",
       "      <td>3922931562549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>davidwilliams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       address  ... title          fuzzy\n",
       "1957        1957  3069 Kimberly Ways Suite 864  ...   Mr.  davidwilliams\n",
       "\n",
       "[1 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long[df_long['member_id']==output.iloc[6][3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>dob</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_address</th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>member_id</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>fuzzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>753 Leonard Ridge</td>\n",
       "      <td>West Andrea</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>1976-11-11</td>\n",
       "      <td>David</td>\n",
       "      <td>753 Leonard Ridge, West Andrea, Monaco</td>\n",
       "      <td>David Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>Williams</td>\n",
       "      <td>229720631152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>davidwilliams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            address         city  ... suffix title          fuzzy\n",
       "6           6  753 Leonard Ridge  West Andrea  ...    NaN   Mr.  davidwilliams\n",
       "\n",
       "[1 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short[df_short['member_id']==output.iloc[6][4][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for fuzzy duplicates within one file\n",
    "\n",
    "Because we are comparing against itself, the main loop will grow exponentially with the size of the file, very soon you will be looking at millions of iterations. Think carefully how to reduce the dataset to something relevant and manageable.\n",
    "\n",
    "There are alternative methods for large datasets that involve tokenising parts of the texts and scale better possibly reducing accuracy . These are detailed in another notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This method below uses a more manual approach to select the combinations of items in this case we can retrieve as many similar items meet the criteria based on the similarity score and not just the top 1 or 2 etc.\n",
    "We need to import the itertools library for its \"combinations\" function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 15)\n",
      "1980\n",
      "1961190 combinations to compute. Careful if this number is large, it may take a long time\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=df_long.copy()\n",
    "list_to_check= list(sorted(set(create_fuzzy_column(df,\"full_name\"))))\n",
    "print(df.shape)\n",
    "print(len(list_to_check))\n",
    "\n",
    "item_combinations=list(combinations_with_replacement(list_to_check, 2))\n",
    "print(len(item_combinations), \"combinations to compute. Careful if this number is large, it may take a long time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-Jun-2021 13:21:08\n",
      "06-Jun-2021 13:21:53\n",
      "Minutes 0.76\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start=datetime.datetime.now()\n",
    "print(start.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "matches = []\n",
    "@lru_cache(maxsize=100000)\n",
    "def get_ratio(a,b):\n",
    "    #r = fuzz.token_sort_ratio(a,b)# not needed as we did token sort in pre processing\n",
    "    r=fuzz.ratio(a,b)\n",
    "    #r=ratio(a,b)*100 #this uses the Levinshtein libary directly, should be fast\n",
    "    return r\n",
    "\n",
    "for x in item_combinations:\n",
    "    s=get_ratio(x[0],x[1])\n",
    "    if s>89:\n",
    "        matches.append([x[0], x[1], s]) \n",
    "        \n",
    "print (datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "print (\"Minutes\", round((datetime.datetime.now()-start).total_seconds()/(60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches=pd.DataFrame(matches, columns=['x1','x2','score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we still need to go back to the original dataset and find the matching groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list_fat=[]\n",
    "output_list_thin=[]\n",
    "match_group=1\n",
    "for index,row in df_matches.iterrows():\n",
    "    key1=df.loc[df['fuzzy'] == row['x1']]['member_id'].tolist()\n",
    "    if row['x1']==row['x2']:\n",
    "        if len(key1)<=1:\n",
    "            #there is only one instance in the population, no real match, back to for loop\n",
    "            continue\n",
    "        key2=[] # these are exact matches against the preprocessed value, we count only once\n",
    "    else:\n",
    "        key2=df.loc[df_long['fuzzy'] == row['x2']]['member_id'].tolist()\n",
    "    key_conso=key1+key2\n",
    "    for k in key_conso:\n",
    "        v=df[df['member_id']==k]['full_name'].to_list()[0] #optional we get the original value\n",
    "        #we could use indexes for extra performance but anyway this routine cannot be run in huge tables\n",
    "        #as the combination would quickly get to tens of millions to check.\n",
    "        output_list_thin.append([k,match_group,row[2],v])\n",
    "    output_list_fat.append([row[0], row[1], row[2], key1, key2, len(key_conso),match_group])\n",
    "    match_group +=1 \n",
    "    \n",
    "output= pd.DataFrame(output_list_fat, columns=['x1','x2','score','k1','k2','countkeys','match_group']).sort_values(by=['score'],ascending=False)\n",
    "output_thin=pd.DataFrame(output_list_thin,columns=['id','match_group','score','value']).sort_values(by=['score'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>score</th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th>countkeys</th>\n",
       "      <th>match_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>michaelsullivan</td>\n",
       "      <td>michaelsullivan</td>\n",
       "      <td>100</td>\n",
       "      <td>[825827228877, 9520235523057]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>michaelthomas</td>\n",
       "      <td>michaelthomas</td>\n",
       "      <td>100</td>\n",
       "      <td>[3747334520428, 7537589811664]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>johnmiller</td>\n",
       "      <td>johnmiller</td>\n",
       "      <td>100</td>\n",
       "      <td>[6774632622452, 6261795470414]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>brownjohn</td>\n",
       "      <td>brownjohn</td>\n",
       "      <td>100</td>\n",
       "      <td>[8673512181554, 7506296213450]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>laurensmith</td>\n",
       "      <td>laurensmith</td>\n",
       "      <td>100</td>\n",
       "      <td>[8579400177275, 8950577347478]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1               x2  score  ...  k2 countkeys  match_group\n",
       "17  michaelsullivan  michaelsullivan    100  ...  []         2           18\n",
       "13    michaelthomas    michaelthomas    100  ...  []         2           14\n",
       "32       johnmiller       johnmiller    100  ...  []         2           33\n",
       "31        brownjohn        brownjohn    100  ...  []         2           32\n",
       "30      laurensmith      laurensmith    100  ...  []         2           31\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>match_group</th>\n",
       "      <th>score</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55177040885</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>Brian Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>406297274061</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>Brian Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3916487516460</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>Jacqueline Hernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9001733828207</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>Jacqueline Hernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5400110077162</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2828385250821</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5433696913272</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>Taylor, Billy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7794666749030</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>Billy Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3632687508653</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2447864260207</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3054578050438</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>David Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6332467549384</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>David Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7537589811664</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3747334520428</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1445917465778</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>Kevin Diaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8914835563291</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>Diaz, Kevin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>825827228877</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Sullivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9520235523057</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>Michael Sullivan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7039363481297</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>Amanda Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>231280510563</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>Amanda Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>9294051750262</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>Lewis, Anthony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2118643743364</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>Anthony Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1360800895169</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>Christopher Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7072377543230</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>Christopher Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3175587312222</td>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>Thomas Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>7249915988253</td>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>Thomas Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4716904989414</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>7345449199476</td>\n",
       "      <td>28</td>\n",
       "      <td>100</td>\n",
       "      <td>Joseph Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>952131193062</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>Danielle Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>8127440448529</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>Danielle Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>8844950381619</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>Heather Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>9432861001628</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>Heather Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8579400177275</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>Lauren Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8950577347478</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>Lauren Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7506296213450</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>John Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8673512181554</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>John Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6261795470414</td>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>John Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6774632622452</td>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>John Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>184447183004</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>Linda Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3213723680900</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>Linda Brown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  match_group  score                 value\n",
       "7     55177040885            4    100        Brian Williams\n",
       "6    406297274061            4    100        Brian Williams\n",
       "8   3916487516460            5    100  Jacqueline Hernandez\n",
       "9   9001733828207            5    100  Jacqueline Hernandez\n",
       "11  5400110077162            6    100          Joseph Smith\n",
       "10  2828385250821            6    100          Joseph Smith\n",
       "17  5433696913272            9    100         Taylor, Billy\n",
       "16  7794666749030            9    100          Billy Taylor\n",
       "21  3632687508653           11    100          Michael Hunt\n",
       "20  2447864260207           11    100          Michael Hunt\n",
       "23  3054578050438           12    100           David Smith\n",
       "22  6332467549384           12    100           David Smith\n",
       "27  7537589811664           14    100        Michael Thomas\n",
       "26  3747334520428           14    100        Michael Thomas\n",
       "34  1445917465778           17    100            Kevin Diaz\n",
       "33  8914835563291           17    100           Diaz, Kevin\n",
       "35   825827228877           18    100      Michael Sullivan\n",
       "36  9520235523057           18    100      Michael Sullivan\n",
       "40  7039363481297           20    100       Amanda Thompson\n",
       "41   231280510563           20    100       Amanda Thompson\n",
       "44  9294051750262           22    100        Lewis, Anthony\n",
       "45  2118643743364           22    100         Anthony Lewis\n",
       "46  1360800895169           23    100     Christopher Moore\n",
       "47  7072377543230           23    100     Christopher Moore\n",
       "53  3175587312222           26    100          Thomas Jones\n",
       "54  7249915988253           26    100          Thomas Jones\n",
       "57  4716904989414           28    100           Joseph Cole\n",
       "58  7345449199476           28    100           Joseph Cole\n",
       "60   952131193062           29    100     Danielle Williams\n",
       "59  8127440448529           29    100     Danielle Williams\n",
       "62  8844950381619           30    100        Heather Taylor\n",
       "61  9432861001628           30    100        Heather Taylor\n",
       "63  8579400177275           31    100          Lauren Smith\n",
       "64  8950577347478           31    100          Lauren Smith\n",
       "66  7506296213450           32    100            John Brown\n",
       "65  8673512181554           32    100            John Brown\n",
       "68  6261795470414           33    100           John Miller\n",
       "67  6774632622452           33    100           John Miller\n",
       "70   184447183004           34    100           Linda Brown\n",
       "69  3213723680900           34    100           Linda Brown"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_thin.iloc[0:40].sort_values(by='match_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
